"""
æ¨¡çµ„èª¿ç”¨å”èª¿å™¨ - è² è²¬ç³»çµ±å±¤çš„æ¨¡çµ„é–“èª¿ç”¨é‚è¼¯
å¯¦ç¾å®Œæ•´çš„ä¸‰å±¤æ¶æ§‹ï¼šè¼¸å…¥å±¤ â†’ è™•ç†å±¤ â†’ è¼¸å‡ºå±¤
æ ¹æ“š docs/å®Œæ•´ç³»çµ±æµç¨‹æ–‡æª”.md ä¸­å®šç¾©çš„åˆ†å±¤æ¶æ§‹

=== Flow-Based å»é‡æ©Ÿåˆ¶ ===
ç‚ºé˜²æ­¢äº‹ä»¶é‡è¤‡è™•ç†,æ¡ç”¨ flow-based å»é‡ç­–ç•¥:

1. Flow ID = session_id + cycle_index
   - session_id: GS (General Session) ID,ä¸æ˜¯æ¨¡çµ„å±¤ç´šçš„ CS/WS
   - cycle_index: ç³»çµ±å¾ªç’°è¨ˆæ•¸å™¨ (æ¯æ¬¡å°è©±å¾€è¿” +1)

2. Dedupe Key = flow_id + layer
   æ ¼å¼: "{session_id}:{cycle_index}:{layer}"
   ç¤ºä¾‹: "gs_20231013_001:7:PROCESSING"

3. ç”Ÿå‘½é€±æœŸç®¡ç†:
   - CYCLE_COMPLETED: æ¸…ç†ç•¶å‰ cycle çš„æ‰€æœ‰ layer éµ
   - SESSION_ENDED: æ¸…ç†æ•´å€‹ session çš„æ‰€æœ‰éµ
   - ä¿è­·æ€§æ¸…ç†: è¶…é 2000 å€‹éµæ™‚è‡ªå‹•æ¸…ç†ä¸€åŠ

4. æœƒè©±å±¤ç´šèªªæ˜:
   - GS (General Session): ç³»çµ±ç´šæœƒè©±,è·¨è¶Šæ•´å€‹å°è©±ç”Ÿå‘½é€±æœŸ
   - CS (Chatting Session): å°è©±æœƒè©±,MEM æ¨¡çµ„ä½¿ç”¨
   - WS (Workflow Session): å·¥ä½œæµæœƒè©±,LLM å’Œ SYS æ¨¡çµ„ä½¿ç”¨
   - æœ¬å”èª¿å™¨ä½¿ç”¨ GS ä½œç‚ºå»é‡çš„ session_id
   
è¨»: LLM æ˜¯å…©å€‹é‚è¼¯ç³»çµ± (å°è©±/å·¥ä½œæµ) çš„ä¸­æ¨
"""

import time
import threading
from typing import Dict, Any, Optional, List
from dataclasses import dataclass
from enum import Enum

from utils.debug_helper import debug_log, info_log, error_log


class ProcessingLayer(Enum):
    """è™•ç†å±¤ç´šå®šç¾©"""
    INPUT = "input"          # è¼¸å…¥å±¤ï¼šSTT, NLP
    PROCESSING = "processing"  # è™•ç†å±¤ï¼šMEM, LLM, SYS
    OUTPUT = "output"        # è¼¸å‡ºå±¤ï¼šTTS


class InvocationResult(Enum):
    """èª¿ç”¨çµæœç‹€æ…‹"""
    SUCCESS = "success"
    FAILED = "failed"
    SKIPPED = "skipped"
    NO_TARGET = "no_target"


@dataclass
class LayerTransition:
    """å±¤ç´šè½‰æ›è«‹æ±‚"""
    from_layer: ProcessingLayer
    to_layer: ProcessingLayer
    data: Dict[str, Any]
    source_module: str
    reasoning: str


@dataclass
class ModuleInvocationRequest:
    """æ¨¡çµ„èª¿ç”¨è«‹æ±‚"""
    target_module: str
    input_data: Dict[str, Any]
    source_module: str
    reasoning: str
    layer: ProcessingLayer
    priority: int = 1
    timeout: float = 30.0


@dataclass
class ModuleInvocationResponse:
    """æ¨¡çµ„èª¿ç”¨å›æ‡‰"""
    target_module: str
    result: InvocationResult
    layer: ProcessingLayer
    output_data: Optional[Dict[str, Any]] = None
    error_message: Optional[str] = None
    execution_time: float = 0.0


class ModuleInvocationCoordinator:
    """æ¨¡çµ„èª¿ç”¨å”èª¿å™¨ - å¯¦ç¾å®Œæ•´ä¸‰å±¤æ¶æ§‹çš„æ¨¡çµ„é–“èª¿ç”¨ç®¡ç†"""
    
    # å®šç¾©æ¨¡çµ„æ‰€å±¬å±¤ç´š
    MODULE_LAYERS = {
        'stt': ProcessingLayer.INPUT,
        'nlp': ProcessingLayer.INPUT,
        'mem': ProcessingLayer.PROCESSING,
        'llm': ProcessingLayer.PROCESSING,
        'sys': ProcessingLayer.PROCESSING,
        'tts': ProcessingLayer.OUTPUT
    }
    
    def __init__(self):
        """åˆå§‹åŒ–å”èª¿å™¨"""
        self._invocation_lock = threading.Lock()
        self._active_invocations = {}
        self._invocation_history = []
        self._layer_transitions = []
        
        # æ–°çš„å»é‡æ©Ÿåˆ¶: flow_id + layer
        # dedupe_key = f"{session_id}:{cycle_index}:{layer}"
        self._layer_dedupe_keys = set()  # å±¤ç´šå»é‡é›†åˆ
        self._dedupe_lock = threading.Lock()
        self._max_dedupe_keys = 2000  # æœ€å¤šä¿ç•™ 2000 å€‹å»é‡éµ
        
        # çµ±è¨ˆä¿¡æ¯
        self._dedupe_hit_count = 0
        self._cleanup_count = 0
        
        info_log("[ModuleCoordinator] ä¸‰å±¤æ¶æ§‹æ¨¡çµ„èª¿ç”¨å”èª¿å™¨åˆå§‹åŒ–")
        info_log("[ModuleCoordinator] ä½¿ç”¨ flow-based å»é‡ç­–ç•¥ (session_id:cycle_index:layer)")
        
        # âœ… è¨‚é–±äº‹ä»¶ç¸½ç·š
        self._setup_event_subscriptions()
    
    def _setup_event_subscriptions(self):
        """è¨­ç½®äº‹ä»¶è¨‚é–± - äº‹ä»¶é©…å‹•æ¶æ§‹çš„æ ¸å¿ƒ"""
        try:
            from core.event_bus import event_bus, SystemEvent
            
            info_log("[ModuleCoordinator] é–‹å§‹è¨‚é–±äº‹ä»¶ç¸½ç·š...")
            
            # è¨‚é–±è¼¸å…¥å±¤å®Œæˆäº‹ä»¶
            event_bus.subscribe(
                SystemEvent.INPUT_LAYER_COMPLETE,
                self._on_input_layer_complete,
                handler_name="ModuleCoordinator.input_complete"
            )
            info_log(f"[ModuleCoordinator] âœ“ å·²è¨‚é–± INPUT_LAYER_COMPLETE")
            
            # è¨‚é–±è™•ç†å±¤å®Œæˆäº‹ä»¶
            event_bus.subscribe(
                SystemEvent.PROCESSING_LAYER_COMPLETE,
                self._on_processing_layer_complete,
                handler_name="ModuleCoordinator.processing_complete"
            )
            info_log(f"[ModuleCoordinator] âœ“ å·²è¨‚é–± PROCESSING_LAYER_COMPLETE")
            
            # è¨‚é–±å¾ªç’°å®Œæˆäº‹ä»¶ (ç”¨æ–¼æ¸…ç†å»é‡éµ)
            event_bus.subscribe(
                SystemEvent.CYCLE_COMPLETED,
                self._on_cycle_completed,
                handler_name="ModuleCoordinator.cycle_complete"
            )
            info_log(f"[ModuleCoordinator] âœ“ å·²è¨‚é–± CYCLE_COMPLETED")
            
            # è¨‚é–±æœƒè©±çµæŸäº‹ä»¶ (ç”¨æ–¼æ¸…ç†å»é‡éµ)
            event_bus.subscribe(
                SystemEvent.SESSION_ENDED,
                self._on_session_ended,
                handler_name="ModuleCoordinator.session_end"
            )
            info_log(f"[ModuleCoordinator] âœ“ å·²è¨‚é–± SESSION_ENDED")
            
            info_log("[ModuleCoordinator] âœ… äº‹ä»¶è¨‚é–±å®Œæˆ (4 å€‹äº‹ä»¶)")
            
        except Exception as e:
            error_log(f"[ModuleCoordinator] âŒ äº‹ä»¶è¨‚é–±å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
    
    def _on_input_layer_complete(self, event):
        """
        è¼¸å…¥å±¤å®Œæˆäº‹ä»¶è™•ç†å™¨
        ç•¶ NLP ç™¼å¸ƒ INPUT_LAYER_COMPLETE äº‹ä»¶æ™‚è§¸ç™¼
        ä½¿ç”¨ flow-based å»é‡: session_id + cycle_index + layer
        
        æ³¨æ„: é€™è£¡çš„ session_id æ˜¯ GS (General Session),
              ä¸æ˜¯æ¨¡çµ„å±¤ç´šçš„ CS (MEM) æˆ– WS (LLM/SYS)
        """
        try:
            # æå– flow è­˜åˆ¥è³‡è¨Š (ä¾†è‡ª General Session)
            session_id = event.data.get('session_id', 'unknown')  # GS ID
            cycle_index = event.data.get('cycle_index', -1)
            
            # æ§‹å»ºå»é‡éµ: flow_id + layer
            dedupe_key = f"{session_id}:{cycle_index}:INPUT"
            
            # æª¢æŸ¥æ˜¯å¦å·²è™•ç†éæ­¤ flow çš„æ­¤ layer
            with self._dedupe_lock:
                if dedupe_key in self._layer_dedupe_keys:
                    self._dedupe_hit_count += 1
                    debug_log(2, f"[ModuleCoordinator] âš ï¸ è·³éé‡è¤‡è™•ç† (dedupe_key={dedupe_key}, å‘½ä¸­æ¬¡æ•¸={self._dedupe_hit_count})")
                    return
                
                # æ¨™è¨˜ç‚ºå·²è™•ç†
                self._layer_dedupe_keys.add(dedupe_key)
                debug_log(3, f"[ModuleCoordinator] âœ“ å·²è¨˜éŒ„å»é‡éµ: {dedupe_key} (å…± {len(self._layer_dedupe_keys)} å€‹)")
                
                # ä¿è­·æ€§æ¸…ç†: é¿å…é›†åˆç„¡é™å¢é•·
                if len(self._layer_dedupe_keys) > self._max_dedupe_keys:
                    removed_count = len(self._layer_dedupe_keys) - (self._max_dedupe_keys // 2)
                    keys_to_remove = list(self._layer_dedupe_keys)[:(self._max_dedupe_keys // 2)]
                    for old_key in keys_to_remove:
                        self._layer_dedupe_keys.discard(old_key)
                    self._cleanup_count += removed_count
                    debug_log(3, f"[ModuleCoordinator] ä¿è­·æ€§æ¸…ç†: ç§»é™¤ {removed_count} å€‹èˆŠéµ")
            
            info_log(f"[ModuleCoordinator] ğŸ¯ æ”¶åˆ°è¼¸å…¥å±¤å®Œæˆäº‹ä»¶ (flow={session_id}:{cycle_index}, event_id={event.event_id})")
            debug_log(2, f"[ModuleCoordinator] äº‹ä»¶æ•¸æ“š: {list(event.data.keys())}")
            self.handle_layer_completion(ProcessingLayer.INPUT, event.data)
                    
        except Exception as e:
            error_log(f"[ModuleCoordinator] âŒ è™•ç†è¼¸å…¥å±¤å®Œæˆäº‹ä»¶å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
    
    def _on_processing_layer_complete(self, event):
        """
        è™•ç†å±¤å®Œæˆäº‹ä»¶è™•ç†å™¨
        ç•¶ LLM ç™¼å¸ƒ PROCESSING_LAYER_COMPLETE äº‹ä»¶æ™‚è§¸ç™¼
        ä½¿ç”¨ flow-based å»é‡: session_id + cycle_index + layer
        
        æ³¨æ„: é€™è£¡çš„ session_id æ˜¯ GS (General Session),
              ä¸æ˜¯æ¨¡çµ„å±¤ç´šçš„ CS (MEM) æˆ– WS (LLM/SYS)
        """
        try:
            # æå– flow è­˜åˆ¥è³‡è¨Š (ä¾†è‡ª General Session)
            session_id = event.data.get('session_id', 'unknown')  # GS ID
            cycle_index = event.data.get('cycle_index', -1)
            
            # æ§‹å»ºå»é‡éµ: flow_id + layer
            dedupe_key = f"{session_id}:{cycle_index}:PROCESSING"
            
            # æª¢æŸ¥æ˜¯å¦å·²è™•ç†éæ­¤ flow çš„æ­¤ layer
            with self._dedupe_lock:
                if dedupe_key in self._layer_dedupe_keys:
                    self._dedupe_hit_count += 1
                    debug_log(2, f"[ModuleCoordinator] âš ï¸ è·³éé‡è¤‡è™•ç† (dedupe_key={dedupe_key}, å‘½ä¸­æ¬¡æ•¸={self._dedupe_hit_count})")
                    return
                
                # æ¨™è¨˜ç‚ºå·²è™•ç†
                self._layer_dedupe_keys.add(dedupe_key)
                debug_log(3, f"[ModuleCoordinator] âœ“ å·²è¨˜éŒ„å»é‡éµ: {dedupe_key} (å…± {len(self._layer_dedupe_keys)} å€‹)")
                
                # ä¿è­·æ€§æ¸…ç†
                if len(self._layer_dedupe_keys) > self._max_dedupe_keys:
                    removed_count = len(self._layer_dedupe_keys) - (self._max_dedupe_keys // 2)
                    keys_to_remove = list(self._layer_dedupe_keys)[:(self._max_dedupe_keys // 2)]
                    for old_key in keys_to_remove:
                        self._layer_dedupe_keys.discard(old_key)
                    self._cleanup_count += removed_count
                    debug_log(3, f"[ModuleCoordinator] ä¿è­·æ€§æ¸…ç†: ç§»é™¤ {removed_count} å€‹èˆŠéµ")
            
            info_log(f"[ModuleCoordinator] ğŸ¯ æ”¶åˆ°è™•ç†å±¤å®Œæˆäº‹ä»¶ (flow={session_id}:{cycle_index}, event_id={event.event_id})")
            debug_log(2, f"[ModuleCoordinator] äº‹ä»¶æ•¸æ“š: {list(event.data.keys())}")
            self.handle_layer_completion(ProcessingLayer.PROCESSING, event.data)
                    
        except Exception as e:
            error_log(f"[ModuleCoordinator] âŒ è™•ç†è™•ç†å±¤å®Œæˆäº‹ä»¶å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
    
    def _on_cycle_completed(self, event):
        """
        å¾ªç’°å®Œæˆäº‹ä»¶è™•ç†å™¨
        æ¸…ç†å·²å®Œæˆ cycle çš„å»é‡éµ
        
        æ³¨æ„: é€™è£¡çš„ session_id æ˜¯ GS (General Session)
        """
        try:
            session_id = event.data.get('session_id', 'unknown')  # GS ID
            cycle_index = event.data.get('cycle_index', -1)
            flow_prefix = f"{session_id}:{cycle_index}:"
            
            with self._dedupe_lock:
                # æ‰¾å‡ºä¸¦ç§»é™¤æ­¤ flow çš„æ‰€æœ‰ layer éµ
                keys_to_remove = [k for k in self._layer_dedupe_keys if k.startswith(flow_prefix)]
                for key in keys_to_remove:
                    self._layer_dedupe_keys.discard(key)
                
                self._cleanup_count += len(keys_to_remove)
                info_log(f"[ModuleCoordinator] ğŸ§¹ CYCLE_COMPLETED æ¸…ç†: ç§»é™¤ {len(keys_to_remove)} å€‹å»é‡éµ (flow={session_id}:{cycle_index})")
                debug_log(3, f"[ModuleCoordinator] å‰©é¤˜å»é‡éµæ•¸é‡: {len(self._layer_dedupe_keys)}")
                
        except Exception as e:
            error_log(f"[ModuleCoordinator] âŒ è™•ç†å¾ªç’°å®Œæˆäº‹ä»¶å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
    
    def _on_session_ended(self, event):
        """
        æœƒè©±çµæŸäº‹ä»¶è™•ç†å™¨
        æ¸…ç†æ•´å€‹ session çš„å»é‡éµ
        
        æ³¨æ„: é€™è£¡çš„ session_id æ˜¯ GS (General Session)
              ç•¶ GS çµæŸæ™‚,å…¶ä¸‹çš„æ‰€æœ‰ CS (MEM) å’Œ WS (LLM/SYS) ä¹Ÿéƒ½çµæŸäº†
        """
        try:
            session_id = event.data.get('session_id', 'unknown')  # GS ID
            session_prefix = f"{session_id}:"
            
            with self._dedupe_lock:
                # æ‰¾å‡ºä¸¦ç§»é™¤æ­¤ session çš„æ‰€æœ‰éµ
                keys_to_remove = [k for k in self._layer_dedupe_keys if k.startswith(session_prefix)]
                for key in keys_to_remove:
                    self._layer_dedupe_keys.discard(key)
                
                self._cleanup_count += len(keys_to_remove)
                info_log(f"[ModuleCoordinator] ğŸ§¹ SESSION_ENDED æ¸…ç†: ç§»é™¤ {len(keys_to_remove)} å€‹å»é‡éµ (session={session_id})")
                debug_log(3, f"[ModuleCoordinator] å‰©é¤˜å»é‡éµæ•¸é‡: {len(self._layer_dedupe_keys)}")
                debug_log(3, f"[ModuleCoordinator] çµ±è¨ˆ - å‘½ä¸­æ¬¡æ•¸: {self._dedupe_hit_count}, æ¸…ç†æ¬¡æ•¸: {self._cleanup_count}")
                
        except Exception as e:
            error_log(f"[ModuleCoordinator] âŒ è™•ç†æœƒè©±çµæŸäº‹ä»¶å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_layer_completion(self, layer: ProcessingLayer, completion_data: Dict[str, Any]) -> bool:
        """
        è™•ç†å±¤ç´šå®Œæˆé€šçŸ¥ï¼Œå”èª¿ä¸‹ä¸€å±¤è™•ç†
        
        Args:
            layer: å®Œæˆçš„å±¤ç´š
            completion_data: å®Œæˆæ•¸æ“š
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸè§¸ç™¼ä¸‹ä¸€å±¤è™•ç†
        """
        try:
            info_log(f"[ModuleCoordinator] {layer.value}å±¤å®Œæˆï¼Œå”èª¿ä¸‹ä¸€å±¤è™•ç†")
            debug_log(2, f"[ModuleCoordinator] å®Œæˆæ•¸æ“š: {list(completion_data.keys())}")
            
            # æ ¹æ“šç•¶å‰å±¤æ±ºå®šä¸‹ä¸€å±¤è™•ç†
            if layer == ProcessingLayer.INPUT:
                return self._transition_to_processing_layer(completion_data)
            elif layer == ProcessingLayer.PROCESSING:
                return self._transition_to_output_layer(completion_data)
            else:
                debug_log(2, f"[ModuleCoordinator] {layer.value}å±¤æ˜¯æœ€çµ‚å±¤ï¼Œç„¡éœ€é€²ä¸€æ­¥è™•ç†")
                return True
                
        except Exception as e:
            error_log(f"[ModuleCoordinator] è™•ç†{layer.value}å±¤å®Œæˆå¤±æ•—: {e}")
            return False
    
    def _transition_to_processing_layer(self, input_data: Dict[str, Any]) -> bool:
        """è¼¸å…¥å±¤ â†’ è™•ç†å±¤è½‰æ›
        
        é‡è¦æ¶æ§‹è¨­è¨ˆï¼š
        - ä¸ä½¿ç”¨ Routerï¼ˆRouter ä¾è³´ç³»çµ±ç‹€æ…‹ï¼Œè€Œç‹€æ…‹å°šæœªè½‰æ›ï¼‰
        - ç›´æ¥å¾ NLP çµæœçš„ primary_intent æ±ºå®šè™•ç†å±¤è·¯å¾‘
        - WORK â†’ LLM + SYS, CHAT â†’ MEM + LLM
        """
        try:
            info_log("[ModuleCoordinator] è¼¸å…¥å±¤ â†’ è™•ç†å±¤è½‰æ›")
            
            # å¾ NLP çµæœç²å–ä¸»è¦æ„åœ–
            nlp_result = input_data.get('nlp_result', {})
            primary_intent = nlp_result.get('primary_intent')
            
            if not primary_intent:
                debug_log(2, "[ModuleCoordinator] NLP çµæœç„¡ä¸»è¦æ„åœ–ï¼Œè·³éè™•ç†å±¤")
                return False
            
            # å°å…¥ IntentType ä»¥é€²è¡Œåˆ¤æ–·
            from modules.nlp_module.intent_types import IntentType
            
            # è™•ç†æšèˆ‰æˆ–å­—ç¬¦ä¸²å€¼
            intent_value = primary_intent.value if hasattr(primary_intent, 'value') else primary_intent
            intent_name = primary_intent.name if hasattr(primary_intent, 'name') else str(primary_intent)
            
            info_log(f"[ModuleCoordinator] ä¸»è¦æ„åœ–: {intent_name} (value={intent_value})")
            
            # ç›´æ¥ä½¿ç”¨ primary_intent ä½œç‚º targetï¼ˆ_prepare_processing_requests æœƒæ ¹æ“šå®ƒæ±ºå®šè·¯å¾‘ï¼‰
            # é€™è£¡å‚³å…¥ intent_name ä½œç‚ºå½¢å¼ä¸Šçš„ targetï¼Œå¯¦éš›è·¯å¾‘ç”± _prepare_processing_requests æ±ºå®š
            
            # æº–å‚™è™•ç†å±¤èª¿ç”¨è«‹æ±‚ï¼ˆæ ¹æ“š primary_intent æ±ºå®š WORK/CHAT è·¯å¾‘ï¼‰
            requests = self._prepare_processing_requests(intent_name, input_data)
            
            # åŸ·è¡Œè™•ç†å±¤èª¿ç”¨
            responses = self.invoke_multiple_modules(requests)
            
            # æª¢æŸ¥æ˜¯å¦æœ‰æˆåŠŸçš„èª¿ç”¨
            success_count = sum(1 for r in responses if r.result == InvocationResult.SUCCESS)
            info_log(f"[ModuleCoordinator] è™•ç†å±¤å®Œæˆ: {success_count}/{len(responses)} æˆåŠŸ")
            
            return success_count > 0
            
        except Exception as e:
            error_log(f"[ModuleCoordinator] è¼¸å…¥å±¤ â†’ è™•ç†å±¤è½‰æ›å¤±æ•—: {e}")
            return False
    
    def _transition_to_output_layer(self, processing_data: Dict[str, Any]) -> bool:
        """è™•ç†å±¤ â†’ è¼¸å‡ºå±¤è½‰æ›"""
        try:
            info_log("[ModuleCoordinator] è™•ç†å±¤ â†’ è¼¸å‡ºå±¤è½‰æ›")
            
            # å¾è™•ç†å±¤çµæœä¸­æå–æ–‡å­—å…§å®¹
            response_text = self._extract_response_text(processing_data)
            
            if not response_text:
                debug_log(2, "[ModuleCoordinator] è™•ç†å±¤ç„¡æ–‡å­—è¼¸å‡ºï¼Œè·³éè¼¸å‡ºå±¤")
                return False
            
            info_log(f"[ModuleCoordinator] è™•ç†å±¤æ–‡å­—è¼¸å‡º: {response_text[:50]}...")
            
            # é€šé Router ç²å–è¼¸å‡ºå±¤è·¯ç”±æ±ºç­–
            from core.router import router
            routing_decision = router.route_system_output(
                text=response_text, 
                source_module="processing_layer"
            )
            
            if routing_decision.target_module != "tts":
                debug_log(1, f"[ModuleCoordinator] Router æœªæŒ‡å‘ TTS: {routing_decision.target_module}")
                return False
            
            info_log(f"[ModuleCoordinator] Router æ±ºç­–: {routing_decision.reasoning}")
            
            # æº–å‚™è¼¸å‡ºå±¤èª¿ç”¨ï¼ˆé€šå¸¸æ˜¯TTSï¼‰
            output_request = ModuleInvocationRequest(
                target_module="tts",
                input_data=self._prepare_output_input(processing_data),
                source_module="processing_layer",
                reasoning="è™•ç†å±¤å®Œæˆï¼Œè½‰é€è¼¸å‡ºå±¤",
                layer=ProcessingLayer.OUTPUT,
                priority=2
            )
            
            # åŸ·è¡Œè¼¸å‡ºå±¤èª¿ç”¨
            response = self.invoke_module(output_request)
            
            success = response.result == InvocationResult.SUCCESS
            if success:
                info_log("[ModuleCoordinator] è¼¸å‡ºå±¤å®Œæˆï¼Œä¸‰å±¤æµç¨‹çµæŸ")
                # âœ… TTS æ¨¡çµ„å·²ç¶“é€šéäº‹ä»¶ç¸½ç·šç™¼å¸ƒ OUTPUT_LAYER_COMPLETE äº‹ä»¶
                # âœ… SystemLoop æœƒè‡ªå‹•æ¥æ”¶ä¸¦è™•ç†ï¼Œä¸éœ€è¦é‡è¤‡é€šçŸ¥
                debug_log(2, "[ModuleCoordinator] ç­‰å¾… TTS ç™¼å¸ƒçš„ OUTPUT_LAYER_COMPLETE äº‹ä»¶å®Œæˆå¾ªç’°")
            else:
                error_log(f"[ModuleCoordinator] è¼¸å‡ºå±¤èª¿ç”¨å¤±æ•—: {response.error_message}")
            
            return success
            
        except Exception as e:
            error_log(f"[ModuleCoordinator] è™•ç†å±¤ â†’ è¼¸å‡ºå±¤è½‰æ›å¤±æ•—: {e}")
            return False
    
    def _prepare_processing_requests(self, primary_target: str, input_data: Dict[str, Any]) -> List[ModuleInvocationRequest]:
        """æº–å‚™è™•ç†å±¤èª¿ç”¨è«‹æ±‚"""
        requests = []
        nlp_result = input_data.get('nlp_result', {})
        primary_intent = nlp_result.get('primary_intent')
        
        # å°å…¥ IntentType ä»¥é€²è¡Œæ­£ç¢ºçš„æšèˆ‰æ¯”è¼ƒ
        from modules.nlp_module.intent_types import IntentType
        
        # è™•ç†æšèˆ‰æˆ–å­—ç¬¦ä¸²å€¼
        intent_value = primary_intent.value if hasattr(primary_intent, 'value') else primary_intent
        intent_name = primary_intent.name if hasattr(primary_intent, 'name') else str(primary_intent)
        
        debug_log(2, f"[ModuleCoordinator] æº–å‚™è™•ç†å±¤è«‹æ±‚ - Intent: {intent_name} (value={intent_value})")
        
        # æ ¹æ“šæ„åœ–æ±ºå®šè™•ç†å±¤æ¨¡çµ„çµ„åˆ
        if primary_intent == IntentType.CHAT or intent_value == "chat":
            # CHATè·¯å¾‘ï¼šMEM + LLM
            info_log("[ModuleCoordinator] CHAT è·¯å¾‘: MEM + LLM")
            requests.extend([
                ModuleInvocationRequest(
                    target_module="mem",
                    input_data=self._prepare_mem_input(input_data),
                    source_module="input_layer",
                    reasoning="èŠå¤©æ¨¡å¼è¨˜æ†¶æŸ¥è©¢",
                    layer=ProcessingLayer.PROCESSING,
                    priority=4
                ),
                ModuleInvocationRequest(
                    target_module="llm",
                    input_data=self._prepare_llm_input(input_data),
                    source_module="input_layer", 
                    reasoning="èŠå¤©å°è©±ç”Ÿæˆ",
                    layer=ProcessingLayer.PROCESSING,
                    priority=3
                )
            ])
        elif primary_intent == IntentType.WORK or intent_value == "work":
            # WORKè·¯å¾‘ï¼šLLM + SYS (ä¸éœ€è¦ MEM)
            info_log("[ModuleCoordinator] WORK è·¯å¾‘: LLM + SYS")
            requests.extend([
                ModuleInvocationRequest(
                    target_module="llm",
                    input_data=self._prepare_llm_input(input_data),
                    source_module="input_layer",
                    reasoning="å·¥ä½œæ¨¡å¼ä»»å‹™åˆ†æ",
                    layer=ProcessingLayer.PROCESSING,
                    priority=4
                ),
                ModuleInvocationRequest(
                    target_module="sys",
                    input_data=self._prepare_sys_input(input_data),
                    source_module="input_layer",
                    reasoning="ç³»çµ±å·¥ä½œæµåŸ·è¡Œ",
                    layer=ProcessingLayer.PROCESSING,
                    priority=3
                )
            ])
        else:
            # é»˜èªï¼šä½¿ç”¨ä¸»è¦ç›®æ¨™
            info_log(f"[ModuleCoordinator] é»˜èªè·¯å¾‘: {primary_target}")
            requests.append(ModuleInvocationRequest(
                target_module=primary_target,
                input_data=self._prepare_module_input(primary_target, input_data),
                source_module="input_layer",
                reasoning=f"é»˜èªè™•ç†ï¼š{intent_name}",
                layer=ProcessingLayer.PROCESSING,
                priority=3
            ))
        
        return requests
    
    def _prepare_mem_input(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æº–å‚™MEMæ¨¡çµ„è¼¸å…¥"""
        nlp_result = input_data.get('nlp_result', {})
        return {
            "text": input_data.get('input_data', {}).get('text', ''),
            "source": "three_layer_coordinator",
            "operation": "store_and_retrieve",
            "memory_context": {
                "identity_id": nlp_result.get('identity', {}).get('identity_id'),
                "conversation_type": nlp_result.get('primary_intent'),
                "entities": nlp_result.get('entities', [])
            },
            "timestamp": input_data.get('timestamp', time.time()),
            "nlp_result": nlp_result
        }
    
    def _prepare_llm_input(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æº–å‚™LLMæ¨¡çµ„è¼¸å…¥
        
        é‡è¦æ¶æ§‹è¨­è¨ˆï¼š
        - ç¬¬ä¸€æ¬¡é€²å…¥è™•ç†å±¤ (cycle_index = 0)ï¼šå¾ç‹€æ…‹ä¸Šä¸‹æ–‡ (WorkflowSession) ç²å–å‘½ä»¤æ–‡æœ¬
        - ç¬¬äºŒæ¬¡ä»¥å¾Œ (cycle_index > 0)ï¼šå¾ Router ç²å–ç”¨æˆ¶å›æ‡‰æ–‡æœ¬
        """
        nlp_result = input_data.get('nlp_result', {})
        cycle_index = input_data.get('cycle_index', 0)
        primary_intent = nlp_result.get('primary_intent')
        
        # å°å…¥ IntentType ä»¥é€²è¡Œåˆ¤æ–·
        from modules.nlp_module.intent_types import IntentType
        intent_value = primary_intent.value if hasattr(primary_intent, 'value') else primary_intent
        
        # åˆ¤æ–·æ–‡æœ¬ä¾†æºï¼šç¬¬ä¸€æ¬¡é€²å…¥ WORK ç‹€æ…‹æ™‚ï¼Œå¾ WorkflowSession ç²å–å‘½ä»¤
        if (primary_intent == IntentType.WORK or intent_value == "work") and cycle_index == 0:
            # ç¬¬ä¸€æ¬¡é€²å…¥ WORK ç‹€æ…‹ï¼šå¾ WorkflowSession.task_definition ç²å– command
            try:
                from core.sessions.session_manager import session_manager
                
                active_ws_ids = session_manager.get_active_workflow_session_ids()
                if active_ws_ids:
                    ws = session_manager.get_workflow_session(active_ws_ids[0])
                    if ws and hasattr(ws, 'task_definition'):
                        # âœ… å¾ç‹€æ…‹ä¸Šä¸‹æ–‡ç²å–å‘½ä»¤æ–‡æœ¬
                        input_text = ws.task_definition.get('command', '')
                        debug_log(2, f"[ModuleCoordinator] ç¬¬ä¸€æ¬¡é€²å…¥ WORK - å¾ WS ç²å– command: {input_text[:50]}...")
                    else:
                        input_text = input_data.get('input_data', {}).get('text', '')
                        debug_log(2, f"[ModuleCoordinator] WS ç„¡ task_definitionï¼Œä½¿ç”¨ Router æ–‡æœ¬")
                else:
                    input_text = input_data.get('input_data', {}).get('text', '')
                    debug_log(2, f"[ModuleCoordinator] ç„¡æ´»èº WSï¼Œä½¿ç”¨ Router æ–‡æœ¬")
            except Exception as e:
                error_log(f"[ModuleCoordinator] å¾ WS ç²å– command å¤±æ•—: {e}")
                input_text = input_data.get('input_data', {}).get('text', '')
        else:
            # å…¶ä»–æƒ…æ³ï¼šå¾ Router ç²å–æ–‡æœ¬ï¼ˆCHAT è·¯å¾‘æˆ– WORK ç¬¬äºŒæ¬¡ä»¥å¾Œï¼‰
            input_text = input_data.get('input_data', {}).get('text', '')
            if cycle_index > 0:
                debug_log(2, f"[ModuleCoordinator] WORK cycle {cycle_index} - å¾ Router ç²å–ç”¨æˆ¶å›æ‡‰")
        
        # âœ… æ ¹æ“š primary_intent æ±ºå®š LLM æ¨¡å¼
        if primary_intent == IntentType.WORK or intent_value == "work":
            llm_mode = "work"
        else:
            llm_mode = "chat"
        
        return {
            "text": input_text,
            "source": "three_layer_coordinator",
            "mode": llm_mode,  # âœ… æ·»åŠ  mode åƒæ•¸ï¼Œè®“ LLM çŸ¥é“æ˜¯ WORK é‚„æ˜¯ CHAT
            "conversation_type": nlp_result.get('primary_intent'),
            "user_input": input_text,
            "context": {
                "intent_segments": nlp_result.get('intent_segments', []),
                "entities": nlp_result.get('entities', []),
                "processing_notes": nlp_result.get('processing_notes', [])
            },
            "timestamp": input_data.get('timestamp', time.time()),
            "nlp_result": nlp_result,
            "identity": nlp_result.get('identity'),
            "intent": nlp_result.get('primary_intent'),
            "confidence": nlp_result.get('overall_confidence', 0.0),
            "cycle_index": cycle_index  # âœ… å‚³é cycle_index ä¾› LLM æ¨¡çµ„ä½¿ç”¨
        }
    
    def _prepare_sys_input(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æº–å‚™SYSæ¨¡çµ„è¼¸å…¥
        
        é‡è¦æ¶æ§‹è¨­è¨ˆï¼š
        - ç¬¬ä¸€æ¬¡é€²å…¥è™•ç†å±¤ (cycle_index = 0)ï¼šå¾ç‹€æ…‹ä¸Šä¸‹æ–‡ (WorkflowSession) ç²å–å‘½ä»¤æ–‡æœ¬
        - ç¬¬äºŒæ¬¡ä»¥å¾Œ (cycle_index > 0)ï¼šå¾ Router ç²å–ç”¨æˆ¶å›æ‡‰æ–‡æœ¬
        """
        nlp_result = input_data.get('nlp_result', {})
        cycle_index = input_data.get('cycle_index', 0)
        
        # åˆ¤æ–·æ–‡æœ¬ä¾†æºï¼ˆèˆ‡ LLM ä½¿ç”¨ç›¸åŒé‚è¼¯ï¼‰
        if cycle_index == 0:
            # ç¬¬ä¸€æ¬¡é€²å…¥ï¼šå¾ WorkflowSession ç²å–å‘½ä»¤
            try:
                from core.sessions.session_manager import session_manager
                
                active_ws_ids = session_manager.get_active_workflow_session_ids()
                if active_ws_ids:
                    ws = session_manager.get_workflow_session(active_ws_ids[0])
                    if ws and hasattr(ws, 'task_definition'):
                        # âœ… å¾ç‹€æ…‹ä¸Šä¸‹æ–‡ç²å–å‘½ä»¤æ–‡æœ¬
                        input_text = ws.task_definition.get('command', '')
                        debug_log(2, f"[ModuleCoordinator] ç¬¬ä¸€æ¬¡é€²å…¥ WORK - SYS å¾ WS ç²å– command: {input_text[:50]}...")
                    else:
                        input_text = input_data.get('input_data', {}).get('text', '')
                else:
                    input_text = input_data.get('input_data', {}).get('text', '')
            except Exception as e:
                error_log(f"[ModuleCoordinator] SYS å¾ WS ç²å– command å¤±æ•—: {e}")
                input_text = input_data.get('input_data', {}).get('text', '')
        else:
            # ç¬¬äºŒæ¬¡ä»¥å¾Œï¼šå¾ Router ç²å–ç”¨æˆ¶å›æ‡‰
            input_text = input_data.get('input_data', {}).get('text', '')
            debug_log(2, f"[ModuleCoordinator] WORK cycle {cycle_index} - SYS å¾ Router ç²å–æ–‡æœ¬")
        
        return {
            "text": input_text,
            "source": "three_layer_coordinator",
            "mode": "workflow",  # âœ… æ·»åŠ  mode åƒæ•¸ï¼ŒSYS æ¨¡çµ„å¿…éœ€
            "operation": "workflow_execution",
            "system_context": {
                "intent": nlp_result.get('primary_intent'),
                "entities": nlp_result.get('entities', []),
                "command_type": "work_task"
            },
            "timestamp": input_data.get('timestamp', time.time()),
            "nlp_result": nlp_result,
            "cycle_index": cycle_index  # âœ… å‚³é cycle_index ä¾› SYS æ¨¡çµ„ä½¿ç”¨
        }
    
    def _prepare_output_input(self, processing_data: Dict[str, Any]) -> Dict[str, Any]:
        """æº–å‚™è¼¸å‡ºå±¤ï¼ˆTTSï¼‰è¼¸å…¥"""
        return {
            "text": processing_data.get('response', processing_data.get('text', '')),
            "source": "three_layer_coordinator",
            "output_mode": "voice",
            "timestamp": time.time(),
            "processing_result": processing_data
        }
    
    def _prepare_module_input(self, target_module: str, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç‚ºç‰¹å®šæ¨¡çµ„æº–å‚™è¼¸å…¥æ•¸æ“šï¼ˆé€šç”¨æ–¹æ³•ï¼‰"""
        if target_module == "mem":
            return self._prepare_mem_input(input_data)
        elif target_module == "llm":
            return self._prepare_llm_input(input_data)
        elif target_module == "sys":
            return self._prepare_sys_input(input_data)
        elif target_module == "tts":
            return self._prepare_output_input(input_data)
        else:
            # é€šç”¨è¼¸å…¥æ ¼å¼
            nlp_result = input_data.get('nlp_result', {})
            return {
                "text": input_data.get('input_data', {}).get('text', ''),
                "source": "three_layer_coordinator",
                "timestamp": input_data.get('timestamp', time.time()),
                "nlp_result": nlp_result,
                "intent": nlp_result.get('primary_intent'),
                "confidence": nlp_result.get('overall_confidence', 0.0)
            }
    
    def invoke_module(self, request: ModuleInvocationRequest) -> ModuleInvocationResponse:
        """
        èª¿ç”¨ç›®æ¨™æ¨¡çµ„
        
        Args:
            request: æ¨¡çµ„èª¿ç”¨è«‹æ±‚
            
        Returns:
            ModuleInvocationResponse: èª¿ç”¨å›æ‡‰
        """
        start_time = time.time()
        
        with self._invocation_lock:
            try:
                info_log(f"[ModuleCoordinator] èª¿ç”¨{request.layer.value}å±¤æ¨¡çµ„: {request.target_module}")
                debug_log(2, f"[ModuleCoordinator] èª¿ç”¨åŸå› : {request.reasoning}")
                debug_log(3, f"[ModuleCoordinator] è¼¸å…¥æ•¸æ“š: {list(request.input_data.keys())}")
                
                # ç²å–ç›®æ¨™æ¨¡çµ„
                from core.framework import core_framework
                target_module = core_framework.get_module(request.target_module)
                
                if not target_module:
                    error_msg = f"ç„¡æ³•æ‰¾åˆ°ç›®æ¨™æ¨¡çµ„: {request.target_module}"
                    error_log(f"[ModuleCoordinator] {error_msg}")
                    return ModuleInvocationResponse(
                        target_module=request.target_module,
                        result=InvocationResult.NO_TARGET,
                        layer=request.layer,
                        error_message=error_msg,
                        execution_time=time.time() - start_time
                    )
                
                # è¨˜éŒ„æ´»èºèª¿ç”¨
                invocation_id = f"{request.target_module}_{int(time.time() * 1000)}"
                self._active_invocations[invocation_id] = {
                    "target": request.target_module,
                    "layer": request.layer.value,
                    "start_time": start_time,
                    "source": request.source_module
                }
                
                # å¯¦éš›èª¿ç”¨æ¨¡çµ„
                result_data = target_module.handle(request.input_data)
                
                # ç§»é™¤æ´»èºèª¿ç”¨è¨˜éŒ„
                if invocation_id in self._active_invocations:
                    del self._active_invocations[invocation_id]
                
                execution_time = time.time() - start_time
                
                # âœ… æ­£ç¢ºåˆ¤æ–·æˆåŠŸ: æª¢æŸ¥ result_data['success'] å­—æ®µ
                is_success = result_data and isinstance(result_data, dict) and result_data.get('success', False)
                
                if result_data:
                    # è¨˜éŒ„æ¨¡çµ„è¿”å›çµæœ
                    self._log_module_result(request.target_module, result_data)
                    
                    # æ ¹æ“š success å­—æ®µæ±ºå®šçµæœç‹€æ…‹
                    if is_success:
                        info_log(f"[ModuleCoordinator] {request.layer.value}å±¤æ¨¡çµ„ {request.target_module} è™•ç†å®Œæˆ ({execution_time:.3f}s)")
                        invocation_result = InvocationResult.SUCCESS
                    else:
                        # success=False è¦–ç‚ºå¤±æ•—,ä¸æ˜¯æˆåŠŸ
                        error_msg = result_data.get('error', 'æœªçŸ¥éŒ¯èª¤')
                        debug_log(2, f"[ModuleCoordinator] {request.layer.value}å±¤æ¨¡çµ„ {request.target_module} è™•ç†å¤±æ•—: {error_msg}")
                        invocation_result = InvocationResult.FAILED
                    
                    response = ModuleInvocationResponse(
                        target_module=request.target_module,
                        result=invocation_result,
                        layer=request.layer,
                        output_data=result_data,
                        execution_time=execution_time
                    )
                    
                    # åªæœ‰çœŸæ­£æˆåŠŸæ™‚æ‰æª¢æŸ¥å±¤ç´šå®Œæˆ
                    if is_success:
                        self._check_layer_completion(request.layer, result_data)
                    
                else:
                    debug_log(2, f"[ModuleCoordinator] {request.layer.value}å±¤æ¨¡çµ„ {request.target_module} ç„¡è¿”å›çµæœ")
                    response = ModuleInvocationResponse(
                        target_module=request.target_module,
                        result=InvocationResult.FAILED,  # ç„¡è¿”å›çµæœè¦–ç‚ºå¤±æ•—
                        layer=request.layer,
                        output_data=None,
                        execution_time=execution_time
                    )
                
                # è¨˜éŒ„èª¿ç”¨æ­·å²
                self._invocation_history.append({
                    "timestamp": time.time(),
                    "target_module": request.target_module,
                    "layer": request.layer.value,
                    "source_module": request.source_module,
                    "result": response.result.value,
                    "execution_time": execution_time
                })
                
                # ä¿æŒæ­·å²è¨˜éŒ„åœ¨åˆç†ç¯„åœå…§
                if len(self._invocation_history) > 100:
                    self._invocation_history = self._invocation_history[-50:]
                
                return response
                
            except Exception as e:
                execution_time = time.time() - start_time
                error_msg = f"èª¿ç”¨æ¨¡çµ„å¤±æ•—: {e}"
                error_log(f"[ModuleCoordinator] {error_msg}")
                
                # æ¸…ç†æ´»èºèª¿ç”¨è¨˜éŒ„
                invocation_id = f"{request.target_module}_{int(start_time * 1000)}"
                if invocation_id in self._active_invocations:
                    del self._active_invocations[invocation_id]
                
                return ModuleInvocationResponse(
                    target_module=request.target_module,
                    result=InvocationResult.FAILED,
                    layer=request.layer,
                    error_message=error_msg,
                    execution_time=execution_time
                )
    
    def _check_layer_completion(self, current_layer: ProcessingLayer, result_data: Dict[str, Any]):
        """æª¢æŸ¥ç•¶å‰å±¤æ˜¯å¦å®Œæˆï¼Œæ±ºå®šæ˜¯å¦è§¸ç™¼ä¸‹ä¸€å±¤"""
        try:
            # ç°¡åŒ–ç‰ˆæœ¬ï¼šç›´æ¥æª¢æŸ¥çµæœæ˜¯å¦åŒ…å«éœ€è¦å‚³éçš„æ•¸æ“š
            if result_data and 'response' in result_data:
                debug_log(2, f"[ModuleCoordinator] {current_layer.value}å±¤è™•ç†å®Œæˆï¼Œæº–å‚™è§¸ç™¼ä¸‹ä¸€å±¤")
                # åœ¨å¯¦éš›å¯¦ç¾ä¸­ï¼Œé€™è£¡æœƒæ ¹æ“šå…·é«”é‚è¼¯æ±ºå®šæ˜¯å¦è§¸ç™¼ä¸‹ä¸€å±¤
                # ç›®å‰ç°¡åŒ–ç‚ºæ—¥èªŒè¨˜éŒ„
            
        except Exception as e:
            debug_log(3, f"[ModuleCoordinator] æª¢æŸ¥å±¤ç´šå®Œæˆç‹€æ…‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    def invoke_multiple_modules(self, requests: List[ModuleInvocationRequest]) -> List[ModuleInvocationResponse]:
        """
        æ‰¹é‡èª¿ç”¨å¤šå€‹æ¨¡çµ„
        
        Args:
            requests: æ¨¡çµ„èª¿ç”¨è«‹æ±‚åˆ—è¡¨
            
        Returns:
            List[ModuleInvocationResponse]: èª¿ç”¨å›æ‡‰åˆ—è¡¨
        """
        info_log(f"[ModuleCoordinator] æ‰¹é‡èª¿ç”¨ {len(requests)} å€‹æ¨¡çµ„")
        
        responses = []
        for request in requests:
            response = self.invoke_module(request)
            responses.append(response)
            
            # å¦‚æœæœ‰ä»»ä½•é—œéµæ¨¡çµ„èª¿ç”¨å¤±æ•—ï¼Œè€ƒæ…®çµ‚æ­¢å¾ŒçºŒèª¿ç”¨
            if response.result == InvocationResult.FAILED and request.priority >= 5:
                error_log(f"[ModuleCoordinator] é—œéµæ¨¡çµ„ {request.target_module} èª¿ç”¨å¤±æ•—ï¼Œçµ‚æ­¢å¾ŒçºŒèª¿ç”¨")
                break
        
        return responses
    
    def _log_module_result(self, module_name: str, result_data: Any):
        """è¨˜éŒ„æ¨¡çµ„è¿”å›çµæœçš„è©³ç´°ä¿¡æ¯"""
        try:
            # ç°¡åŒ–æ—¥èªŒï¼šç›´æ¥è¼¸å‡ºæ•´å€‹çµæœå­—å…¸
            debug_log(3, f"[ModuleCoordinator] {module_name} å®Œæ•´è¿”å›çµæœ: {result_data}")
                
        except Exception as e:
            debug_log(3, f"[ModuleCoordinator] è¨˜éŒ„ {module_name} çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    def _extract_response_text(self, processing_data: Dict[str, Any]) -> str:
        """å¾è™•ç†å±¤æ•¸æ“šä¸­æå–æ–‡å­—å›æ‡‰"""
        try:
            # å„ªå…ˆé †åºï¼šresponse > text > content
            if "response" in processing_data:
                return processing_data["response"]
            elif "text" in processing_data:
                return processing_data["text"]
            elif "content" in processing_data:
                return processing_data["content"]
            else:
                # å¦‚æœæ˜¯åµŒå¥—çµæ§‹ï¼Œå˜—è©¦æ·±åº¦æå–
                if isinstance(processing_data, dict):
                    for key in ["llm_output", "result", "data"]:
                        if key in processing_data:
                            nested_data = processing_data[key]
                            if isinstance(nested_data, dict):
                                if "text" in nested_data:
                                    return nested_data["text"]
                                elif "response" in nested_data:
                                    return nested_data["response"]
                
                debug_log(2, f"[ModuleCoordinator] ç„¡æ³•å¾è™•ç†å±¤æ•¸æ“šä¸­æå–æ–‡å­—: {list(processing_data.keys())}")
                return ""
                
        except Exception as e:
            error_log(f"[ModuleCoordinator] æå–å›æ‡‰æ–‡å­—å¤±æ•—: {e}")
            return ""
    
    def get_active_invocations(self) -> Dict[str, Any]:
        """ç²å–ç•¶å‰æ´»èºçš„èª¿ç”¨ç‹€æ…‹"""
        return dict(self._active_invocations)
    
    def get_invocation_stats(self) -> Dict[str, Any]:
        """ç²å–èª¿ç”¨çµ±è¨ˆä¿¡æ¯"""
        if not self._invocation_history:
            return {
                "total_invocations": 0,
                "avg_execution_time": 0.0,
                "success_rate": 0.0,
                "module_stats": {}
            }
        
        total = len(self._invocation_history)
        successful = sum(1 for h in self._invocation_history if h["result"] == "success")
        avg_time = sum(h["execution_time"] for h in self._invocation_history) / total
        
        # æ¨¡çµ„çµ±è¨ˆ
        module_stats = {}
        for history in self._invocation_history:
            module = history["target_module"]
            if module not in module_stats:
                module_stats[module] = {"count": 0, "success": 0, "avg_time": 0.0}
            
            module_stats[module]["count"] += 1
            if history["result"] == "success":
                module_stats[module]["success"] += 1
            module_stats[module]["avg_time"] = (
                module_stats[module]["avg_time"] * (module_stats[module]["count"] - 1) + 
                history["execution_time"]
            ) / module_stats[module]["count"]
        
        return {
            "total_invocations": total,
            "avg_execution_time": avg_time,
            "success_rate": successful / total,
            "active_invocations": len(self._active_invocations),
            "module_stats": module_stats
        }
    
    def get_deduplication_stats(self) -> Dict[str, Any]:
        """
        ç²å–å»é‡çµ±è¨ˆä¿¡æ¯ (G. ç›£æ§èˆ‡é™¤éŒ¯)
        
        Returns:
            åŒ…å«å»é‡å‘½ä¸­æ¬¡æ•¸ã€æ¸…ç†æ¬¡æ•¸ã€æ´»èºéµæ•¸é‡ç­‰è¨ºæ–·ä¿¡æ¯
        """
        with self._dedupe_lock:
            # åˆ†ææ´»èºçš„ dedupe keys
            active_flows = set()
            layers_count = {"INPUT": 0, "PROCESSING": 0, "OUTPUT": 0}
            
            for key in self._layer_dedupe_keys:
                try:
                    parts = key.split(":")
                    if len(parts) >= 3:
                        session_id = parts[0]
                        cycle_index = parts[1]
                        layer = parts[2]
                        
                        flow_id = f"{session_id}:{cycle_index}"
                        active_flows.add(flow_id)
                        
                        if layer in layers_count:
                            layers_count[layer] += 1
                except:
                    pass
            
            return {
                "dedupe_hit_count": self._dedupe_hit_count,
                "cleanup_count": self._cleanup_count,
                "active_dedupe_keys": len(self._layer_dedupe_keys),
                "max_dedupe_keys": self._max_dedupe_keys,
                "active_flows": len(active_flows),
                "layers_distribution": layers_count,
                "memory_pressure": len(self._layer_dedupe_keys) / self._max_dedupe_keys if self._max_dedupe_keys > 0 else 0.0
            }


# å…¨å±€å”èª¿å™¨å¯¦ä¾‹
module_coordinator = ModuleInvocationCoordinator()