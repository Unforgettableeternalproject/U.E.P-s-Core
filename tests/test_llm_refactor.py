#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LLM æ¨¡çµ„é‡æ§‹æ¸¬è©¦è…³æœ¬
æ¸¬è©¦æ–°çš„ CHAT/WORK æ¨¡å¼å’Œæ‰€æœ‰æ–°åŠŸèƒ½
"""

import sys
import os
from pathlib import Path

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°è·¯å¾‘
project_root = Path(__file__).parent.parent  # tests/ çš„ä¸Šä¸€å±¤æ‰æ˜¯å°ˆæ¡ˆæ ¹ç›®éŒ„
sys.path.insert(0, str(project_root))

# å°å…¥å¿…è¦æ¨¡çµ„
from modules.llm_module.llm_module import LLMModule
from modules.llm_module.schemas import LLMInput, LLMOutput
from core.status_manager import status_manager
from utils.debug_helper import info_log, debug_log, error_log

def test_status_manager():
    """æ¸¬è©¦ StatusManager æ•´åˆ"""
    print("\n=== æ¸¬è©¦ StatusManager æ•´åˆ ===")
    
    # ç²å–ç•¶å‰ç‹€æ…‹
    status = status_manager.get_status_dict()
    print(f"ç•¶å‰ç³»çµ±ç‹€æ…‹: {status}")
    
    # æ¸¬è©¦ç‹€æ…‹æ›´æ–°
    status_manager.update_mood(0.1, "æ¸¬è©¦å¿ƒæƒ…æå‡")
    status_manager.update_pride(0.05, "æ¸¬è©¦è‡ªè±ªæ„Ÿæå‡")
    
    # ç²å–å€‹æ€§ä¿®é£¾ç¬¦
    modifiers = status_manager.get_personality_modifiers()
    print(f"å€‹æ€§ä¿®é£¾ç¬¦: {modifiers}")
    
    return True

def test_llm_chat_mode():
    """æ¸¬è©¦ CHAT æ¨¡å¼"""
    print("\n=== æ¸¬è©¦ CHAT æ¨¡å¼ ===")
    
    try:
        # åˆå§‹åŒ– LLM æ¨¡çµ„
        llm = LLMModule()
        if not llm.initialize():
            error_log("LLM æ¨¡çµ„åˆå§‹åŒ–å¤±æ•—")
            return False
            
        # æº–å‚™ CHAT æ¨¡å¼è¼¸å…¥
        chat_input = LLMInput(
            mode="chat",
            text="ä½ å¥½ï¼Œä»Šå¤©å¤©æ°£å¦‚ä½•ï¼Ÿ",
            memory_context="æ˜¨å¤©æˆ‘å€‘èŠéå¤©æ°£è©±é¡Œ",
            identity_context={"name": "æ¸¬è©¦ç”¨æˆ¶", "preferences": ["å‹å–„å°è©±"]}
        )
        
        print(f"è¼¸å…¥: {chat_input.text}")
        print(f"æ¨¡å¼: {chat_input.mode}")
        
        # è™•ç†è«‹æ±‚ 
        result = llm.handle(chat_input.model_dump())
        print(f"å›æ‡‰: {result.get('text', 'No response')}")
        print(f"è™•ç†æ™‚é–“: {result.get('processing_time', 0):.3f}s")
        print(f"æˆåŠŸ: {result.get('success', False)}")
        
        # æ¸¬è©¦å¿«å–åŠŸèƒ½
        print("\n--- æ¸¬è©¦å¿«å–åŠŸèƒ½ ---")
        result2 = llm.handle(chat_input.model_dump())
        print(f"ç¬¬äºŒæ¬¡å›æ‡‰: {result2.get('text', 'No response')}")
        print(f"è™•ç†æ™‚é–“: {result2.get('processing_time', 0):.3f}s")
        
        return result.get('success', False)
        
    except Exception as e:
        error_log(f"CHAT æ¨¡å¼æ¸¬è©¦å¤±æ•—: {e}")
        return False

def test_llm_work_mode():
    """æ¸¬è©¦ WORK æ¨¡å¼"""
    print("\n=== æ¸¬è©¦ WORK æ¨¡å¼ ===")
    
    try:
        llm = LLMModule()
        
        # æº–å‚™ WORK æ¨¡å¼è¼¸å…¥
        work_input = LLMInput(
            mode="work",
            text="å¹«æˆ‘åˆ†æç³»çµ±æ€§èƒ½ä¸¦æä¾›å„ªåŒ–å»ºè­°",
            available_functions="ç³»çµ±æ€§èƒ½åˆ†æåŠŸèƒ½",
            workflow_context={"task_type": "performance_analysis", "priority": "high"}
        )
        
        print(f"è¼¸å…¥: {work_input.text}")
        print(f"æ¨¡å¼: {work_input.mode}")
        print(f"å·¥ä½œå…§å®¹: {work_input.workflow_context}")
        
        # è™•ç†è«‹æ±‚
        result = llm.handle(work_input.model_dump())
        print(f"å›æ‡‰: {result.get('text', 'No response')}")
        print(f"è™•ç†æ™‚é–“: {result.get('processing_time', 0):.3f}s")
        print(f"ç³»çµ±å‹•ä½œ: {result.get('system_action', 'None')}")
        
        return result.get('success', False)
        
    except Exception as e:
        error_log(f"WORK æ¨¡å¼æ¸¬è©¦å¤±æ•—: {e}")
        return False

def test_legacy_compatibility():
    """æ¸¬è©¦å‘å¾Œå…¼å®¹æ€§"""
    print("\n=== æ¸¬è©¦å‘å¾Œå…¼å®¹æ€§ ===")
    
    try:
        llm = LLMModule()
        
        # ä½¿ç”¨èˆŠçš„ intent æ ¼å¼
        legacy_input = {
            "text": "é€™æ˜¯èˆŠç‰ˆæ ¼å¼çš„æ¸¬è©¦",
            "intent": "chat",
            "memory": "ä¸€äº›è¨˜æ†¶å…§å®¹",
            "is_internal": False
        }
        
        print(f"èˆŠç‰ˆè¼¸å…¥: {legacy_input}")
        
        result = llm.handle(legacy_input)
        print(f"å›æ‡‰: {result.get('text', 'No response')}")
        print(f"ç‹€æ…‹: {result.get('status', 'unknown')}")
        
        return result.get('status') == 'ok'
        
    except Exception as e:
        error_log(f"å‘å¾Œå…¼å®¹æ€§æ¸¬è©¦å¤±æ•—: {e}")
        return False

def test_module_status():
    """æ¸¬è©¦æ¨¡çµ„ç‹€æ…‹æŸ¥è©¢"""
    print("\n=== æ¸¬è©¦æ¨¡çµ„ç‹€æ…‹ ===")
    
    try:
        llm = LLMModule()
        status = llm.get_module_status()
        
        print("æ¨¡çµ„ç‹€æ…‹:")
        for key, value in status.items():
            print(f"  {key}: {value}")
            
        return True
        
    except Exception as e:
        error_log(f"æ¨¡çµ„ç‹€æ…‹æ¸¬è©¦å¤±æ•—: {e}")
        return False

def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("é–‹å§‹ LLM æ¨¡çµ„é‡æ§‹æ¸¬è©¦...")
    
    tests = [
        ("StatusManager æ•´åˆ", test_status_manager),
        ("CHAT æ¨¡å¼", test_llm_chat_mode),
        ("WORK æ¨¡å¼", test_llm_work_mode), 
        ("å‘å¾Œå…¼å®¹æ€§", test_legacy_compatibility),
        ("æ¨¡çµ„ç‹€æ…‹", test_module_status)
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            print(f"\n{'='*50}")
            result = test_func()
            results.append((test_name, result))
            print(f"{test_name}: {'âœ… é€šé' if result else 'âŒ å¤±æ•—'}")
        except Exception as e:
            error_log(f"{test_name} æ¸¬è©¦ç•°å¸¸: {e}")
            results.append((test_name, False))
    
    # ç¸½çµ
    print(f"\n{'='*50}")
    print("æ¸¬è©¦çµæœç¸½çµ:")
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for test_name, result in results:
        status = "âœ… é€šé" if result else "âŒ å¤±æ•—" 
        print(f"  {test_name}: {status}")
    
    print(f"\nç¸½è¨ˆ: {passed}/{total} æ¸¬è©¦é€šé")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼LLM æ¨¡çµ„é‡æ§‹æˆåŠŸï¼")
    else:
        print("âš ï¸  æœ‰æ¸¬è©¦å¤±æ•—ï¼Œéœ€è¦æª¢æŸ¥å’Œä¿®å¾©ã€‚")
    
    return passed == total

if __name__ == "__main__":
    main()