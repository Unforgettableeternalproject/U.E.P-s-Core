# U.E.P Core 專案藍圖

Unified Experience Partner (U.E.P) 是一個模組化設計的桌面互動助理系統，結合語音輸入、自然語言理解、大型語言模型推理、情境記憶處理、語音合成與桌面控制等能力，旨在提供自然、直覺、並具個性化的使用體驗。

---

## 一、系統核心架構總覽

```
[User] ─► STT ─► NLP ─► LLM + MEM ─► SYS + TTS ─► UI (overlay)
                                ▲             ▼
                              Snapshot      Voice Output
                                ▼             ▼
                            Memory Flow     MOV + ANI
```

U.E.P 的整體流程包含語音轉文字、指令/聊天辨識、語意推論、功能執行、視覺表現、語音回饋與互動動作六個主要階段，並以模組化形式進行開發與擴充。

---

## 二、模組設計概述與發展路線

### 1. STT Module

* **目前狀態**：採用 `speech_recognition`，支援即時語音轉文字
* **缺少功能**：未支援喚醒詞、聲音活動偵測 (VAD)、使用者辨識
* **未來規劃**：

  * 整合感應式錄製（無需明確關鍵詞即可觸發）
  * 聯動 MEM 模組，自動學習使用者語音特徵以識別身份
  * 支援快取最近錄音音訊，用於 NLP 模組的後處理

### 2. NLP Module

* **目前狀態**：使用 DistilBERT 分類聊天 / 指令 / 無效輸入
* **未來擴充**：

  * 聊天主題辨識與自動命名快照（Topic Labeling）
  * 與 SYS 模組聯動，擷取功能需求資訊（例如檔案/程式名稱）
  * 處理多輪上下文，為 MEM 提供快照整理依據

### 3. MEM Module

* **目前狀態**：RAG + 本地檔案紀錄，記憶摘要回傳給 LLM
* **未來擴充**：

  * 快照管理與主題鏈結（動態追蹤上下文）
  * 建立短期記憶（快取）與長期記憶（資料庫）分層架構
  * 根據 NLP 標記選取最適摘要範圍回傳給 LLM

### 4. LLM Module

* **目前狀態**：與 Gemini 2.0 Flash API 串接，具 System Prompt
* **未來擴充**：

  * 輸入參數化：狀態、任務類型、聊天快照、語者屬性
  * 輸出參數化（JSON）：語氣情緒、SYS 任務、TTS 模式等
  * 支援多模型策略（本地微調 vs 雲端推理）

### 5. TTS Module

* **目前狀態**：Edge TTS 預處理 + RVC 聲音轉換，具 API 架構
* **技術瓶頸**：語速與語調控制不足，處理延遲偏高
* **未來改進**：

  * 最佳化語音生成流程，支援非同步佇列處理
  * 支援語者風格/情緒輸入參數（由 LLM 提供）
  * 預計支援記憶化語者模型（可隨個人風格成長）

### 6. SYS Module

* **目前狀態**：基礎檔案建立、刪除、查找功能
* **未來擴充**：

  * 支援網頁搜尋、行事曆、代辦事項
  * 整合 LLM 系統推理判斷（必要時請求協助）
  * 支援與 TTS/UI 同步運作的時間型任務執行

### 7. UI Module

* **目前狀態**：尚未建立
* **第一階段目標**：建立桌面透明應用 + 放置圖片
* **未來擴充**：

  * 整合使用者控制面板 / 狀態切換頁面
  * 除錯模式面板（顯示 CORE debug log）
  * 管理 overlay、動畫播放與互動區域

### 8. MOV Module

* **目前狀態**：尚未建立
* **階段性目標**：

  1. 控制 U.E.P 視覺物件在桌面移動
  2. 根據輸出內容影響桌面物件（如推開視窗）
  3. 監控滑鼠位置進行追蹤與迴避

### 9. ANI Module

* **目前狀態**：尚未建立
* **任務目標**：

  * 同步動畫與系統事件（語音播報時嘴型動作等）
  * 根據核心狀態（工作、聊天等）切換主動畫序列
  * 支援動畫素材擴充與特效疊加（如心情指數變化）

---

## 三、U.E.P 核心控制層（Core Layer）

### 功能責任：

* 控制模組之間的串接與任務流向
* 管理 U.E.P 的五種狀態（idle, chat, work, mischievous\*, error）
* 收集各模組 log 與執行 trace，協助除錯與統計
* 管理系統模式（例如 單人 vs 多人 / 本地 vs 雲端 / 安靜模式）

### 檔案結構：

| 檔案                 | 功能說明                 |
| ------------------ | -------------------- |
| `controller.py`    | 主任務處理流程控制與資料流串接邏輯    |
| `router.py`        | 模組任務路由與任務類型分派處理器（可選） |
| `registry.py`      | 模組註冊、初始化、動態呼叫模組      |
| `state_manager.py` | 狀態機控管目前情境、主動畫邏輯切換    |

---

## 四、預計開發階段

### ✅ Phase 1：基礎架構與流程整合

* 建立 `core/controller.py` 基礎流程（接收→處理→回應）
* 遷移 STT / NLP / TTS / SYS 初版模組並整合測試
* 完成 `logger.py`、模組註冊與呼叫機制

### 🚧 Phase 2：記憶流與推論優化

* 整合 MEM + LLM + NLP 模組的快照與摘要流
* 實作 LLM 輸出參數化（emotion / command / system\_hint）
* 將 LLM 輸出同步給 TTS + SYS + UI（多向輸出）

### 🎨 Phase 3：前端動態表現與互動

* UI Module 實作基本 overlay 畫面
* MOV 控制初步位置移動 + 邊界偵測
* ANI 管理動畫狀態（idle/chat/work/error）與同步事件

### 🔁 Phase 4：記憶進階功能與使用者識別

* 加入 STT 的使用者語音識別特徵辨識機制
* 導入 MEM 快取 + 長期記憶資料庫管理
* 多使用者記憶分離處理機制（語音與聊天記錄對應）

---

## 五、後續擴充方向建議

* 🤖 支援 Plugin 式外掛功能（類似 Copilot Plugin 設計）
* 📦 模組熱插拔與動態重新載入（搭配 `registry.py`）
* 🎤 本地語音模型 / Whisper-VAD 整合（離線體驗）
* 🧠 使用者模型個性建構（連動 MEM，支援人格成長）
* 📈 整合任務追蹤與系統分析統計模組（可視化）

---

> 本藍圖為 U.E.P Core 系統 2025 年第二季開發起點，後續將根據模組實作進度與技術演進持續修訂。
