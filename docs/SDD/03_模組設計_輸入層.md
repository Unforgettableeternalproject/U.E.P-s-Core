# 第三章:模組設計 - 輸入層 (Module Design - Input Layer)

[← 上一章:核心子系統](./02_核心子系統.md) | [返回主文件](../System%20Design%20Documentation.md) | [下一章:模組設計 - 處理層 →](./04_模組設計_處理層.md)

---

## 3.1 STT 模組 (Speech-to-Text Module)

**檔案位置**: `modules/stt_module/`  
**職責**: 語音轉文字、說話者識別、語音活動偵測

### 3.1.1 模組架構

```
stt_module/
├── stt_module.py                    # 主模組類
├── __init__.py                      # 註冊函數
├── schemas.py                       # Input/Output Schemas
├── config.yaml                      # 模組配置
│
├── vad.py                           # Voice Activity Detection
├── speaker_identification.py       # 說話者識別
├── speaker_context_handler.py      # Working Context 決策處理器
├── smart_keyword_detector.py       # 喚醒詞偵測
│
└── models/whisper-large-v3/         # 本地 Whisper 模型
```

### 3.1.2 核心技術棧

| 技術組件 | 版本/模型 | 用途 |
|:---|:---|:---|
| **Whisper** | `openai/whisper-large-v3` | 語音轉文字 (ASR) |
| **Pyannote** | `pyannote/speaker-diarization-3.1` | 說話者分離 |
| **Embedding Model** | `pyannote/embedding` | 說話者特徵提取 (512-dim) |
| **FAISS** | `faiss-cpu==1.9.0.post1` | 說話者特徵聚類與匹配 |
| **PyAudio** | v0.2.14 | 音訊錄製 |
| **Torchaudio** | (torch dependency) | 音訊處理 |

### 3.1.3 核心功能

1. **Whisper ASR**: 使用 Whisper-large-v3 模型進行語音轉文字
2. **Pyannote 說話者識別**: 提取 512-dim 聲紋特徵進行說話者辨識
3. **VAD (Voice Activity Detection)**: Energy-Based 語音活動偵測
4. **持續監聽模式**: VAD 觸發自動錄製
5. **樣本累積**: Working Context 整合 (累積 15+ 樣本確認身份)

### 3.1.4 Input/Output Schemas

```python
@dataclass
class STTInput(BaseModel):
    """STT 模組輸入"""
    mode: ActivationMode                # MANUAL | CONTINUOUS
    duration: Optional[float] = None    # 錄製時長 (秒)
    language: str = "zh-TW"             # 語言
    enable_speaker_id: bool = True      # 啟用說話者識別
    
@dataclass
class STTOutput(BaseModel):
    """STT 模組輸出"""
    text: str                           # 辨識文字
    confidence: float                   # 信心分數 (0.0-1.0)
    speaker_info: Optional[SpeakerInfo] # 說話者資訊
    should_activate: bool = True        # 是否應該啟動系統
    
@dataclass
class SpeakerInfo:
    """說話者資訊"""
    speaker_id: str                     # 說話者 ID (gs_xxx 或 anonymous)
    confidence: float                   # 識別信心分數
    is_new_speaker: bool                # 是否為新說話者
```

### 3.1.5 說話者識別系統

#### 設計理念

STT 模組的說話者識別系統是 U.E.P 最具技術深度的創新點,採用**多距離度量融合算法**提升識別穩健性。

**為何需要多距離度量？**
- 單一距離度量易受噪音、音量變化影響
- 融合多種距離可提升魯棒性
- 不同距離度量捕捉不同聲音特徵

#### 多距離度量融合

| 距離類型 | 權重 | 用途 |
|:---|:---|:---|
| **Cosine Distance** | 0.3 | 向量夾角相似度 (核心度量) |
| **Euclidean Distance** | 0.3 | 空間距離 (整體相似度) |
| **Magnitude Difference** | 0.2 | 幅度差異 (音量特徵) |
| **Correlation Distance** | 0.2 | 波形相關性 (音色特徵) |

**組合公式**:
```
combined_score = 0.3×cosine + 0.3×euclidean + 0.2×magnitude + 0.2×correlation
```

#### FAISS 聚類與匹配

**聚類算法**: DBSCAN (Density-Based Spatial Clustering)

**關鍵參數**:
- `eps=0.001`: 極小鄰域半徑 (高相似度才分群)
- `min_samples=1`: 最小樣本數
- `metric='precomputed'`: 使用預計算距離矩陣 (組合距離)

**流程**:
```
提取 512-dim 聲紋特徵
    ↓
計算所有樣本間的組合距離
    ↓
DBSCAN 聚類 → 識別說話者
    ↓
匹配現有說話者資料庫
```

#### 樣本累積機制

**Working Context 整合**:
- STT 每次識別到說話者後,將聲紋特徵儲存至 Working Context
- 累積樣本數達到閾值 (15+ 樣本) 時觸發確認
- 確認後創建或更新說話者資料庫

**樣本累積流程**:
```
說話者識別 → Working Context 儲存樣本
    ↓
樣本數 < 15? → 繼續累積
    ↓
樣本數 ≥ 15 → 觸發 SpeakerContextHandler
    ↓
確認身份 → 更新說話者資料庫
```

### 3.1.6 Voice Activity Detection (VAD)

#### Energy-Based VAD

**原理**: 計算音訊視窗能量,與閾值比較判斷是否為語音

**關鍵參數**:
- `energy_threshold=0.0005`: 能量閾值
- `window_size=25ms`: 視窗大小
- `min_speech_duration=0.05s`: 最小語音持續時間

**處理流程**:
```
音訊輸入 → 分割視窗 (25ms)
    ↓
計算各視窗能量 (均方值)
    ↓
能量 > 閾值? → 標記為語音
    ↓
語音持續時間 ≥ 50ms? → 偵測到語音活動
```

### 3.1.7 持續監聽模式

**Continuous Listening 流程**:

```
[監聽開始]
    ↓
錄製音訊片段 (0.5s)
    ↓
VAD 檢測 → 偵測到語音活動?
    ├─ 否 → 繼續監聽
    └─ 是 → 錄製完整語音 (直到靜音)
        ↓
    Whisper ASR + Pyannote 說話者識別
        ↓
    發送至 NLP (直接回調)
        ↓
    停止監聽 (等待系統處理)
```

**為何使用直接回調而非 Event Bus？**
- **低延遲要求**: 語音輸入到回應需儘快完成
- **單一消費者**: 只有 NLP Module 需要 STT 輸出

### 3.1.8 配置參數

| 參數 | 預設值 | 說明 |
|:---|:---|:---|
| `whisper_model_id` | `openai/whisper-large-v3` | Whisper 模型 ID |
| `use_local_model` | `true` | 使用本地模型 |
| `device` | `cuda` | 運算裝置 |
| `language` | `zh-TW` | 語言 |
| `sample_rate` | `16000` | 取樣率 (Hz) |
| `vad_energy_threshold` | `0.0005` | VAD 能量閾值 |
| `speaker_similarity_threshold` | `0.999995` | 說話者相似度閾值 |
| `min_samples_for_recognition` | `15` | 確認身份所需樣本數 |

### 3.1.9 已知問題與改進方向

#### 已知問題
1. **VAD 靜音閾值過短**: 說話中的短暫停頓會被誤判為結束
   - **影響**: 語音被提前截斷
   
2. **TTS-STT 音訊串音**: TTS 播放的殘留音訊會觸發 STT VAD
   - **影響**: 系統自言自語
   - **臨時解法**: TTS 播放期間停用 VAD

#### 改進方向
- 整合更先進的 VAD 模型 (如 Silero VAD)
- 多說話者同時識別支援
- 即時語音轉文字 (Streaming ASR)

---

## 3.2 NLP 模組 (Natural Language Processing Module)

**檔案位置**: `modules/nlp_module/`  
**職責**: 意圖分析、身份管理、狀態決策

### 3.2.1 模組架構

```
nlp_module/
├── nlp_module.py                # 主模組類
├── __init__.py                  # 註冊函數
├── schemas.py                   # Input/Output Schemas
├── config.yaml                  # 模組配置
│
├── identity_manager.py          # 身份管理 (NLP 層)
├── intent_segmenter.py          # Stage 4 意圖分段
├── intent_types.py              # IntentType Enum, IntentSegment
├── bio_tagger.py                # BIO 標註 (實體提取)
└── multi_intent_context.py     # 複合意圖追蹤
```

### 3.2.2 核心技術棧

| 技術組件 | 用途 |
|:---|:---|
| **BIOS Tagger** | 意圖分段 (Stage 4) |
| **IdentityManager** | 使用者身份管理 |
| **Multi-Intent Context** | 複合意圖追蹤 |

### 3.2.3 核心職責

1. **意圖分段與分析**: BIOS Tagger (Stage 4) 進行意圖分段
2. **使用者身份管理**: 說話者 ID → 使用者身份映射
3. **狀態決策權**: **唯一有權決定系統狀態轉換的模組**
4. **路由下一層模組**: 決定調用 MEM/LLM 等模組
5. **發布 INPUT_LAYER_COMPLETE 事件**: 通知 Module Coordinator

### 3.2.4 Input/Output Schemas

```python
@dataclass
class NLPInput(BaseModel):
    """NLP 模組輸入"""
    text: str                           # 輸入文字
    speaker_id: Optional[str] = None    # 說話者 ID (來自 STT)
    enable_identity_processing: bool = True
    
@dataclass
class NLPOutput(BaseModel):
    """NLP 模組輸出"""
    text: str                           # 原始文字
    primary_intent: IntentType          # 主要意圖
    intent_segments: List[IntentSegment] # 意圖分段清單
    identity: Optional[UserProfile]     # 使用者身份
    next_modules: List[str]             # 下一層模組清單
    state_transition: Optional[SystemStateTransition]  # 狀態轉換

class IntentType(Enum):
    """意圖類型"""
    CALL = "call"          # 喚醒呼叫
    CHAT = "chat"          # 對話意圖
    WORK = "work"          # 工作流意圖
    RESPONSE = "response"  # 回應工作流提示
    UNKNOWN = "unknown"    # 未知意圖
```

### 3.2.5 意圖分段系統 (BIOS Tagger - Stage 4)

#### 設計理念

**BIOS Tagger** 採用序列標註方法進行意圖分段:
- **B (Begin)**: 意圖開始
- **I (Inside)**: 意圖內部
- **O (Outside)**: 非意圖
- **S (Separator)**: 分隔符 (如「然後」、「接著」)

#### 分段範例

**輸入**: "幫我搜尋明天的天氣,然後提醒我開會"

**BIOS 標註**:
```
幫我搜尋明天的天氣 → B-WORK I-WORK I-WORK I-WORK I-WORK
,然後                 → S-SEP S-SEP
提醒我開會           → B-WORK I-WORK I-WORK I-WORK
```

**分段結果**:
```python
[
    IntentSegment(
        segment_text="幫我搜尋明天的天氣",
        intent_type=IntentType.WORK,
        confidence=0.92,
        priority="high"
    ),
    IntentSegment(
        segment_text="然後提醒我開會",
        intent_type=IntentType.WORK,
        confidence=0.88,
        priority="high"
    )
]
```

#### 優先級決策規則

| 意圖類型 | 關鍵字條件 | 優先級 |
|:---|:---|:---|
| `CALL` | - | `critical` |
| `RESPONSE` | - | `high` |
| `WORK` | 含「緊急」、「立刻」、「馬上」 | `high` |
| `WORK` | 一般工作流 | `normal` |
| `CHAT` | - | `normal` |
| `UNKNOWN` | - | `low` |

#### 主要意圖選擇邏輯

從多個分段中選擇主要意圖:

1. **優先級最高者**
2. 若優先級相同,選擇**信心分數最高者**
3. 若都相同,選擇**第一個**

### 3.2.6 身份管理 (Identity Management)

#### 設計理念

NLP 層的 IdentityManager 負責:
- 從 Working Context 獲取說話者資訊 (STT 提供)
- 映射說話者 ID → 使用者身份
- 創建新身份 (若需要)

**注意**: 這是 NLP 層的身份管理,與 MEM 層的 IdentityManager (記憶隔離) 不同

#### 身份處理流程

```
STT 識別說話者 → Working Context 儲存
    ↓
NLP IdentityManager 讀取說話者資訊
    ↓
檢查身份映射:
    ├─ 已存在? → 返回 UserProfile
    ├─ 信心分數 ≥ 0.8? → 創建新身份
    └─ 信心分數 < 0.8? → 返回 Anonymous
```

#### UserProfile 結構

```python
@dataclass
class UserProfile:
    """使用者身份資料"""
    identity_id: str                    # 身份 ID (如 "alice")
    speaker_id: str                     # 說話者 ID (如 "gs_alice_001")
    memory_token: str                   # 記憶體存取 Token
    is_confirmed: bool                  # 是否已確認身份
    display_name: Optional[str]         # 顯示名稱
```

### 3.2.7 狀態決策邏輯

**NLP 模組是唯一有權決定系統狀態轉換的模組。**

#### 狀態轉換決策表

| 當前狀態 | 主要意圖 | 目標狀態 |
|:---|:---|:---|
| `IDLE` | `CHAT` | `CHAT` |
| `IDLE` | `WORK` | `WORK` |
| `CHAT` | `WORK` | `WORK` |
| `WORK` | `CHAT` | `CHAT` |
| `CHAT` | `CALL` | `IDLE` |
| `WORK` | `CALL` | `IDLE` |

### 3.2.8 模組路由決策

#### 路由規則

| 主要意圖 | 下一層模組 | 說明 |
|:---|:---|:---|
| `CHAT` | `["mem_module", "llm_module"]` | 檢索記憶 + 生成回應 |
| `WORK` | `["llm_module"]` | LLM 透過 MCP 調用 SYS |
| `RESPONSE` | `["llm_module"]` | 回應工作流提示 |
| `CALL` | `[]` | 僅喚醒系統,無需下一層 |
| `UNKNOWN` | `["llm_module"]` | 讓 LLM 嘗試理解 |

#### 為何 WORK 不直接調用 SYS？

- LLM Module 整合了 **MCP Client**
- LLM 根據使用者意圖決定是否調用 SYS 工具
- 保持模組間鬆耦合

### 3.2.9 事件發布

NLP 完成分析後發布 `INPUT_LAYER_COMPLETE` 事件:

```python
event_bus.publish(
    SystemEvent.INPUT_LAYER_COMPLETE,
    EventData(
        session_id=session_id,
        cycle_index=cycle_index,
        source_module="nlp_module",
        data={
            "primary_intent": "chat",
            "next_modules": ["mem_module", "llm_module"],
            "state_transition": {
                "new_state": "CHAT",
                "priority": "high"
            },
            "identity_id": "alice"
        }
    )
)
```

### 3.2.10 配置參數

| 參數 | 預設值 | 說明 |
|:---|:---|:---|
| `intent_segmentation.confidence_threshold` | `0.7` | 意圖信心閾值 |
| `identity_config.sample_threshold` | `15` | 說話者樣本閾值 |
| `identity_config.confirmation_threshold` | `0.8` | 身份確認閾值 |
| `multi_intent_tracking.enabled` | `true` | 多意圖追蹤 |

### 3.2.11 已知問題與改進方向

#### 已知問題
1. **實體提取未實現**: BIO Tagger 僅定義介面,未實際實作
2. **Stage 3 IntentAnalyzer 已棄用**: 保留用於向後相容,應移除
3. **狀態佇列重複添加**: 多次 CHAT 意圖會重複添加到狀態佇列

#### 改進方向
- 整合預訓練 NLU 模型 (如 BERT-based)
- 支援多語言意圖分析
- 實作完整的實體提取系統

---

## 總結 (Summary)

本章節說明了輸入層的兩個核心模組:

✅ **STT 模組**:
- Whisper-large-v3 ASR (語音轉文字)
- Pyannote 說話者識別 (多距離度量融合)
- FAISS DBSCAN 聚類與匹配
- Energy-Based VAD (語音活動偵測)
- 持續監聽模式
- Working Context 樣本累積機制

✅ **NLP 模組**:
- BIOS Tagger 意圖分段 (Stage 4)
- 使用者身份管理 (IdentityManager)
- 狀態決策權 (IDLE → CHAT/WORK)
- 模組路由決策
- INPUT_LAYER_COMPLETE 事件發布

這兩個模組共同構成系統的感知層,將使用者的語音或文字輸入轉換為結構化的意圖資訊,並驅動後續的處理層執行。

---

[← 上一章:核心子系統](./02_核心子系統.md) | [返回主文件](../System%20Design%20Documentation.md) | [下一章:模組設計 - 處理層 →](./04_模組設計_處理層.md)
