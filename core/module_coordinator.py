"""
æ¨¡çµ„èª¿ç”¨å”èª¿å™¨ - è² è²¬ç³»çµ±å±¤çš„æ¨¡çµ„é–“èª¿ç”¨é‚è¼¯
å¯¦ç¾å®Œæ•´çš„ä¸‰å±¤æ¶æ§‹ï¼šè¼¸å…¥å±¤ â†’ è™•ç†å±¤ â†’ è¼¸å‡ºå±¤
æ ¹æ“š docs/å®Œæ•´ç³»çµ±æµç¨‹æ–‡æª”.md ä¸­å®šç¾©çš„åˆ†å±¤æ¶æ§‹

=== Flow-Based å»é‡æ©Ÿåˆ¶ ===
ç‚ºé˜²æ­¢äº‹ä»¶é‡è¤‡è™•ç†,æ¡ç”¨ flow-based å»é‡ç­–ç•¥:

1. Flow ID = session_id + cycle_index
   - session_id: GS (General Session) ID,ä¸æ˜¯æ¨¡çµ„å±¤ç´šçš„ CS/WS
   - cycle_index: ç³»çµ±å¾ªç’°è¨ˆæ•¸å™¨ (æ¯æ¬¡å°è©±å¾€è¿” +1)

2. Dedupe Key = flow_id + layer
   æ ¼å¼: "{session_id}:{cycle_index}:{layer}"
   ç¤ºä¾‹: "gs_20231013_001:7:PROCESSING"

3. ç”Ÿå‘½é€±æœŸç®¡ç†:
   - CYCLE_COMPLETED: æ¸…ç†ç•¶å‰ cycle çš„æ‰€æœ‰ layer éµ
   - SESSION_ENDED: æ¸…ç†æ•´å€‹ session çš„æ‰€æœ‰éµ
   - ä¿è­·æ€§æ¸…ç†: è¶…é 2000 å€‹éµæ™‚è‡ªå‹•æ¸…ç†ä¸€åŠ

4. æœƒè©±å±¤ç´šèªªæ˜:
   - GS (General Session): ç³»çµ±ç´šæœƒè©±,è·¨è¶Šæ•´å€‹å°è©±ç”Ÿå‘½é€±æœŸ
   - CS (Chatting Session): å°è©±æœƒè©±,MEM æ¨¡çµ„ä½¿ç”¨
   - WS (Workflow Session): å·¥ä½œæµæœƒè©±,LLM å’Œ SYS æ¨¡çµ„ä½¿ç”¨
   - æœ¬å”èª¿å™¨ä½¿ç”¨ GS ä½œç‚ºå»é‡çš„ session_id
   
è¨»: LLM æ˜¯å…©å€‹é‚è¼¯ç³»çµ± (å°è©±/å·¥ä½œæµ) çš„ä¸­æ¨
"""

import time
import threading
from typing import Dict, Any, Optional, List
from dataclasses import dataclass
from enum import Enum

from utils.debug_helper import debug_log, info_log, error_log


class ProcessingLayer(Enum):
    """è™•ç†å±¤ç´šå®šç¾©"""
    INPUT = "input"          # è¼¸å…¥å±¤ï¼šSTT, NLP
    PROCESSING = "processing"  # è™•ç†å±¤ï¼šMEM, LLM, SYS
    OUTPUT = "output"        # è¼¸å‡ºå±¤ï¼šTTS


class InvocationResult(Enum):
    """èª¿ç”¨çµæœç‹€æ…‹"""
    SUCCESS = "success"
    FAILED = "failed"
    SKIPPED = "skipped"
    NO_TARGET = "no_target"


@dataclass
class LayerTransition:
    """å±¤ç´šè½‰æ›è«‹æ±‚"""
    from_layer: ProcessingLayer
    to_layer: ProcessingLayer
    data: Dict[str, Any]
    source_module: str
    reasoning: str


@dataclass
class ModuleInvocationRequest:
    """æ¨¡çµ„èª¿ç”¨è«‹æ±‚"""
    target_module: str
    input_data: Dict[str, Any]
    source_module: str
    reasoning: str
    layer: ProcessingLayer
    priority: int = 1
    timeout: float = 30.0


@dataclass
class ModuleInvocationResponse:
    """æ¨¡çµ„èª¿ç”¨å›æ‡‰"""
    target_module: str
    result: InvocationResult
    layer: ProcessingLayer
    output_data: Optional[Dict[str, Any]] = None
    error_message: Optional[str] = None
    execution_time: float = 0.0


class ModuleInvocationCoordinator:
    """æ¨¡çµ„èª¿ç”¨å”èª¿å™¨ - å¯¦ç¾å®Œæ•´ä¸‰å±¤æ¶æ§‹çš„æ¨¡çµ„é–“èª¿ç”¨ç®¡ç†"""
    
    # å®šç¾©æ¨¡çµ„æ‰€å±¬å±¤ç´š
    MODULE_LAYERS = {
        'stt': ProcessingLayer.INPUT,
        'nlp': ProcessingLayer.INPUT,
        'mem': ProcessingLayer.PROCESSING,
        'llm': ProcessingLayer.PROCESSING,
        'sys': ProcessingLayer.PROCESSING,
        'tts': ProcessingLayer.OUTPUT
    }
    
    def __init__(self):
        """åˆå§‹åŒ–å”èª¿å™¨"""
        self._invocation_lock = threading.Lock()
        self._active_invocations = {}
        self._invocation_history = []
        self._layer_transitions = []
        
        # æ–°çš„å»é‡æ©Ÿåˆ¶: flow_id + layer
        # dedupe_key = f"{session_id}:{cycle_index}:{layer}"
        self._layer_dedupe_keys = set()  # å±¤ç´šå»é‡é›†åˆ
        self._dedupe_lock = threading.Lock()
        self._max_dedupe_keys = 2000  # æœ€å¤šä¿ç•™ 2000 å€‹å»é‡éµ
        
        # çµ±è¨ˆä¿¡æ¯
        self._dedupe_hit_count = 0
        self._cleanup_count = 0
        
        # æœƒè©±çµæŸç®¡ç† - é›™æ¢ä»¶çµ‚æ­¢æ©Ÿåˆ¶
        self._pending_session_end = None  # æ¨™è¨˜æœƒè©±çµæŸè«‹æ±‚ï¼Œç­‰å¾… CYCLE_COMPLETED
        
        info_log("[ModuleCoordinator] ä¸‰å±¤æ¶æ§‹æ¨¡çµ„èª¿ç”¨å”èª¿å™¨åˆå§‹åŒ–")
        info_log("[ModuleCoordinator] ä½¿ç”¨ flow-based å»é‡ç­–ç•¥ (session_id:cycle_index:layer)")
        
        # âœ… è¨‚é–±äº‹ä»¶ç¸½ç·š
        self._setup_event_subscriptions()
    
    def _setup_event_subscriptions(self):
        """è¨­ç½®äº‹ä»¶è¨‚é–± - äº‹ä»¶é©…å‹•æ¶æ§‹çš„æ ¸å¿ƒ"""
        try:
            from core.event_bus import event_bus, SystemEvent
            
            info_log("[ModuleCoordinator] é–‹å§‹è¨‚é–±äº‹ä»¶ç¸½ç·š...")
            
            # è¨‚é–±è¼¸å…¥å±¤å®Œæˆäº‹ä»¶
            event_bus.subscribe(
                SystemEvent.INPUT_LAYER_COMPLETE,
                self._on_input_layer_complete,
                handler_name="ModuleCoordinator.input_complete"
            )
            info_log(f"[ModuleCoordinator] âœ“ å·²è¨‚é–± INPUT_LAYER_COMPLETE")
            
            # è¨‚é–±è™•ç†å±¤å®Œæˆäº‹ä»¶
            event_bus.subscribe(
                SystemEvent.PROCESSING_LAYER_COMPLETE,
                self._on_processing_layer_complete,
                handler_name="ModuleCoordinator.processing_complete"
            )
            info_log(f"[ModuleCoordinator] âœ“ å·²è¨‚é–± PROCESSING_LAYER_COMPLETE")
            
            # è¨‚é–±å¾ªç’°å®Œæˆäº‹ä»¶ (ç”¨æ–¼æ¸…ç†å»é‡éµ)
            event_bus.subscribe(
                SystemEvent.CYCLE_COMPLETED,
                self._on_cycle_completed,
                handler_name="ModuleCoordinator.cycle_complete"
            )
            info_log(f"[ModuleCoordinator] âœ“ å·²è¨‚é–± CYCLE_COMPLETED")
            
            # è¨‚é–±ç‹€æ…‹ä½‡åˆ—æ¨é€²äº‹ä»¶ (è·³éè¼¸å…¥å±¤ï¼Œç›´æ¥å•Ÿå‹•è™•ç†å±¤)
            event_bus.subscribe(
                SystemEvent.STATE_ADVANCED,
                self._on_state_advanced,
                handler_name="ModuleCoordinator.state_advanced"
            )
            info_log(f"[ModuleCoordinator] âœ“ å·²è¨‚é–± STATE_ADVANCED")
            
            # è¨‚é–±æœƒè©±çµæŸäº‹ä»¶ (ç”¨æ–¼æ¸…ç†å»é‡éµ)
            event_bus.subscribe(
                SystemEvent.SESSION_ENDED,
                self._on_session_ended,
                handler_name="ModuleCoordinator.session_end"
            )
            info_log(f"[ModuleCoordinator] âœ“ å·²è¨‚é–± SESSION_ENDED")
            
            # âœ… è¨‚é–±ç³»çµ±é€šçŸ¥äº‹ä»¶ (ç›´æ¥è™•ç†ï¼Œä¸ç¶“éç‹€æ…‹ä½‡åˆ—)
            event_bus.subscribe(SystemEvent.TODO_OVERDUE, self._on_todo_notification)
            event_bus.subscribe(SystemEvent.TODO_UPCOMING, self._on_todo_notification)
            event_bus.subscribe(SystemEvent.CALENDAR_EVENT_STARTING, self._on_calendar_notification)
            event_bus.subscribe(SystemEvent.REMINDER_TRIGGERED, self._on_reminder_notification)
            event_bus.subscribe(SystemEvent.SYSTEM_STARTUP_REPORT, self._on_startup_report)
            info_log(f"[ModuleCoordinator] âœ“ å·²è¨‚é–±ç³»çµ±é€šçŸ¥äº‹ä»¶ (5 å€‹)")
            
            info_log("[ModuleCoordinator] âœ… äº‹ä»¶è¨‚é–±å®Œæˆ (9 å€‹äº‹ä»¶)")
            
        except Exception as e:
            error_log(f"[ModuleCoordinator] âŒ äº‹ä»¶è¨‚é–±å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
    
    def _on_input_layer_complete(self, event):
        """
        è¼¸å…¥å±¤å®Œæˆäº‹ä»¶è™•ç†å™¨
        ç•¶ NLP ç™¼å¸ƒ INPUT_LAYER_COMPLETE äº‹ä»¶æ™‚è§¸ç™¼
        ä½¿ç”¨ flow-based å»é‡: session_id + cycle_index + layer
        
        æ³¨æ„: é€™è£¡çš„ session_id æ˜¯ GS (General Session),
              ä¸æ˜¯æ¨¡çµ„å±¤ç´šçš„ CS (MEM) æˆ– WS (LLM/SYS)
        """
        try:
            # æå– flow è­˜åˆ¥è³‡è¨Š (ä¾†è‡ª General Session)
            session_id = event.data.get('session_id', 'unknown')  # GS ID
            cycle_index = event.data.get('cycle_index', -1)
            
            # æ§‹å»ºå»é‡éµ: flow_id + layer
            dedupe_key = f"{session_id}:{cycle_index}:INPUT"
            
            # æª¢æŸ¥æ˜¯å¦å·²è™•ç†éæ­¤ flow çš„æ­¤ layer
            with self._dedupe_lock:
                if dedupe_key in self._layer_dedupe_keys:
                    self._dedupe_hit_count += 1
                    debug_log(2, f"[ModuleCoordinator] âš ï¸ è·³éé‡è¤‡è™•ç† (dedupe_key={dedupe_key}, å‘½ä¸­æ¬¡æ•¸={self._dedupe_hit_count})")
                    return
                
                # æ¨™è¨˜ç‚ºå·²è™•ç†
                self._layer_dedupe_keys.add(dedupe_key)
                debug_log(3, f"[ModuleCoordinator] âœ“ å·²è¨˜éŒ„å»é‡éµ: {dedupe_key} (å…± {len(self._layer_dedupe_keys)} å€‹)")
                
                # ä¿è­·æ€§æ¸…ç†: é¿å…é›†åˆç„¡é™å¢é•·
                if len(self._layer_dedupe_keys) > self._max_dedupe_keys:
                    removed_count = len(self._layer_dedupe_keys) - (self._max_dedupe_keys // 2)
                    keys_to_remove = list(self._layer_dedupe_keys)[:(self._max_dedupe_keys // 2)]
                    for old_key in keys_to_remove:
                        self._layer_dedupe_keys.discard(old_key)
                    self._cleanup_count += removed_count
                    debug_log(3, f"[ModuleCoordinator] ä¿è­·æ€§æ¸…ç†: ç§»é™¤ {removed_count} å€‹èˆŠéµ")
            
            info_log(f"[ModuleCoordinator] ğŸ¯ æ”¶åˆ°è¼¸å…¥å±¤å®Œæˆäº‹ä»¶ (flow={session_id}:{cycle_index}, event_id={event.event_id})")
            debug_log(2, f"[ModuleCoordinator] äº‹ä»¶æ•¸æ“š: {list(event.data.keys())}")
            self.handle_layer_completion(ProcessingLayer.INPUT, event.data)
                    
        except Exception as e:
            error_log(f"[ModuleCoordinator] âŒ è™•ç†è¼¸å…¥å±¤å®Œæˆäº‹ä»¶å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
    
    def _on_state_advanced(self, event):
        """
        ç‹€æ…‹ä½‡åˆ—æ¨é€²äº‹ä»¶è™•ç†å™¨
        ç•¶ StateQueue ç™¼å¸ƒ STATE_ADVANCED äº‹ä»¶æ™‚è§¸ç™¼ï¼Œç›´æ¥å•Ÿå‹•è™•ç†å±¤ï¼ˆè·³éè¼¸å…¥å±¤ï¼‰
        
        é€™æ˜¯ Cycle 0 çš„æ­£ç¢ºè§¸ç™¼æ–¹å¼ï¼š
        - ç‹€æ…‹ä½‡åˆ—æ¨é€²æ™‚ä¸éœ€è¦ç¶“éè¼¸å…¥å±¤ï¼ˆSTT/NLPï¼‰
        - ç›´æ¥ä½¿ç”¨ä½‡åˆ—é …ç›®çš„ context_content å•Ÿå‹•è™•ç†å±¤
        - éµå¾ªäº‹ä»¶é©…å‹•æ¶æ§‹ï¼Œä¸ä½¿ç”¨ç›´æ¥èª¿ç”¨çš„æ·å¾‘
        """
        try:
            new_state = event.data.get('new_state')
            content = event.data.get('content', '')
            metadata = event.data.get('metadata', {})
            cycle_index = event.data.get('cycle_index', 0)
            
            info_log(f"[ModuleCoordinator] ğŸš€ æ”¶åˆ° STATE_ADVANCED äº‹ä»¶: {new_state}, Cycle {cycle_index}")
            debug_log(2, f"[ModuleCoordinator] å…§å®¹: {content[:100]}...")
            
            # ç²å–ç•¶å‰ GS (ç”¨æ–¼ flow-based å»é‡)
            from core.sessions.session_manager import session_manager
            current_gs = session_manager.get_current_general_session()
            session_id = current_gs.session_id if current_gs else 'unknown'
            
            # âœ… ç›´æ¥ä½¿ç”¨äº‹ä»¶ä¸­çš„ cycle_indexï¼Œç”± StateQueue åœ¨ç™¼å¸ƒæ™‚è¨ˆç®—
            # StateQueue æœƒè®€å–ç•¶å‰ cycle ä¸¦ +1ï¼Œç¢ºä¿ä½¿ç”¨æ­£ç¢ºçš„ä¸‹ä¸€å€‹å¾ªç’°ç´¢å¼•
            debug_log(2, f"[ModuleCoordinator] ä½¿ç”¨ StateQueue æä¾›çš„ cycle_index: {cycle_index}")
            
            # æ§‹å»ºè™•ç†å±¤è¼¸å…¥ï¼ˆæ¨¡æ“¬è¼¸å…¥å±¤å®Œæˆçš„æ ¼å¼ï¼‰
            processing_input = {
                "text": content,
                "session_id": session_id,  # GS ID for flow tracking
                "cycle_index": cycle_index,  # Use cycle index from StateQueue
                "system_initiated": True,  # æ¨™è¨˜ç‚ºç³»çµ±ç™¼èµ·
                "queue_initiated": True,  # æ¨™è¨˜ç‚ºä½‡åˆ—æ¨é€²
                "metadata": metadata,
                # æ¨¡æ“¬ NLP çµæœï¼ˆæ ¹æ“šç›®æ¨™ç‹€æ…‹æ±ºå®šæ„åœ–ï¼‰
                "nlp_result": {
                    "primary_intent": "chat" if new_state == "chat" else "work",
                    "overall_confidence": 1.0,
                    "segments": [],
                    "state_advanced": True  # ç‰¹æ®Šæ¨™è¨˜
                }
            }
            
            # ç›´æ¥è§¸ç™¼è™•ç†å±¤ï¼ˆä½¿ç”¨çµ±ä¸€çš„ handle_layer_completion å…¥å£ï¼‰
            debug_log(2, "[ModuleCoordinator] è·³éè¼¸å…¥å±¤ï¼Œç›´æ¥å•Ÿå‹•è™•ç†å±¤...")
            self.handle_layer_completion(ProcessingLayer.INPUT, processing_input)
            
        except Exception as e:
            error_log(f"[ModuleCoordinator] âŒ è™•ç† STATE_ADVANCED äº‹ä»¶å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
    
    def _on_processing_layer_complete(self, event):
        """
        è™•ç†å±¤å®Œæˆäº‹ä»¶è™•ç†å™¨
        ç•¶ LLM ç™¼å¸ƒ PROCESSING_LAYER_COMPLETE äº‹ä»¶æ™‚è§¸ç™¼
        ä½¿ç”¨ flow-based å»é‡: session_id + cycle_index + layer
        
        æ³¨æ„: é€™è£¡çš„ session_id æ˜¯ GS (General Session),
              ä¸æ˜¯æ¨¡çµ„å±¤ç´šçš„ CS (MEM) æˆ– WS (LLM/SYS)
        """
        try:
            # æå– flow è­˜åˆ¥è³‡è¨Š (ä¾†è‡ª General Session)
            session_id = event.data.get('session_id', 'unknown')  # GS ID
            cycle_index = event.data.get('cycle_index', -1)
            
            # æ§‹å»ºå»é‡éµ: flow_id + layer
            dedupe_key = f"{session_id}:{cycle_index}:PROCESSING"
            
            # æª¢æŸ¥æ˜¯å¦å·²è™•ç†éæ­¤ flow çš„æ­¤ layer
            with self._dedupe_lock:
                if dedupe_key in self._layer_dedupe_keys:
                    self._dedupe_hit_count += 1
                    debug_log(2, f"[ModuleCoordinator] âš ï¸ è·³éé‡è¤‡è™•ç† (dedupe_key={dedupe_key}, å‘½ä¸­æ¬¡æ•¸={self._dedupe_hit_count})")
                    return
                
                # æ¨™è¨˜ç‚ºå·²è™•ç†
                self._layer_dedupe_keys.add(dedupe_key)
                debug_log(3, f"[ModuleCoordinator] âœ“ å·²è¨˜éŒ„å»é‡éµ: {dedupe_key} (å…± {len(self._layer_dedupe_keys)} å€‹)")
                
                # ä¿è­·æ€§æ¸…ç†
                if len(self._layer_dedupe_keys) > self._max_dedupe_keys:
                    removed_count = len(self._layer_dedupe_keys) - (self._max_dedupe_keys // 2)
                    keys_to_remove = list(self._layer_dedupe_keys)[:(self._max_dedupe_keys // 2)]
                    for old_key in keys_to_remove:
                        self._layer_dedupe_keys.discard(old_key)
                    self._cleanup_count += removed_count
                    debug_log(3, f"[ModuleCoordinator] ä¿è­·æ€§æ¸…ç†: ç§»é™¤ {removed_count} å€‹èˆŠéµ")
            
            info_log(f"[ModuleCoordinator] ğŸ¯ æ”¶åˆ°è™•ç†å±¤å®Œæˆäº‹ä»¶ (flow={session_id}:{cycle_index}, event_id={event.event_id})")
            debug_log(2, f"[ModuleCoordinator] äº‹ä»¶æ•¸æ“š: {list(event.data.keys())}")
            self.handle_layer_completion(ProcessingLayer.PROCESSING, event.data)
                    
        except Exception as e:
            error_log(f"[ModuleCoordinator] âŒ è™•ç†è™•ç†å±¤å®Œæˆäº‹ä»¶å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
    
    def _on_cycle_completed(self, event):
        """
        å¾ªç’°å®Œæˆäº‹ä»¶è™•ç†å™¨
        
        è™•ç†å…©å€‹ä»»å‹™ï¼š
        1. æ¸…ç†å»é‡éµ - ç§»é™¤å·²å®Œæˆ cycle çš„æ‰€æœ‰ layer éµ
        2. æª¢æŸ¥æœƒè©±çµæŸ - é›™æ¢ä»¶çµ‚æ­¢æ©Ÿåˆ¶çš„ç¬¬äºŒå€‹æ¢ä»¶
        
        æ³¨æ„: é€™è£¡çš„ session_id æ˜¯ GS (General Session)
        """
        try:
            session_id = event.data.get('session_id', 'unknown')  # GS ID
            cycle_index = event.data.get('cycle_index', -1)
            flow_prefix = f"{session_id}:{cycle_index}:"
            
            # ä»»å‹™ 1: æ¸…ç†å»é‡éµ
            with self._dedupe_lock:
                # æ‰¾å‡ºä¸¦ç§»é™¤æ­¤ flow çš„æ‰€æœ‰ layer éµ
                keys_to_remove = [k for k in self._layer_dedupe_keys if k.startswith(flow_prefix)]
                for key in keys_to_remove:
                    self._layer_dedupe_keys.discard(key)
                
                self._cleanup_count += len(keys_to_remove)
                info_log(f"[ModuleCoordinator] ğŸ§¹ CYCLE_COMPLETED æ¸…ç†: ç§»é™¤ {len(keys_to_remove)} å€‹å»é‡éµ (flow={session_id}:{cycle_index})")
                debug_log(3, f"[ModuleCoordinator] å‰©é¤˜å»é‡éµæ•¸é‡: {len(self._layer_dedupe_keys)}")
            
            # ä»»å‹™ 2: æª¢æŸ¥æœƒè©±çµæŸè«‹æ±‚ï¼ˆé›™æ¢ä»¶çµ‚æ­¢æ©Ÿåˆ¶ï¼‰
            if self._pending_session_end:
                pending = self._pending_session_end
                pending_gs_id = pending.get('gs_id')
                
                # æª¢æŸ¥æ˜¯å¦æ˜¯åŒä¸€å€‹ GS
                if pending_gs_id == session_id:
                    reason = pending.get('reason', 'LLM requested')
                    info_log(f"[ModuleCoordinator] âœ… é›™æ¢ä»¶çµ‚æ­¢æ©Ÿåˆ¶æ»¿è¶³ï¼š")
                    info_log(f"  â””â”€ æ¢ä»¶ 1: å¤–éƒ¨ä¸­æ–·é» (LLM session_control) âœ…")
                    info_log(f"  â””â”€ æ¢ä»¶ 2: å¾ªç’°çµæŸ (CYCLE_COMPLETED) âœ…")
                    info_log(f"[ModuleCoordinator] ç¾åœ¨åŸ·è¡Œæœƒè©±çµæŸ (gs_id={session_id}, reason={reason})")
                    
                    # åŸ·è¡Œæœƒè©±çµæŸ
                    self._handle_session_end(pending.get('session_control'))
                    
                    # æ¸…é™¤æ¨™è¨˜
                    self._pending_session_end = None
                else:
                    debug_log(2, f"[ModuleCoordinator] æœƒè©±çµæŸæ¨™è¨˜çš„ gs_id ({pending_gs_id}) èˆ‡ç•¶å‰å¾ªç’°çš„ gs_id ({session_id}) ä¸åŒ¹é…ï¼Œç¹¼çºŒç­‰å¾…")
                
        except Exception as e:
            error_log(f"[ModuleCoordinator] âŒ è™•ç†å¾ªç’°å®Œæˆäº‹ä»¶å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
    
    def _on_session_ended(self, event):
        """
        æœƒè©±çµæŸäº‹ä»¶è™•ç†å™¨
        æ¸…ç†æ•´å€‹ session çš„å»é‡éµ
        
        æ³¨æ„: é€™è£¡çš„ session_id æ˜¯ GS (General Session)
              ç•¶ GS çµæŸæ™‚,å…¶ä¸‹çš„æ‰€æœ‰ CS (MEM) å’Œ WS (LLM/SYS) ä¹Ÿéƒ½çµæŸäº†
        """
        try:
            session_id = event.data.get('session_id', 'unknown')  # GS ID
            session_prefix = f"{session_id}:"
            
            with self._dedupe_lock:
                # æ‰¾å‡ºä¸¦ç§»é™¤æ­¤ session çš„æ‰€æœ‰éµ
                keys_to_remove = [k for k in self._layer_dedupe_keys if k.startswith(session_prefix)]
                for key in keys_to_remove:
                    self._layer_dedupe_keys.discard(key)
                
                self._cleanup_count += len(keys_to_remove)
                info_log(f"[ModuleCoordinator] ğŸ§¹ SESSION_ENDED æ¸…ç†: ç§»é™¤ {len(keys_to_remove)} å€‹å»é‡éµ (session={session_id})")
                debug_log(3, f"[ModuleCoordinator] å‰©é¤˜å»é‡éµæ•¸é‡: {len(self._layer_dedupe_keys)}")
                debug_log(3, f"[ModuleCoordinator] çµ±è¨ˆ - å‘½ä¸­æ¬¡æ•¸: {self._dedupe_hit_count}, æ¸…ç†æ¬¡æ•¸: {self._cleanup_count}")
                
        except Exception as e:
            error_log(f"[ModuleCoordinator] âŒ è™•ç†æœƒè©±çµæŸäº‹ä»¶å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_layer_completion(self, layer: ProcessingLayer, completion_data: Dict[str, Any]) -> bool:
        """
        è™•ç†å±¤ç´šå®Œæˆé€šçŸ¥ï¼Œå”èª¿ä¸‹ä¸€å±¤è™•ç†
        
        Args:
            layer: å®Œæˆçš„å±¤ç´š
            completion_data: å®Œæˆæ•¸æ“š
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸè§¸ç™¼ä¸‹ä¸€å±¤è™•ç†
        """
        try:
            info_log(f"[ModuleCoordinator] {layer.value}å±¤å®Œæˆï¼Œå”èª¿ä¸‹ä¸€å±¤è™•ç†")
            debug_log(2, f"[ModuleCoordinator] å®Œæˆæ•¸æ“š: {list(completion_data.keys())}")
            
            # æ ¹æ“šç•¶å‰å±¤æ±ºå®šä¸‹ä¸€å±¤è™•ç†
            if layer == ProcessingLayer.INPUT:
                return self._transition_to_processing_layer(completion_data)
            elif layer == ProcessingLayer.PROCESSING:
                return self._transition_to_output_layer(completion_data)
            else:
                debug_log(2, f"[ModuleCoordinator] {layer.value}å±¤æ˜¯æœ€çµ‚å±¤ï¼Œç„¡éœ€é€²ä¸€æ­¥è™•ç†")
                return True
                
        except Exception as e:
            error_log(f"[ModuleCoordinator] è™•ç†{layer.value}å±¤å®Œæˆå¤±æ•—: {e}")
            return False
    
    def _transition_to_processing_layer(self, input_data: Dict[str, Any]) -> bool:
        """è¼¸å…¥å±¤ â†’ è™•ç†å±¤è½‰æ›
        
        é‡è¦æ¶æ§‹è¨­è¨ˆï¼š
        - ä¸ä½¿ç”¨ Routerï¼ˆRouter ä¾è³´ç³»çµ±ç‹€æ…‹ï¼Œè€Œç‹€æ…‹å°šæœªè½‰æ›ï¼‰
        - ç›´æ¥å¾ NLP çµæœçš„ primary_intent æ±ºå®šè™•ç†å±¤è·¯å¾‘
        - WORK â†’ LLM + SYS, CHAT â†’ MEM + LLM
        """
        try:
            info_log("[ModuleCoordinator] è¼¸å…¥å±¤ â†’ è™•ç†å±¤è½‰æ›")
            
            # å¾ NLP çµæœç²å–ä¸»è¦æ„åœ–
            nlp_result = input_data.get('nlp_result', {})
            
            # ğŸ” èª¿è©¦ï¼šæª¢æŸ¥ input_data çš„æ‰€æœ‰éµ
            debug_log(2, f"[ModuleCoordinator] input_data keys: {list(input_data.keys())}")
            # ğŸ” èª¿è©¦ï¼šæª¢æŸ¥ nlp_result çš„æ‰€æœ‰éµ
            debug_log(2, f"[ModuleCoordinator] nlp_result keys: {list(nlp_result.keys())}")
            
            primary_intent = nlp_result.get('primary_intent')
            
            # ğŸ†• æª¢æŸ¥ NLP çš„ session_controlï¼ˆèˆ‡ LLM ä¸åŒï¼šNLP ç«‹å³çµæŸå¾ªç’°ï¼‰
            # 
            # LLM (è™•ç†å±¤) session_control: ç­‰å¾… CYCLE_COMPLETEDï¼ˆé›™æ¢ä»¶çµ‚æ­¢ï¼‰
            # NLP (è¼¸å…¥å±¤) session_control: ç«‹å³åŸ·è¡Œæœƒè©±çµæŸä¸¦çµæŸå¾ªç’°
            # 
            # åŸå› ï¼šNLP åœ¨è¼¸å…¥å±¤å°±åµæ¸¬åˆ°éœ€è¦ä¸­æ–· CSï¼ˆå¦‚ DWï¼‰ï¼Œ
            #      ä¸éœ€è¦ç¶“éè™•ç†å±¤å’Œè¼¸å‡ºå±¤ï¼Œç›´æ¥çµæŸæœƒè©±ä¸¦é€²å…¥ä¸‹ä¸€å€‹å¾ªç’°
            session_control = nlp_result.get('session_control')
            if session_control:
                debug_log(2, f"[ModuleCoordinator] NLP session_control: {session_control}")
                
                # æª¢æŸ¥æ˜¯å¦æ‡‰è©²çµæŸæœƒè©±
                should_end = (session_control.get('action') == 'end_session' or 
                             session_control.get('should_end_session') is True)
                
                if should_end:
                    reason = session_control.get('reason', 'NLP requested')
                    info_log(f"[ModuleCoordinator] ğŸ”š NLP è«‹æ±‚çµæŸæœƒè©± (åŸå› : {reason})")
                    
                    # âœ… ç«‹å³åŸ·è¡Œæœƒè©±çµæŸï¼ˆä¸ç­‰å¾… CYCLE_COMPLETEDï¼‰
                    self._handle_session_end(session_control)
                    
                    # ğŸ†• æ¨™è¨˜ç•¶å‰ç‹€æ…‹ç‚ºå®Œæˆï¼Œä»¥ä¾¿ä¸‹æ¬¡å¾ªç’°å¯ä»¥æ¨é€²
                    from core.states.state_queue import get_state_queue_manager
                    state_queue = get_state_queue_manager()
                    state_queue.complete_current_state(
                        success=True,
                        result_data={"interrupted": True, "reason": reason}
                    )
                    info_log("[ModuleCoordinator] âœ… å·²æ¨™è¨˜ç•¶å‰ç‹€æ…‹å®Œæˆ")
                    
                    info_log("[ModuleCoordinator] âœ… æœƒè©±å·²çµæŸï¼Œçµ‚æ­¢æœ¬æ¬¡å¾ªç’°")
                    # è¿”å› False çµæŸæœ¬æ¬¡å¾ªç’°ï¼ŒSystemLoop æœƒæª¢æ¸¬åˆ°ç‹€æ…‹ä½‡åˆ—æœ‰æ–°ç‹€æ…‹ä¸¦é–‹å§‹æ–°å¾ªç’°
                    return False
            
            if not primary_intent:
                debug_log(2, "[ModuleCoordinator] NLP çµæœç„¡ä¸»è¦æ„åœ–ï¼Œè·³éè™•ç†å±¤")
                return False
            
            # å°å…¥ IntentType ä»¥é€²è¡Œåˆ¤æ–·
            from modules.nlp_module.intent_types import IntentType
            
            # è™•ç†æšèˆ‰æˆ–å­—ç¬¦ä¸²å€¼
            intent_value = primary_intent.value if hasattr(primary_intent, 'value') else primary_intent
            intent_name = primary_intent.name if hasattr(primary_intent, 'name') else str(primary_intent)
            
            info_log(f"[ModuleCoordinator] ä¸»è¦æ„åœ–: {intent_name} (value={intent_value})")
            
            # âœ¨ æ ¹æ“šç•¶å‰ç³»çµ±ç‹€æ…‹ï¼ˆä¸æ˜¯ Intentï¼‰æ±ºå®šè™•ç†è·¯å¾‘
            # NLP çš„ Intent åªæ˜¯å»ºè­°ï¼Œå¯¦éš›è·¯å¾‘ç”±ç•¶å‰ State æ±ºå®š
            from core.states.state_manager import state_manager
            current_state = state_manager.get_current_state()
            cycle_index = input_data.get('cycle_index', 0)
            
            # æª¢æŸ¥æ˜¯å¦ç‚ºç³»çµ±åŒ¯å ±æ¨¡å¼ï¼ˆä¸éœ€è¦å·¥ä½œæµç¨‹ï¼‰
            is_system_report = input_data.get('system_report', False)
            
            # æ ¹æ“šç•¶å‰ç‹€æ…‹è·¯ç”±åˆ°å°æ‡‰çš„è™•ç†é‚è¼¯
            if current_state.value == "WORK" and cycle_index <= 0:
                # ç•¶å‰åœ¨ WORK ç‹€æ…‹ä¸”æ˜¯ Cycle 0
                if is_system_report:
                    # ç³»çµ±åŒ¯å ±æ¨¡å¼ï¼šç›´æ¥èª¿ç”¨ LLM ç”Ÿæˆå›æ‡‰ï¼Œä¸å•Ÿå‹•å·¥ä½œæµ
                    info_log("[ModuleCoordinator] ğŸ¯ WORKï¼ˆç³»çµ±åŒ¯å ±ï¼‰- ç›´æ¥ LLM è™•ç†")
                    return self._handle_system_report(input_data)
                else:
                    # WORK Cycle 0: ä¸‰éšæ®µè™•ç†ï¼ˆLLM æ±ºç­– â†’ SYS å•Ÿå‹• â†’ LLM å›æ‡‰ï¼‰
                    info_log("[ModuleCoordinator] ğŸ¯ WORK Cycle 0 - é–‹å§‹ä¸‰éšæ®µè™•ç†")
                    return self._handle_work_cycle_0(input_data)
            else:
                # CHAT ç‹€æ…‹ æˆ– WORK Cycle 1+: æ¨™æº–è™•ç†
                # æ³¨æ„ï¼šå³ä½¿ NLP è­˜åˆ¥å‡º WORK intentï¼Œå¦‚æœç•¶å‰ç‹€æ…‹æ˜¯ CHATï¼Œä»èµ° CHAT è·¯å¾‘
                # WORK intent å·²ç”± NLP åŠ å…¥ç‹€æ…‹ä½‡åˆ—ï¼Œæœƒåœ¨ä¸‹å€‹å¾ªç’°è™•ç†
                info_log(f"[ModuleCoordinator] æ¨™æº–è·¯å¾‘è™•ç† (state={current_state.value}, intent={intent_name}, cycle={cycle_index})")
                
                # æº–å‚™è™•ç†å±¤èª¿ç”¨è«‹æ±‚ï¼ˆæ ¹æ“šç•¶å‰ç‹€æ…‹æ±ºå®š WORK/CHAT è·¯å¾‘ï¼‰
                requests = self._prepare_processing_requests(current_state.value, input_data)
                
                # ğŸ”§ ç‰¹æ®Šæƒ…æ³ï¼šå¦‚æœæ²’æœ‰æ¨¡çµ„éœ€è¦èª¿ç”¨ï¼ˆä¾‹å¦‚ CALL æ„åœ–åœ¨ IDLE ç‹€æ…‹ï¼‰
                # éœ€è¦ä¸»å‹•å®Œæˆå¾ªç’°ä»¥æ¨é€² cycle_indexï¼Œé¿å…ä¸‹æ¬¡è¼¸å…¥è¢«å»é‡æ©Ÿåˆ¶æ“‹ä½
                if len(requests) == 0:
                    info_log("[ModuleCoordinator] ç„¡æ¨¡çµ„éœ€è¦èª¿ç”¨ï¼Œä¸»å‹•å®Œæˆå¾ªç’°")
                    
                    # å°å…¥ SystemLoop ä¸¦å®Œæˆå¾ªç’°
                    from core.system_loop import system_loop
                    if system_loop:
                        system_loop._complete_cycle(publish_event=True)
                        debug_log(2, "[ModuleCoordinator] å·²å®Œæˆå¾ªç’°ä¸¦æ¨é€² cycle_index")
                    
                    return True  # è¿”å› True è¡¨ç¤ºè™•ç†å®Œæˆï¼ˆé›–ç„¶æ²’æœ‰èª¿ç”¨æ¨¡çµ„ï¼‰
                
                # åŸ·è¡Œè™•ç†å±¤èª¿ç”¨
                responses = self.invoke_multiple_modules(requests)
                
                # æª¢æŸ¥æ˜¯å¦æœ‰æˆåŠŸçš„èª¿ç”¨
                success_count = sum(1 for r in responses if r.result == InvocationResult.SUCCESS)
                info_log(f"[ModuleCoordinator] è™•ç†å±¤å®Œæˆ: {success_count}/{len(responses)} æˆåŠŸ")
                
                return success_count > 0
            
        except Exception as e:
            error_log(f"[ModuleCoordinator] è¼¸å…¥å±¤ â†’ è™•ç†å±¤è½‰æ›å¤±æ•—: {e}")
            return False
    
    def _transition_to_output_layer(self, processing_data: Dict[str, Any]) -> bool:
        """è™•ç†å±¤ â†’ è¼¸å‡ºå±¤è½‰æ›"""
        try:
            info_log("[ModuleCoordinator] è™•ç†å±¤ â†’ è¼¸å‡ºå±¤è½‰æ›")
            
            # å¾è™•ç†å±¤çµæœä¸­æå–æ–‡å­—å…§å®¹
            response_text = self._extract_response_text(processing_data)
            
            if not response_text:
                debug_log(2, "[ModuleCoordinator] è™•ç†å±¤ç„¡æ–‡å­—è¼¸å‡ºï¼Œè·³éè¼¸å‡ºå±¤")
                return False
            
            info_log(f"[ModuleCoordinator] è™•ç†å±¤æ–‡å­—è¼¸å‡º: {response_text[:50]}...")
            
            # é€šé Router ç²å–è¼¸å‡ºå±¤è·¯ç”±æ±ºç­–
            from core.router import router
            routing_decision = router.route_system_output(
                text=response_text, 
                source_module="processing_layer"
            )
            
            if routing_decision.target_module != "tts":
                debug_log(1, f"[ModuleCoordinator] Router æœªæŒ‡å‘ TTS: {routing_decision.target_module}")
                return False
            
            info_log(f"[ModuleCoordinator] Router æ±ºç­–: {routing_decision.reasoning}")
            
            # æº–å‚™è¼¸å‡ºå±¤èª¿ç”¨ï¼ˆé€šå¸¸æ˜¯TTSï¼‰
            output_request = ModuleInvocationRequest(
                target_module="tts",
                input_data=self._prepare_output_input(processing_data),
                source_module="processing_layer",
                reasoning="è™•ç†å±¤å®Œæˆï¼Œè½‰é€è¼¸å‡ºå±¤",
                layer=ProcessingLayer.OUTPUT,
                priority=2
            )
            
            # ğŸ”§ ç•°æ­¥åŸ·è¡Œè¼¸å‡ºå±¤èª¿ç”¨ï¼Œé¿å…é˜»å¡äº‹ä»¶åˆ†ç™¼ç·šç¨‹
            # é€™æ¨£ MOV å¯ä»¥åŠæ™‚æ”¶åˆ° PROCESSING_LAYER_COMPLETE ä¸¦æ’­æ”¾å‹•ç•«
            import threading
            
            def _async_invoke_output():
                """ç•°æ­¥åŸ·è¡Œè¼¸å‡ºå±¤èª¿ç”¨"""
                try:
                    response = self.invoke_module(output_request)
                    success = response.result == InvocationResult.SUCCESS
                    
                    if success:
                        info_log("[ModuleCoordinator] è¼¸å‡ºå±¤å®Œæˆï¼Œä¸‰å±¤æµç¨‹çµæŸ")
                        # âœ… TTS æ¨¡çµ„å·²ç¶“é€šéäº‹ä»¶ç¸½ç·šç™¼å¸ƒ OUTPUT_LAYER_COMPLETE äº‹ä»¶
                        # âœ… SystemLoop æœƒè‡ªå‹•æ¥æ”¶ä¸¦è™•ç†ï¼Œä¸éœ€è¦é‡è¤‡é€šçŸ¥
                        debug_log(2, "[ModuleCoordinator] ç­‰å¾… TTS ç™¼å¸ƒçš„ OUTPUT_LAYER_COMPLETE äº‹ä»¶å®Œæˆå¾ªç’°")
                        
                        # ğŸ†• Task 5: æª¢æŸ¥æœƒè©±çµæŸè«‹æ±‚ï¼ˆé›™æ¢ä»¶çµ‚æ­¢æ©Ÿåˆ¶ï¼‰
                        llm_output = processing_data.get('llm_output', {})
                        session_control = llm_output.get('metadata', {}).get('session_control')
                        
                        debug_log(2, f"[ModuleCoordinator] æª¢æŸ¥ session_control: {session_control}")
                        
                        # Support multiple formats:
                        # 1. {'action': 'end_session'}
                        # 2. {'session_ended': True}
                        # 3. {'should_end_session': True} (from system notifications)
                        should_end = (session_control and 
                                     (session_control.get('action') == 'end_session' or 
                                      session_control.get('session_ended') is True or
                                      session_control.get('should_end_session') is True))
                        
                        debug_log(2, f"[ModuleCoordinator] should_end åˆ¤å®šçµæœ: {should_end}")
                        
                        if should_end:
                            # Try different reason keys for compatibility
                            reason = (session_control.get('reason') or 
                                     session_control.get('end_reason') or 
                                     'LLM requested')
                            info_log(f"[ModuleCoordinator] ğŸ”š LLM è«‹æ±‚çµæŸæœƒè©± (åŸå› : {reason})")
                            
                            # âœ… æ¨™è¨˜æ‰€æœ‰æ´»èºçš„å·¥ä½œæµæœƒè©±å¾…çµæŸï¼ˆä¸æ˜¯ç«‹å³çµæŸï¼‰
                            # æœƒè©±å°‡åœ¨æœ¬æ¬¡å¾ªç’°çš„ CYCLE_COMPLETED æ™‚ç”± Controller çµæŸ
                            from core.sessions.session_manager import unified_session_manager
                            
                            active_ws = unified_session_manager.get_active_workflow_session_ids()
                            for ws_id in active_ws:
                                unified_session_manager.mark_workflow_session_for_end(ws_id, reason=reason)
                                debug_log(2, f"[ModuleCoordinator] âœ… å·²æ¨™è¨˜ WS å¾…çµæŸ: {ws_id}")
                            
                            # å¾ processing_data é ‚å±¤ç²å– session_id (GS ID)
                            gs_id = processing_data.get('session_id', 'unknown')
                            self._pending_session_end = {
                                'reason': reason,
                                'session_control': session_control,
                                'gs_id': gs_id
                            }
                            info_log(f"[ModuleCoordinator] âœ… å·²æ¨™è¨˜æœƒè©±çµæŸè«‹æ±‚ï¼Œç­‰å¾…å¾ªç’°å®Œæˆ (gs_id={gs_id})")
                    else:
                        error_log(f"[ModuleCoordinator] è¼¸å‡ºå±¤èª¿ç”¨å¤±æ•—: {response.error_message}")
                        
                except Exception as e:
                    error_log(f"[ModuleCoordinator] ç•°æ­¥è¼¸å‡ºå±¤èª¿ç”¨å¤±æ•—: {e}")
                    import traceback
                    error_log(traceback.format_exc())
            
            # å•Ÿå‹•ç•°æ­¥ç·šç¨‹
            output_thread = threading.Thread(target=_async_invoke_output, daemon=True, name="OutputLayer-TTS")
            output_thread.start()
            debug_log(2, "[ModuleCoordinator] ğŸš€ å·²ç•°æ­¥å•Ÿå‹•è¼¸å‡ºå±¤èª¿ç”¨ï¼Œäº‹ä»¶è™•ç†å™¨ç«‹å³è¿”å›")
            
            # ç«‹å³è¿”å› Trueï¼Œè®“äº‹ä»¶è™•ç†å™¨ç¹¼çºŒè™•ç†å…¶ä»–è¨‚é–±è€…ï¼ˆå¦‚ MOVï¼‰
            return True
            
        except Exception as e:
            error_log(f"[ModuleCoordinator] è™•ç†å±¤ â†’ è¼¸å‡ºå±¤è½‰æ›å¤±æ•—: {e}")
            return False
    
    # ========== ç³»çµ±é€šçŸ¥äº‹ä»¶è™•ç†å™¨ ==========
    
    def _on_todo_notification(self, event):
        """è™•ç†å¾…è¾¦äº‹é …é€šçŸ¥äº‹ä»¶ - ç™¼å¸ƒåˆ°ç‹€æ…‹ä½‡åˆ—"""
        try:
            data = event.data
            title = data.get('title', 'å¾…è¾¦äº‹é …')
            deadline = data.get('deadline')
            stage = data.get('stage', 'unknown')
            
            # æ ¹æ“šä¸åŒéšæ®µèª¿æ•´è¨Šæ¯ï¼ˆä½¿ç”¨è‹±æ–‡ï¼Œç³»çµ±å…§éƒ¨çµ±ä¸€ä½¿ç”¨è‹±æ–‡ï¼‰
            stage_messages = {
                '1h_before': f'Reminder: Todo item "{title}" is due in one hour',
                'overdue': f'Alert: Todo item "{title}" is overdue',
                'urgent': f'Urgent: Todo item "{title}" is due soon'
            }
            
            notification_content = stage_messages.get(stage, f'Todo reminder: {title}')
            if deadline:
                notification_content += f', deadline: {deadline}'
            
            # ç™¼å¸ƒåˆ°ç‹€æ…‹ä½‡åˆ—ï¼Œèµ°æ­£å¸¸æµç¨‹
            self._publish_notification_to_state_queue(
                content=notification_content,
                notification_type='todo',
                metadata={
                    'title': title,
                    'deadline': deadline,
                    'stage': stage
                }
            )
            
            info_log(f"[ModuleCoordinator] âœ… å·²ç™¼å¸ƒå¾…è¾¦é€šçŸ¥åˆ°ç‹€æ…‹ä½‡åˆ—: {title} ({stage})")
        except Exception as e:
            error_log(f"[ModuleCoordinator] è™•ç†å¾…è¾¦é€šçŸ¥å¤±æ•—: {e}")
            import traceback
            error_log(traceback.format_exc())
    
    def _on_calendar_notification(self, event):
        """è™•ç†æ—¥æ›†äº‹ä»¶é€šçŸ¥ - ç™¼å¸ƒåˆ°ç‹€æ…‹ä½‡åˆ—"""
        try:
            data = event.data
            summary = data.get('summary', 'æ—¥æ›†äº‹ä»¶')
            start_time = data.get('start_time')
            location = data.get('location')
            stage = data.get('stage', 'unknown')
            
            # æ ¹æ“šä¸åŒéšæ®µèª¿æ•´è¨Šæ¯ï¼ˆä½¿ç”¨è‹±æ–‡ï¼Œç³»çµ±å…§éƒ¨çµ±ä¸€ä½¿ç”¨è‹±æ–‡ï¼‰
            stage_messages = {
                '15min_before': f'Reminder: "{summary}" is starting soon',
                '5min_before': f'Reminder: "{summary}" starts in 5 minutes',
                'starting': f'Starting now: {summary}'
            }
            
            notification_content = stage_messages.get(stage, f'Calendar reminder: {summary}')
            if location:
                notification_content += f', location: {location}'
            
            # ç™¼å¸ƒåˆ°ç‹€æ…‹ä½‡åˆ—ï¼Œèµ°æ­£å¸¸æµç¨‹
            self._publish_notification_to_state_queue(
                content=notification_content,
                notification_type='calendar',
                metadata={
                    'summary': summary,
                    'start_time': start_time,
                    'location': location,
                    'stage': stage
                }
            )
            
            info_log(f"[ModuleCoordinator] âœ… å·²ç™¼å¸ƒæ—¥æ›†é€šçŸ¥åˆ°ç‹€æ…‹ä½‡åˆ—: {summary} ({stage})")
        except Exception as e:
            error_log(f"[ModuleCoordinator] è™•ç†æ—¥æ›†é€šçŸ¥å¤±æ•—: {e}")
            import traceback
            error_log(traceback.format_exc())
    
    def _on_reminder_notification(self, event):
        """è™•ç†æé†’é€šçŸ¥äº‹ä»¶ - ç™¼å¸ƒåˆ°ç‹€æ…‹ä½‡åˆ—"""
        try:
            data = event.data
            message = data.get('message', 'Reminder')
            
            notification_content = f'Reminder: {message}'
            
            # ç™¼å¸ƒåˆ°ç‹€æ…‹ä½‡åˆ—ï¼Œèµ°æ­£å¸¸æµç¨‹
            self._publish_notification_to_state_queue(
                content=notification_content,
                notification_type='reminder',
                metadata={
                    'message': message
                }
            )
            
            info_log(f"[ModuleCoordinator] âœ… å·²ç™¼å¸ƒæé†’é€šçŸ¥åˆ°ç‹€æ…‹ä½‡åˆ—: {message}")
        except Exception as e:
            error_log(f"[ModuleCoordinator] è™•ç†æé†’é€šçŸ¥å¤±æ•—: {e}")
    
    def _on_startup_report(self, event):
        """è™•ç†å•Ÿå‹•å ±å‘Šäº‹ä»¶ - ç™¼å¸ƒåˆ°ç‹€æ…‹ä½‡åˆ—"""
        try:
            data = event.data
            report = data.get('report', 'ç³»çµ±å·²å•Ÿå‹•')
            
            # ç™¼å¸ƒåˆ°ç‹€æ…‹ä½‡åˆ—ï¼Œèµ°æ­£å¸¸æµç¨‹
            self._publish_notification_to_state_queue(
                content=report,
                notification_type='startup_report',
                metadata={}
            )
            
            info_log(f"[ModuleCoordinator] âœ… å·²ç™¼å¸ƒå•Ÿå‹•å ±å‘Šåˆ°ç‹€æ…‹ä½‡åˆ—")
        except Exception as e:
            error_log(f"[ModuleCoordinator] è™•ç†å•Ÿå‹•å ±å‘Šå¤±æ•—: {e}")
    
    def _publish_notification_to_state_queue(self, content: str, notification_type: str, metadata: Dict[str, Any]):
        """å°‡é€šçŸ¥ç™¼å¸ƒåˆ°ç‹€æ…‹ä½‡åˆ—ï¼Œèµ°æ­£å¸¸çš„ç‹€æ…‹æµç¨‹
        
        Args:
            content: é€šçŸ¥å…§å®¹
            notification_type: é€šçŸ¥é¡å‹ï¼ˆtodo, calendar, reminder, startup_reportï¼‰
            metadata: é€šçŸ¥å…ƒæ•¸æ“š
        """
        try:
            from core.states.state_queue import get_state_queue_manager
            from core.states.state_manager import UEPState
            
            debug_log(3, f"[ModuleCoordinator] ç™¼å¸ƒé€šçŸ¥åˆ°ç‹€æ…‹ä½‡åˆ—: {content[:50]}...")
            
            # æ§‹å»ºç‹€æ…‹ä½‡åˆ—é …ç›®çš„å…ƒæ•¸æ“š
            queue_metadata = {
                'system_report': True,  # æ¨™è¨˜ç‚ºç³»çµ±åŒ¯å ±æ¨¡å¼ï¼ˆä¸éœ€è¦å·¥ä½œæµï¼‰
                'notification_type': notification_type,
                'system_initiated': True,  # æ¨™è¨˜ç‚ºç³»çµ±ä¸»å‹•ç™¼èµ·
                **metadata
            }
            
            # ç™¼å¸ƒåˆ°ç‹€æ…‹ä½‡åˆ—ï¼ˆWORK ç‹€æ…‹ï¼‰
            state_queue = get_state_queue_manager()
            state_queue.add_state(
                state=UEPState.WORK,
                context_content=content,
                trigger_content=f"ç³»çµ±é€šçŸ¥ï¼š{notification_type}",
                metadata=queue_metadata
            )
            
            debug_log(2, f"[ModuleCoordinator] é€šçŸ¥å·²åŠ å…¥ç‹€æ…‹ä½‡åˆ—ï¼Œé¡å‹: {notification_type}")
                
        except Exception as e:
            error_log(f"[ModuleCoordinator] ç™¼å¸ƒé€šçŸ¥åˆ°ç‹€æ…‹ä½‡åˆ—å¤±æ•—: {e}")
            import traceback
            error_log(traceback.format_exc())
    
    # ========== ç³»çµ±åŒ¯å ±è™•ç† ==========
    
    def _handle_system_report(self, input_data: Dict[str, Any]) -> bool:
        """è™•ç†ç³»çµ±åŒ¯å ±ï¼ˆWORK ç‹€æ…‹ä½†ä¸éœ€è¦å·¥ä½œæµç¨‹ï¼‰
        
        ç³»çµ±åŒ¯å ±å ´æ™¯ï¼š
        - å¾…è¾¦äº‹é …é€šçŸ¥
        - æ—¥æ›†äº‹ä»¶æé†’
        - ç³»çµ±ç‹€æ…‹å ±å‘Š
        
        è™•ç†æµç¨‹ï¼š
        1. ç›´æ¥èª¿ç”¨ LLM ç”Ÿæˆå‹å–„çš„é€šçŸ¥è¨Šæ¯
        2. è¼¸å‡ºåˆ° TTS
        
        Args:
            input_data: åŒ…å«é€šçŸ¥å…§å®¹çš„è¼¸å…¥æ•¸æ“š
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            info_log("[ModuleCoordinator] ğŸ“¢ ç³»çµ±åŒ¯å ±æ¨¡å¼ - ç›´æ¥ LLM è™•ç†")
            
            # æº–å‚™ LLM è¼¸å…¥ï¼ˆç³»çµ±åŒ¯å ±ä¸éœ€è¦ MCP toolsï¼‰
            llm_data = self._prepare_llm_input(input_data)
            llm_data['phase'] = 'response'
            llm_data['system_report'] = True  # æ¨™è¨˜ç‚ºç³»çµ±åŒ¯å ±
            
            # æ·»åŠ ç³»çµ±æç¤ºï¼šé€™æ˜¯ç³»çµ±ä¸»å‹•é€šçŸ¥
            if 'metadata' not in llm_data:
                llm_data['metadata'] = {}
            llm_data['metadata']['is_system_initiated'] = True
            
            llm_request = ModuleInvocationRequest(
                target_module="llm",
                input_data=llm_data,
                source_module="input_layer",
                reasoning="ç³»çµ±åŒ¯å ± - LLM ç”Ÿæˆé€šçŸ¥è¨Šæ¯",
                layer=ProcessingLayer.PROCESSING,
                priority=5
            )
            
            llm_response = self.invoke_module(llm_request)
            
            if llm_response.result != InvocationResult.SUCCESS:
                error_log("[ModuleCoordinator] LLM è™•ç†ç³»çµ±åŒ¯å ±å¤±æ•—")
                return False
            
            info_log("[ModuleCoordinator] âœ… ç³»çµ±åŒ¯å ±è™•ç†å®Œæˆ")
            return True
            
        except Exception as e:
            error_log(f"[ModuleCoordinator] è™•ç†ç³»çµ±åŒ¯å ±å¤±æ•—: {e}")
            return False
    
    def _handle_work_cycle_0(self, input_data: Dict[str, Any]) -> bool:
        """è™•ç† WORK è·¯å¾‘çš„ Cycle 0ï¼ˆå•Ÿå‹•å·¥ä½œæµï¼‰
        
        âœ… MCP æ¶æ§‹ï¼šLLM é€šé MCP function calling å•Ÿå‹•å·¥ä½œæµ
        
        Cycle 0 æµç¨‹ï¼š
        1. LLM æ¥æ”¶ç”¨æˆ¶è«‹æ±‚å’Œå¯ç”¨çš„ MCP tools
        2. LLM æ±ºç­–ä¸¦èª¿ç”¨ start_workflow
        3. MCP Client â†’ SYS æ¨¡çµ„å•Ÿå‹•å·¥ä½œæµ
        4. LLM ç”Ÿæˆå›æ‡‰ï¼šã€Œå·¥ä½œæµå·²å•Ÿå‹•ï¼Œç¬¬ä¸€æ­¥æ˜¯...ã€
        
        Cycle 1+ æµç¨‹ï¼ˆå·¥ä½œæµæ­¥é©Ÿäº’å‹•ï¼‰ï¼š
        1. SYS é€šé review_step è¿”å›ç•¶å‰æ­¥é©Ÿä¿¡æ¯
        2. LLM å°‡æ­¥é©Ÿè½‰æ›ç‚ºç”¨æˆ¶å‹å¥½çš„æè¿°
        3. ç”¨æˆ¶å›æ‡‰ â†’ LLM æ±ºå®š approve_step/modify_step/cancel_workflow
        4. é€šé MCP èª¿ç”¨å°æ‡‰å·¥å…·
        5. é‡è¤‡ç›´åˆ°å·¥ä½œæµå®Œæˆ
        
        Args:
            input_data: è¼¸å…¥æ•¸æ“š
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            info_log("[ModuleCoordinator] ğŸ¯ WORK Cycle 0 - LLM é€šé MCP è™•ç†å·¥ä½œæµ")
            
            # èª¿ç”¨ LLMï¼ˆLLM æœƒé€šé MCP function calling å•Ÿå‹•å·¥ä½œæµï¼‰
            llm_data = self._prepare_llm_input(input_data)
            llm_data['phase'] = 'response'  # ç›´æ¥ç”Ÿæˆå›æ‡‰ï¼ˆåŒ…å« MCP èª¿ç”¨ï¼‰
            
            llm_request = ModuleInvocationRequest(
                target_module="llm",
                input_data=llm_data,
                source_module="input_layer",
                reasoning="WORK Cycle 0 - LLM è™•ç†å·¥ä½œæµï¼ˆå« MCP èª¿ç”¨ï¼‰",
                layer=ProcessingLayer.PROCESSING,
                priority=5
            )
            
            llm_response = self.invoke_module(llm_request)
            
            if llm_response.result != InvocationResult.SUCCESS:
                error_log("[ModuleCoordinator] LLM è™•ç†éšæ®µå¤±æ•—")
                return False
            
            llm_output = llm_response.output_data
            debug_log(2, f"[ModuleCoordinator] llm å®Œæ•´è¿”å›çµæœ: {llm_output}")
            
            # âœ… æª¢æŸ¥æ˜¯å¦æˆåŠŸèª¿ç”¨äº† MCP function
            function_call_made = llm_output.get('metadata', {}).get('function_call_made', False)
            function_call_result = llm_output.get('metadata', {}).get('function_call_result', {})
            
            if function_call_made:
                info_log("[ModuleCoordinator] âœ… LLM å·²é€šé MCP å•Ÿå‹•å·¥ä½œæµ")
                
                # âœ… æª¢æŸ¥å·¥ä½œæµæ˜¯å¦æˆåŠŸå•Ÿå‹•
                if function_call_result.get('status') == 'success':
                    debug_log(2, "[ModuleCoordinator] å·¥ä½œæµå•Ÿå‹•æˆåŠŸï¼ŒLLM å·²ç”Ÿæˆåˆå§‹å›æ‡‰")
                    # TODO: åœ¨æœªä¾†çš„ Cycle 1 ä¸­ï¼Œéœ€è¦ï¼š
                    # 1. èª¿ç”¨ review_step ç²å–ç¬¬ä¸€å€‹æ­¥é©Ÿ
                    # 2. LLM å°‡æ­¥é©Ÿè½‰æ›ç‚ºç”¨æˆ¶æè¿°
                    # 3. ç­‰å¾…ç”¨æˆ¶å›æ‡‰å¾Œå†ç¹¼çºŒ
                else:
                    debug_log(2, f"[ModuleCoordinator] å·¥ä½œæµå•Ÿå‹•å¤±æ•—: {function_call_result.get('error')}")
                    # LLM å·²ç¶“åœ¨ follow-up response ä¸­è§£é‡‹äº†éŒ¯èª¤
            else:
                debug_log(2, "[ModuleCoordinator] LLM æœªèª¿ç”¨ MCP functionï¼ˆå¯èƒ½åœ¨è©¢å•æ›´å¤šä¿¡æ¯ï¼‰")
            
            # èˆŠæ¶æ§‹çš„å…¼å®¹è™•ç†ï¼ˆå¦‚æœ LLM è¿”å›äº†èˆŠæ ¼å¼çš„ workflow_decisionï¼‰
            workflow_decision = llm_output.get('workflow_decision')
            if workflow_decision:
                debug_log(1, "[ModuleCoordinator] âš ï¸ LLM è¿”å›äº†èˆŠæ ¼å¼çš„ workflow_decisionï¼Œæ‡‰è©²ä½¿ç”¨ MCP function calling")
            
            # âœ… Cycle 0 å®Œæˆï¼ŒLLM å·²ç¶“è¿”å›åˆå§‹å›æ‡‰
            # âš ï¸ æ³¨æ„ï¼šå®Œæ•´çš„ Cycle 0 æ‡‰è©²åŒ…æ‹¬ï¼š
            #    1. å•Ÿå‹•å·¥ä½œæµ âœ“
            #    2. ç²å–ç¬¬ä¸€æ­¥ä¿¡æ¯ (TODO)
            #    3. LLM æè¿°ç¬¬ä¸€æ­¥çµ¦ç”¨æˆ¶ (TODO)
            #    4. ç­‰å¾…ç”¨æˆ¶å›æ‡‰æ‰é€²å…¥ Cycle 1
            
            info_log("[ModuleCoordinator] âœ“ WORK Cycle 0 å®Œæˆï¼ˆMCP æ¶æ§‹ï¼‰")
            return True
            
        except Exception as e:
            error_log(f"[ModuleCoordinator] WORK Cycle 0 è™•ç†å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _prepare_processing_requests(self, primary_target: str, input_data: Dict[str, Any]) -> List[ModuleInvocationRequest]:
        """æº–å‚™è™•ç†å±¤èª¿ç”¨è«‹æ±‚
        
        Args:
            primary_target: ç•¶å‰ç³»çµ±ç‹€æ…‹ï¼ˆ"chat" æˆ– "work"ï¼‰ï¼Œæ±ºå®šè™•ç†è·¯å¾‘
            input_data: è¼¸å…¥æ•¸æ“š
        
        Note: ä½¿ç”¨ç•¶å‰ç³»çµ±ç‹€æ…‹è€Œé NLP Intent ä¾†æ±ºå®šè™•ç†è·¯å¾‘
        """
        requests = []
        nlp_result = input_data.get('nlp_result', {})
        
        # ä½¿ç”¨ç•¶å‰ç³»çµ±ç‹€æ…‹ï¼ˆprimary_targetï¼‰è€Œé NLP Intent
        # primary_target æ˜¯å¾ state_manager.get_current_state().value ç²å¾—çš„
        route_target = primary_target.lower()  # "chat" or "work"
        
        debug_log(2, f"[ModuleCoordinator] æº–å‚™è™•ç†å±¤è«‹æ±‚ - è·¯ç”±ç›®æ¨™: {route_target} (åŸºæ–¼ç•¶å‰ç‹€æ…‹)")
        
        # æ ¹æ“šç•¶å‰ç‹€æ…‹æ±ºå®šè™•ç†å±¤æ¨¡çµ„çµ„åˆ
        if route_target == "chat":
            # CHATè·¯å¾‘ï¼šMEM + LLM
            info_log("[ModuleCoordinator] CHAT è·¯å¾‘: MEM + LLM (åŸºæ–¼ç•¶å‰ç‹€æ…‹)")
            requests.extend([
                ModuleInvocationRequest(
                    target_module="mem",
                    input_data=self._prepare_mem_input(input_data),
                    source_module="input_layer",
                    reasoning="èŠå¤©æ¨¡å¼è¨˜æ†¶æŸ¥è©¢",
                    layer=ProcessingLayer.PROCESSING,
                    priority=4
                ),
                ModuleInvocationRequest(
                    target_module="llm",
                    input_data=self._prepare_llm_input(input_data),
                    source_module="input_layer", 
                    reasoning="èŠå¤©å°è©±ç”Ÿæˆ",
                    layer=ProcessingLayer.PROCESSING,
                    priority=3
                )
            ])
        elif route_target == "work":
            # WORKè·¯å¾‘ï¼šæª¢æŸ¥æ˜¯å¦ç‚º RESPONSEï¼ˆå·¥ä½œæµè¼¸å…¥å›æ‡‰ï¼‰
            user_intent = nlp_result.get('primary_intent')
            from modules.nlp_module.intent_types import IntentType
            intent_value = user_intent.value if hasattr(user_intent, 'value') else user_intent
            
            if user_intent == IntentType.RESPONSE or intent_value == "response":
                # RESPONSEè·¯å¾‘ï¼šåƒ… LLMï¼ˆå·¥ä½œæµè¼¸å…¥å›æ‡‰ï¼Œä¸éœ€è¦ MEM å’Œ SYSï¼‰
                info_log("[ModuleCoordinator] WORK/RESPONSE è·¯å¾‘: LLM only (å·¥ä½œæµè¼¸å…¥)")
                requests.append(
                    ModuleInvocationRequest(
                        target_module="llm",
                        input_data=self._prepare_llm_input(input_data),
                        source_module="input_layer",
                        reasoning="å·¥ä½œæµç”¨æˆ¶å›æ‡‰è™•ç†",
                        layer=ProcessingLayer.PROCESSING,
                        priority=4
                    )
                )
            else:
                # WORKè·¯å¾‘ï¼šLLM + SYS (ä¸éœ€è¦ MEM)
                info_log("[ModuleCoordinator] WORK è·¯å¾‘: LLM + SYS (åŸºæ–¼ç•¶å‰ç‹€æ…‹)")
                requests.extend([
                    ModuleInvocationRequest(
                        target_module="llm",
                        input_data=self._prepare_llm_input(input_data),
                        source_module="input_layer",
                        reasoning="å·¥ä½œæ¨¡å¼ä»»å‹™åˆ†æ",
                        layer=ProcessingLayer.PROCESSING,
                        priority=4
                    ),
                    ModuleInvocationRequest(
                        target_module="sys",
                        input_data=self._prepare_sys_input(input_data),
                        source_module="input_layer",
                        reasoning="ç³»çµ±å·¥ä½œæµåŸ·è¡Œ",
                        layer=ProcessingLayer.PROCESSING,
                        priority=3
                    )
                ])
        else:
            # é»˜èªï¼šIDLE æˆ–å…¶ä»–ç‹€æ…‹
            info_log(f"[ModuleCoordinator] é»˜èªè·¯å¾‘: {route_target}")
            # IDLE ç‹€æ…‹é€šå¸¸ä¸éœ€è¦è™•ç†å±¤ï¼Œè¿”å›ç©ºåˆ—è¡¨
            pass
        
        return requests
    
    def _prepare_mem_input(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æº–å‚™MEMæ¨¡çµ„è¼¸å…¥"""
        nlp_result = input_data.get('nlp_result', {})
        return {
            "text": input_data.get('input_data', {}).get('text', ''),
            "source": "three_layer_coordinator",
            "operation": "store_and_retrieve",
            "memory_context": {
                "identity_id": nlp_result.get('identity', {}).get('identity_id'),
                "conversation_type": nlp_result.get('primary_intent'),
                "entities": nlp_result.get('entities', [])
            },
            "timestamp": input_data.get('timestamp', time.time()),
            "nlp_result": nlp_result
        }
    
    def _prepare_llm_input(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æº–å‚™LLMæ¨¡çµ„è¼¸å…¥
        
        é‡è¦æ¶æ§‹è¨­è¨ˆï¼š
        - ç¬¬ä¸€æ¬¡é€²å…¥è™•ç†å±¤ (cycle_index = 0)ï¼šå¾ç‹€æ…‹ä¸Šä¸‹æ–‡ç²å–å‘½ä»¤æ–‡æœ¬å’Œ metadata
        - ç¬¬äºŒæ¬¡ä»¥å¾Œ (cycle_index > 0)ï¼šå¾ Router ç²å–ç”¨æˆ¶å›æ‡‰æ–‡æœ¬
        """
        nlp_result = input_data.get('nlp_result', {})
        cycle_index = input_data.get('cycle_index', 0)
        primary_intent = nlp_result.get('primary_intent')
        
        # å°å…¥ IntentType ä»¥é€²è¡Œåˆ¤æ–·
        from modules.nlp_module.intent_types import IntentType
        intent_value = primary_intent.value if hasattr(primary_intent, 'value') else primary_intent
        
        # âœ… Cycle 0: å¾ç‹€æ…‹ä¸Šä¸‹æ–‡ç²å–æ–‡æœ¬å’Œ metadata
        intent_metadata = None
        if cycle_index == 0:
            from core.states.state_queue import get_state_queue_manager
            state_queue = get_state_queue_manager()
            current_item = state_queue.current_item
            
            if current_item:
                # ä½¿ç”¨ç‹€æ…‹çš„ context_content ä½œç‚ºè¼¸å…¥æ–‡æœ¬
                input_text = current_item.context_content
                debug_log(2, f"[ModuleCoordinator] Cycle 0 - å¾ç‹€æ…‹ä¸Šä¸‹æ–‡ç²å–: {input_text[:50]}...")
                
                # å¾ç‹€æ…‹ metadata æå–é™ç´šæ¨™è¨˜
                state_metadata = current_item.metadata or {}
                if state_metadata.get('degraded_from_work'):
                    intent_metadata = {
                        'degraded_from_work': state_metadata['degraded_from_work'],
                        'original_intent': state_metadata.get('original_intent'),
                        'degradation_reason': state_metadata.get('degradation_reason')
                    }
                    debug_log(2, f"[ModuleCoordinator] å¾ç‹€æ…‹ä¸Šä¸‹æ–‡æª¢æ¸¬åˆ°é™ç´šçš„ WORK è«‹æ±‚: {intent_metadata}")
            else:
                # Fallback: ä½¿ç”¨åŸå§‹è¼¸å…¥æ–‡æœ¬
                input_text = input_data.get('input_data', {}).get('text', '')
                debug_log(1, f"[ModuleCoordinator] âš ï¸ Cycle 0 ä½†ç„¡ current_itemï¼Œä½¿ç”¨åŸå§‹è¼¸å…¥")
        else:
            # Cycle > 0: å¾ Router ç²å–ç”¨æˆ¶å›æ‡‰æ–‡æœ¬
            # âœ… ä¿®å¾©ï¼šå…ˆå˜—è©¦å¾é ‚å±¤ç²å– text (STATE_ADVANCED äº‹ä»¶æ ¼å¼)ï¼Œå†å˜—è©¦å¾ input_data ç²å– (Router æ ¼å¼)
            input_text = input_data.get('text', '') or input_data.get('input_data', {}).get('text', '')
            debug_log(2, f"[ModuleCoordinator] Cycle {cycle_index} - å¾ Router ç²å–ç”¨æˆ¶å›æ‡‰: {input_text[:50] if input_text else '(ç©º)'}")
        
        # âœ… æ ¹æ“š primary_intent æ±ºå®š LLM æ¨¡å¼
        if primary_intent == IntentType.WORK or intent_value == "work":
            llm_mode = "work"
        elif primary_intent == IntentType.RESPONSE or intent_value == "response":
            # RESPONSE æ„åœ–ï¼šå·¥ä½œæµè¼¸å…¥å›æ‡‰ï¼Œä½¿ç”¨ work æ¨¡å¼è®“ LLM èª¿ç”¨ provide_workflow_input
            llm_mode = "work"
            debug_log(2, "[ModuleCoordinator] RESPONSE intent - using work mode for workflow input")
        else:
            llm_mode = "chat"
        
        # âœ… WORK Cycle 0: æå– NLP æ‰¾åˆ°çš„å·¥ä½œæµåŒ¹é…ä¿¡æ¯
        suggested_workflow = None
        if (primary_intent == IntentType.WORK or intent_value == "work") and cycle_index == 0:
            # å¾ NLP çš„ processing_notes æˆ– intent_segments ä¸­æå–å·¥ä½œæµæç¤º
            for note in nlp_result.get('processing_notes', []):
                if 'matching function' in note.lower() or 'workflow' in note.lower():
                    suggested_workflow = note
                    break
        
        base_data = {
            "text": input_text,
            "source": "three_layer_coordinator",
            "mode": llm_mode,  # âœ… æ·»åŠ  mode åƒæ•¸ï¼Œè®“ LLM çŸ¥é“æ˜¯ WORK é‚„æ˜¯ CHAT
            "conversation_type": nlp_result.get('primary_intent'),
            "user_input": input_text,
            "context": {
                "intent_segments": nlp_result.get('intent_segments', []),
                "entities": nlp_result.get('entities', []),
                "processing_notes": nlp_result.get('processing_notes', [])
            },
            "processing_context": {"intent_metadata": intent_metadata} if intent_metadata else None,  # âœ… æ·»åŠ é™ç´š metadata
            "timestamp": input_data.get('timestamp', time.time()),
            "nlp_result": nlp_result,
            "identity": nlp_result.get('identity'),
            "intent": nlp_result.get('primary_intent'),
            "confidence": nlp_result.get('overall_confidence', 0.0),
            "cycle_index": cycle_index  # âœ… å‚³é cycle_index ä¾› LLM æ¨¡çµ„ä½¿ç”¨
        }
        
        # âœ… æ·»åŠ å·¥ä½œæµæç¤ºï¼ˆå¦‚æœæœ‰ï¼‰
        if suggested_workflow:
            base_data['workflow_hint'] = suggested_workflow
        
        return base_data
    
    def _prepare_sys_input(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """æº–å‚™SYSæ¨¡çµ„è¼¸å…¥
        
        é‡è¦æ¶æ§‹è¨­è¨ˆï¼š
        - ç¬¬ä¸€æ¬¡é€²å…¥è™•ç†å±¤ (cycle_index = 0)ï¼šå¾ç‹€æ…‹ä¸Šä¸‹æ–‡ (WorkflowSession) ç²å–å‘½ä»¤æ–‡æœ¬
        - ç¬¬äºŒæ¬¡ä»¥å¾Œ (cycle_index > 0)ï¼šå¾ Router ç²å–ç”¨æˆ¶å›æ‡‰æ–‡æœ¬
        """
        nlp_result = input_data.get('nlp_result', {})
        cycle_index = input_data.get('cycle_index', 0)
        
        # åˆ¤æ–·æ–‡æœ¬ä¾†æºï¼ˆèˆ‡ LLM ä½¿ç”¨ç›¸åŒé‚è¼¯ï¼‰
        if cycle_index == 0:
            # âœ… Cycle 0: ä½¿ç”¨å®Œæ•´çš„åŸå§‹è¼¸å…¥æ–‡æœ¬
            # å…ˆå˜—è©¦å¾é ‚å±¤ç²å– (STATE_ADVANCED æ ¼å¼)ï¼Œå†å¾ input_data ç²å– (Router æ ¼å¼)
            input_text = input_data.get('text', '') or input_data.get('input_data', {}).get('text', '')
            debug_log(2, f"[ModuleCoordinator] WORK Cycle 0 - SYS ä½¿ç”¨å®Œæ•´åŸå§‹è¼¸å…¥: {input_text[:50] if input_text else '(ç©º)'}...")
        else:
            # ç¬¬äºŒæ¬¡ä»¥å¾Œï¼šå¾ Router ç²å–ç”¨æˆ¶å›æ‡‰
            input_text = input_data.get('text', '') or input_data.get('input_data', {}).get('text', '')
            debug_log(2, f"[ModuleCoordinator] WORK cycle {cycle_index} - SYS å¾ Router ç²å–æ–‡æœ¬: {input_text[:50] if input_text else '(ç©º)'}")
        
        return {
            "text": input_text,
            "source": "three_layer_coordinator",
            "mode": "workflow",  # âœ… æ·»åŠ  mode åƒæ•¸ï¼ŒSYS æ¨¡çµ„å¿…éœ€
            "operation": "workflow_execution",
            "system_context": {
                "intent": nlp_result.get('primary_intent'),
                "entities": nlp_result.get('entities', []),
                "command_type": "work_task"
            },
            "timestamp": input_data.get('timestamp', time.time()),
            "nlp_result": nlp_result,
            "cycle_index": cycle_index  # âœ… å‚³é cycle_index ä¾› SYS æ¨¡çµ„ä½¿ç”¨
        }
    
    def _prepare_output_input(self, processing_data: Dict[str, Any]) -> Dict[str, Any]:
        """æº–å‚™è¼¸å‡ºå±¤ï¼ˆTTSï¼‰è¼¸å…¥"""
        return {
            "text": processing_data.get('response', processing_data.get('text', '')),
            "source": "three_layer_coordinator",
            "output_mode": "voice",
            "timestamp": time.time(),
            "processing_result": processing_data
        }
    
    def _prepare_module_input(self, target_module: str, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç‚ºç‰¹å®šæ¨¡çµ„æº–å‚™è¼¸å…¥æ•¸æ“šï¼ˆé€šç”¨æ–¹æ³•ï¼‰"""
        if target_module == "mem":
            return self._prepare_mem_input(input_data)
        elif target_module == "llm":
            return self._prepare_llm_input(input_data)
        elif target_module == "sys":
            return self._prepare_sys_input(input_data)
        elif target_module == "tts":
            return self._prepare_output_input(input_data)
        else:
            # é€šç”¨è¼¸å…¥æ ¼å¼
            nlp_result = input_data.get('nlp_result', {})
            return {
                "text": input_data.get('input_data', {}).get('text', ''),
                "source": "three_layer_coordinator",
                "timestamp": input_data.get('timestamp', time.time()),
                "nlp_result": nlp_result,
                "intent": nlp_result.get('primary_intent'),
                "confidence": nlp_result.get('overall_confidence', 0.0)
            }
    
    def invoke_module(self, request: ModuleInvocationRequest) -> ModuleInvocationResponse:
        """
        èª¿ç”¨ç›®æ¨™æ¨¡çµ„
        
        Args:
            request: æ¨¡çµ„èª¿ç”¨è«‹æ±‚
            
        Returns:
            ModuleInvocationResponse: èª¿ç”¨å›æ‡‰
        """
        start_time = time.time()
        
        with self._invocation_lock:
            try:
                info_log(f"[ModuleCoordinator] èª¿ç”¨{request.layer.value}å±¤æ¨¡çµ„: {request.target_module}")
                debug_log(2, f"[ModuleCoordinator] èª¿ç”¨åŸå› : {request.reasoning}")
                debug_log(3, f"[ModuleCoordinator] è¼¸å…¥æ•¸æ“š: {list(request.input_data.keys())}")
                
                # ç²å–ç›®æ¨™æ¨¡çµ„
                from core.framework import core_framework
                target_module = core_framework.get_module(request.target_module)
                
                if not target_module:
                    error_msg = f"ç„¡æ³•æ‰¾åˆ°ç›®æ¨™æ¨¡çµ„: {request.target_module}"
                    error_log(f"[ModuleCoordinator] {error_msg}")
                    return ModuleInvocationResponse(
                        target_module=request.target_module,
                        result=InvocationResult.NO_TARGET,
                        layer=request.layer,
                        error_message=error_msg,
                        execution_time=time.time() - start_time
                    )
                
                # è¨˜éŒ„æ´»èºèª¿ç”¨
                invocation_id = f"{request.target_module}_{int(time.time() * 1000)}"
                self._active_invocations[invocation_id] = {
                    "target": request.target_module,
                    "layer": request.layer.value,
                    "start_time": start_time,
                    "source": request.source_module
                }
                
                # å¯¦éš›èª¿ç”¨æ¨¡çµ„
                result_data = target_module.handle(request.input_data)
                
                # ç§»é™¤æ´»èºèª¿ç”¨è¨˜éŒ„
                if invocation_id in self._active_invocations:
                    del self._active_invocations[invocation_id]
                
                execution_time = time.time() - start_time
                
                # âœ… æ­£ç¢ºåˆ¤æ–·æˆåŠŸ: æª¢æŸ¥ result_data['success'] å­—æ®µ
                is_success = result_data and isinstance(result_data, dict) and result_data.get('success', False)
                
                if result_data:
                    # è¨˜éŒ„æ¨¡çµ„è¿”å›çµæœ
                    self._log_module_result(request.target_module, result_data)
                    
                    # æ ¹æ“š success å­—æ®µæ±ºå®šçµæœç‹€æ…‹
                    if is_success:
                        info_log(f"[ModuleCoordinator] {request.layer.value}å±¤æ¨¡çµ„ {request.target_module} è™•ç†å®Œæˆ ({execution_time:.3f}s)")
                        invocation_result = InvocationResult.SUCCESS
                    else:
                        # success=False è¦–ç‚ºå¤±æ•—,ä¸æ˜¯æˆåŠŸ
                        error_msg = result_data.get('error', 'æœªçŸ¥éŒ¯èª¤')
                        debug_log(2, f"[ModuleCoordinator] {request.layer.value}å±¤æ¨¡çµ„ {request.target_module} è™•ç†å¤±æ•—: {error_msg}")
                        invocation_result = InvocationResult.FAILED
                    
                    response = ModuleInvocationResponse(
                        target_module=request.target_module,
                        result=invocation_result,
                        layer=request.layer,
                        output_data=result_data,
                        execution_time=execution_time
                    )
                    
                    # åªæœ‰çœŸæ­£æˆåŠŸæ™‚æ‰æª¢æŸ¥å±¤ç´šå®Œæˆ
                    if is_success:
                        self._check_layer_completion(request.layer, result_data)
                    
                else:
                    debug_log(2, f"[ModuleCoordinator] {request.layer.value}å±¤æ¨¡çµ„ {request.target_module} ç„¡è¿”å›çµæœ")
                    response = ModuleInvocationResponse(
                        target_module=request.target_module,
                        result=InvocationResult.FAILED,  # ç„¡è¿”å›çµæœè¦–ç‚ºå¤±æ•—
                        layer=request.layer,
                        output_data=None,
                        execution_time=execution_time
                    )
                
                # è¨˜éŒ„èª¿ç”¨æ­·å²
                self._invocation_history.append({
                    "timestamp": time.time(),
                    "target_module": request.target_module,
                    "layer": request.layer.value,
                    "source_module": request.source_module,
                    "result": response.result.value,
                    "execution_time": execution_time
                })
                
                # ä¿æŒæ­·å²è¨˜éŒ„åœ¨åˆç†ç¯„åœå…§
                if len(self._invocation_history) > 100:
                    self._invocation_history = self._invocation_history[-50:]
                
                return response
                
            except Exception as e:
                execution_time = time.time() - start_time
                error_msg = f"èª¿ç”¨æ¨¡çµ„å¤±æ•—: {e}"
                error_log(f"[ModuleCoordinator] {error_msg}")
                
                # æ¸…ç†æ´»èºèª¿ç”¨è¨˜éŒ„
                invocation_id = f"{request.target_module}_{int(start_time * 1000)}"
                if invocation_id in self._active_invocations:
                    del self._active_invocations[invocation_id]
                
                return ModuleInvocationResponse(
                    target_module=request.target_module,
                    result=InvocationResult.FAILED,
                    layer=request.layer,
                    error_message=error_msg,
                    execution_time=execution_time
                )
    
    def _check_layer_completion(self, current_layer: ProcessingLayer, result_data: Dict[str, Any]):
        """æª¢æŸ¥ç•¶å‰å±¤æ˜¯å¦å®Œæˆï¼Œæ±ºå®šæ˜¯å¦è§¸ç™¼ä¸‹ä¸€å±¤"""
        try:
            # ç°¡åŒ–ç‰ˆæœ¬ï¼šç›´æ¥æª¢æŸ¥çµæœæ˜¯å¦åŒ…å«éœ€è¦å‚³éçš„æ•¸æ“š
            if result_data and 'response' in result_data:
                debug_log(2, f"[ModuleCoordinator] {current_layer.value}å±¤è™•ç†å®Œæˆï¼Œæº–å‚™è§¸ç™¼ä¸‹ä¸€å±¤")
                # åœ¨å¯¦éš›å¯¦ç¾ä¸­ï¼Œé€™è£¡æœƒæ ¹æ“šå…·é«”é‚è¼¯æ±ºå®šæ˜¯å¦è§¸ç™¼ä¸‹ä¸€å±¤
                # ç›®å‰ç°¡åŒ–ç‚ºæ—¥èªŒè¨˜éŒ„
            
        except Exception as e:
            debug_log(3, f"[ModuleCoordinator] æª¢æŸ¥å±¤ç´šå®Œæˆç‹€æ…‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    def invoke_multiple_modules(self, requests: List[ModuleInvocationRequest]) -> List[ModuleInvocationResponse]:
        """
        æ‰¹é‡èª¿ç”¨å¤šå€‹æ¨¡çµ„
        
        Args:
            requests: æ¨¡çµ„èª¿ç”¨è«‹æ±‚åˆ—è¡¨
            
        Returns:
            List[ModuleInvocationResponse]: èª¿ç”¨å›æ‡‰åˆ—è¡¨
        """
        info_log(f"[ModuleCoordinator] æ‰¹é‡èª¿ç”¨ {len(requests)} å€‹æ¨¡çµ„")
        
        responses = []
        for request in requests:
            response = self.invoke_module(request)
            responses.append(response)
            
            # å¦‚æœæœ‰ä»»ä½•é—œéµæ¨¡çµ„èª¿ç”¨å¤±æ•—ï¼Œè€ƒæ…®çµ‚æ­¢å¾ŒçºŒèª¿ç”¨
            if response.result == InvocationResult.FAILED and request.priority >= 5:
                error_log(f"[ModuleCoordinator] é—œéµæ¨¡çµ„ {request.target_module} èª¿ç”¨å¤±æ•—ï¼Œçµ‚æ­¢å¾ŒçºŒèª¿ç”¨")
                break
        
        return responses
    
    def _log_module_result(self, module_name: str, result_data: Any):
        """è¨˜éŒ„æ¨¡çµ„è¿”å›çµæœçš„è©³ç´°ä¿¡æ¯"""
        try:
            # ç°¡åŒ–æ—¥èªŒï¼šç›´æ¥è¼¸å‡ºæ•´å€‹çµæœå­—å…¸
            debug_log(3, f"[ModuleCoordinator] {module_name} å®Œæ•´è¿”å›çµæœ: {result_data}")
                
        except Exception as e:
            debug_log(3, f"[ModuleCoordinator] è¨˜éŒ„ {module_name} çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    def _extract_response_text(self, processing_data: Dict[str, Any]) -> str:
        """å¾è™•ç†å±¤æ•¸æ“šä¸­æå–æ–‡å­—å›æ‡‰"""
        try:
            # å„ªå…ˆé †åºï¼šresponse > text > content
            if "response" in processing_data:
                return processing_data["response"]
            elif "text" in processing_data:
                return processing_data["text"]
            elif "content" in processing_data:
                return processing_data["content"]
            else:
                # å¦‚æœæ˜¯åµŒå¥—çµæ§‹ï¼Œå˜—è©¦æ·±åº¦æå–
                if isinstance(processing_data, dict):
                    for key in ["llm_output", "result", "data"]:
                        if key in processing_data:
                            nested_data = processing_data[key]
                            if isinstance(nested_data, dict):
                                if "text" in nested_data:
                                    return nested_data["text"]
                                elif "response" in nested_data:
                                    return nested_data["response"]
                
                debug_log(2, f"[ModuleCoordinator] ç„¡æ³•å¾è™•ç†å±¤æ•¸æ“šä¸­æå–æ–‡å­—: {list(processing_data.keys())}")
                return ""
                
        except Exception as e:
            error_log(f"[ModuleCoordinator] æå–å›æ‡‰æ–‡å­—å¤±æ•—: {e}")
            return ""
    
    def get_active_invocations(self) -> Dict[str, Any]:
        """ç²å–ç•¶å‰æ´»èºçš„èª¿ç”¨ç‹€æ…‹"""
        return dict(self._active_invocations)
    
    def get_invocation_stats(self) -> Dict[str, Any]:
        """ç²å–èª¿ç”¨çµ±è¨ˆä¿¡æ¯"""
        if not self._invocation_history:
            return {
                "total_invocations": 0,
                "avg_execution_time": 0.0,
                "success_rate": 0.0,
                "module_stats": {}
            }
        
        total = len(self._invocation_history)
        successful = sum(1 for h in self._invocation_history if h["result"] == "success")
        avg_time = sum(h["execution_time"] for h in self._invocation_history) / total
        
        # æ¨¡çµ„çµ±è¨ˆ
        module_stats = {}
        for history in self._invocation_history:
            module = history["target_module"]
            if module not in module_stats:
                module_stats[module] = {"count": 0, "success": 0, "avg_time": 0.0}
            
            module_stats[module]["count"] += 1
            if history["result"] == "success":
                module_stats[module]["success"] += 1
            module_stats[module]["avg_time"] = (
                module_stats[module]["avg_time"] * (module_stats[module]["count"] - 1) + 
                history["execution_time"]
            ) / module_stats[module]["count"]
        
        return {
            "total_invocations": total,
            "avg_execution_time": avg_time,
            "success_rate": successful / total,
            "active_invocations": len(self._active_invocations),
            "module_stats": module_stats
        }
    
    def _handle_session_end(self, session_control: Dict[str, Any]):
        """
        ğŸ†• è™•ç†æœƒè©±çµæŸè«‹æ±‚ï¼ˆé›™æ¢ä»¶çµ‚æ­¢æ©Ÿåˆ¶ - æ¢ä»¶ 1ï¼‰
        
        ç•¶ LLM æ±ºå®šçµæŸæœƒè©±æ™‚ï¼ˆé€šé session_controlï¼‰ï¼š
        âœ… æ¢ä»¶ 1: å¤–éƒ¨ä¸­æ–·é»è¢«å‘¼å« â†’ æ¨™è¨˜ pending_end = True
        âŒ æ¢ä»¶ 2: æ‰€å±¬å¾ªç’°çµæŸ â†’ ç”± Controller åœ¨ CYCLE_COMPLETED æ™‚æª¢æŸ¥ä¸¦åŸ·è¡Œ
        
        é›™æ¢ä»¶çµ‚æ­¢æ©Ÿåˆ¶ï¼š
        1. LLM ç™¼å¸ƒ session_control â†’ MC æ¨™è¨˜ Session.pending_end = Trueï¼ˆæ¢ä»¶ 1ï¼‰
        2. SystemLoop ç™¼å¸ƒ CYCLE_COMPLETED â†’ Controller æª¢æŸ¥ pending_endï¼ˆæ¢ä»¶ 2ï¼‰
        3. å…©å€‹æ¢ä»¶éƒ½æ»¿è¶³æ™‚ï¼ŒController æ‰çœŸæ­£èª¿ç”¨ end_session()
        
        é€™ç¢ºä¿ï¼š
        - âœ… LLM å›æ‡‰èƒ½å®Œæ•´è¼¸å‡º
        - âœ… TTS èƒ½å®ŒæˆèªéŸ³åˆæˆ
        - âœ… å»é‡éµèƒ½æ­£ç¢ºæ¸…ç†
        - âœ… æœƒè©±åœ¨å¾ªç’°é‚Šç•Œä¹¾æ·¨åœ°çµæŸ
        
        Args:
            session_control: æœƒè©±æ§åˆ¶æŒ‡ä»¤
        """
        try:
            info_log("[ModuleCoordinator] ğŸ“‹ æ¨™è¨˜ CS/WS å¾…çµæŸï¼ˆæ¢ä»¶ 1: å¤–éƒ¨ä¸­æ–·é»ï¼‰")
            
            # ç²å–çµæŸåŸå› 
            reason = (session_control.get('reason') or 
                     session_control.get('end_reason') or 
                     'session_control_requested')
            
            # ç²å–æ‰€æœ‰æ´»èºçš„å­æœƒè©±
            from core.sessions.session_manager import unified_session_manager
            
            # æ¨™è¨˜æ‰€æœ‰å·¥ä½œæµæœƒè©± (WS) å¾…çµæŸ
            active_ws = unified_session_manager.get_active_workflow_sessions()
            for ws in active_ws:
                debug_log(2, f"[ModuleCoordinator] æ¨™è¨˜ WS å¾…çµæŸ: {ws.session_id} (åŸå› : {reason})")
                ws.pending_end = True
                ws.pending_end_reason = reason
            
            # æ¨™è¨˜æ‰€æœ‰èŠå¤©æœƒè©± (CS) å¾…çµæŸ
            active_cs = unified_session_manager.get_active_chatting_sessions()
            for cs in active_cs:
                debug_log(2, f"[ModuleCoordinator] æ¨™è¨˜ CS å¾…çµæŸ: {cs.session_id} (åŸå› : {reason})")
                cs.pending_end = True
                cs.pending_end_reason = reason
            
            info_log("[ModuleCoordinator] âœ… CS/WS å·²æ¨™è¨˜å¾…çµæŸï¼Œç­‰å¾…å¾ªç’°å®Œæˆï¼ˆæ¢ä»¶ 2ï¼‰")
            
        except Exception as e:
            error_log(f"[ModuleCoordinator] æ¨™è¨˜æœƒè©±å¾…çµæŸå¤±æ•—: {e}")
    
    def get_deduplication_stats(self) -> Dict[str, Any]:
        """
        ç²å–å»é‡çµ±è¨ˆä¿¡æ¯ (G. ç›£æ§èˆ‡é™¤éŒ¯)
        
        Returns:
            åŒ…å«å»é‡å‘½ä¸­æ¬¡æ•¸ã€æ¸…ç†æ¬¡æ•¸ã€æ´»èºéµæ•¸é‡ç­‰è¨ºæ–·ä¿¡æ¯
        """
        with self._dedupe_lock:
            # åˆ†ææ´»èºçš„ dedupe keys
            active_flows = set()
            layers_count = {"INPUT": 0, "PROCESSING": 0, "OUTPUT": 0}
            
            for key in self._layer_dedupe_keys:
                try:
                    parts = key.split(":")
                    if len(parts) >= 3:
                        session_id = parts[0]
                        cycle_index = parts[1]
                        layer = parts[2]
                        
                        flow_id = f"{session_id}:{cycle_index}"
                        active_flows.add(flow_id)
                        
                        if layer in layers_count:
                            layers_count[layer] += 1
                except:
                    pass
            
            return {
                "dedupe_hit_count": self._dedupe_hit_count,
                "cleanup_count": self._cleanup_count,
                "active_dedupe_keys": len(self._layer_dedupe_keys),
                "max_dedupe_keys": self._max_dedupe_keys,
                "active_flows": len(active_flows),
                "layers_distribution": layers_count,
                "memory_pressure": len(self._layer_dedupe_keys) / self._max_dedupe_keys if self._max_dedupe_keys > 0 else 0.0
            }


# å…¨å±€å”èª¿å™¨å¯¦ä¾‹
module_coordinator = ModuleInvocationCoordinator()