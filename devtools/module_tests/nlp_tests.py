# -*- coding: utf-8 -*-
"""
NLP æ¨¡çµ„æ¸¬è©¦å‡½æ•¸
å·²é‡æ§‹æ¨¡çµ„ - å®Œæ•´åŠŸèƒ½æ¸¬è©¦
"""

from utils.debug_helper import debug_log, info_log, error_log

def nlp_test(modules, text: str = "", enable_identity: bool = True, enable_segmentation: bool = True):
    """æ¸¬è©¦å¢å¼·ç‰ˆNLPæ¨¡çµ„ - åŒ…å«èªè€…èº«ä»½å’Œæ„åœ–åˆ†æ"""
    nlp = modules.get("nlp")
    if nlp is None:
        error_log("[Controller] âŒ ç„¡æ³•è¼‰å…¥ NLP æ¨¡çµ„")
        return

    test_text = text if text else "Hello UEP, please save my work and then play some music"
    
    print(f"\nğŸ§  æ¸¬è©¦å¢å¼·ç‰ˆNLP - æ–‡æœ¬: '{test_text}'")
    print("=" * 60)
    
    # æº–å‚™æ¸¬è©¦è¼¸å…¥
    nlp_input = {
        "text": test_text,
        "speaker_id": "test_speaker_001",
        "speaker_confidence": 0.85,
        "speaker_status": "known",
        "enable_identity_processing": enable_identity,
        "enable_segmentation": enable_segmentation,
        "current_system_state": "idle",
        "conversation_history": []
    }
    
    try:
        result = nlp.handle(nlp_input)
        
        print(f"ğŸ“ åŸå§‹æ–‡æœ¬: {result.get('original_text', 'N/A')}")
        print(f"ğŸ¯ ä¸»è¦æ„åœ–: {result.get('primary_intent', 'N/A')}")
        print(f"ğŸ“Š æ•´é«”ä¿¡å¿ƒåº¦: {result.get('overall_confidence', 0):.3f}")
        
        # èªè€…èº«ä»½ä¿¡æ¯
        identity = result.get('identity')
        if identity:
            print(f"ğŸ‘¤ èªè€…èº«ä»½: {identity.get('identity_id', 'N/A')}")
            print(f"ğŸ”„ èº«ä»½å‹•ä½œ: {result.get('identity_action', 'N/A')}")
        else:
            print("ğŸ‘¤ èªè€…èº«ä»½: æœªè­˜åˆ¥")
        
        # æ„åœ–åˆ†æ®µ
        segments = result.get('intent_segments', [])
        print(f"\nğŸ“‹ æ„åœ–åˆ†æ®µ ({len(segments)}å€‹):")
        for i, segment in enumerate(segments, 1):
            if hasattr(segment, 'text'):
                print(f"  {i}. '{segment.text}' -> {segment.intent} (ä¿¡å¿ƒåº¦: {segment.confidence:.3f})")
            else:
                print(f"  {i}. '{segment.get('text', 'N/A')}' -> {segment.get('intent', 'N/A')}")
        
        # ä¸Šä¸‹æ–‡ä¿¡æ¯
        context_ids = result.get('context_ids', [])
        if context_ids:
            print(f"\nğŸ”— å‰µå»ºçš„ä¸Šä¸‹æ–‡: {len(context_ids)}å€‹")
            for ctx_id in context_ids:
                print(f"  - {ctx_id}")
        
        # åŸ·è¡Œè¨ˆåŠƒ
        execution_plan = result.get('execution_plan', [])
        if execution_plan:
            print(f"\nğŸ“‹ åŸ·è¡Œè¨ˆåŠƒ:")
            for plan_item in execution_plan:
                print(f"  æ­¥é©Ÿ{plan_item.get('step', 'N/A')}: {plan_item.get('description', 'N/A')} (å„ªå…ˆç´š: {plan_item.get('priority', 'N/A')})")
        
        # ç‹€æ…‹è½‰æ›
        state_transition = result.get('state_transition')
        if state_transition:
            print(f"\nğŸ”„ ç‹€æ…‹è½‰æ›: {state_transition}")
        
        # ä¸‹ä¸€æ­¥æ¨¡çµ„
        next_modules = result.get('next_modules', [])
        if next_modules:
            print(f"â¡ï¸ ä¸‹ä¸€æ­¥æ¨¡çµ„: {', '.join(next_modules)}")
        
        # è™•ç†è¨»è¨˜
        processing_notes = result.get('processing_notes', [])
        if processing_notes:
            print(f"\nğŸ“ è™•ç†è¨»è¨˜:")
            for note in processing_notes:
                print(f"  - {note}")
        
        return result
        
    except Exception as e:
        error_log(f"[NLP] å¢å¼·ç‰ˆæ¸¬è©¦å¤±æ•—: {e}")
        return None

def nlp_test_state_queue_integration(modules, text: str = ""):
    """æ¸¬è©¦NLPèˆ‡ç‹€æ…‹ä½‡åˆ—çš„æ•´åˆ"""
    nlp = modules.get("nlp")    
    
    if nlp is None:
        error_log("[Controller] âŒ ç„¡æ³•è¼‰å…¥ NLP æ¨¡çµ„")
        return

    from core.state_queue import get_state_queue_manager
    state_queue = get_state_queue_manager()

    test_text = text if text else "Hi UEP, how are you? Please save my work and then remind me about the meeting."
    
    print(f"\nğŸ”„ æ¸¬è©¦NLPèˆ‡ç‹€æ…‹ä½‡åˆ—æ•´åˆ")
    print(f"ğŸ“ æ¸¬è©¦æ–‡æœ¬: '{test_text}'")
    print("=" * 80)
    
    # æ¸…ç©ºä½‡åˆ—é–‹å§‹æ¸¬è©¦
    state_queue.clear_queue()
    print(f"ğŸ§¹ æ¸…ç©ºç‹€æ…‹ä½‡åˆ—")
    
    # é¡¯ç¤ºåˆå§‹ç‹€æ…‹
    initial_status = state_queue.get_queue_status()
    print(f"ğŸ åˆå§‹ç‹€æ…‹: {initial_status['current_state']}")
    print(f"ğŸ“‹ åˆå§‹ä½‡åˆ—é•·åº¦: {initial_status['queue_length']}")
    
    # åŸ·è¡ŒNLPåˆ†æ
    result = nlp_test(test_text, enable_segmentation=True)
    
    # é¡¯ç¤ºåˆ†æå¾Œçš„ç‹€æ…‹ä½‡åˆ—
    print(f"\nğŸ“Š NLPåˆ†æå¾Œçš„ç‹€æ…‹ä½‡åˆ—:")
    final_status = state_queue.get_queue_status()
    print(f"ğŸ¯ ç•¶å‰ç‹€æ…‹: {final_status['current_state']}")
    print(f"ğŸ“‹ ä½‡åˆ—é•·åº¦: {final_status['queue_length']}")
    
    if final_status['queue_items']:
        print(f"ğŸ“ ä½‡åˆ—å…§å®¹:")
        for i, item in enumerate(final_status['queue_items'], 1):
            print(f"  {i}. {item['state']} (å„ªå…ˆç´š: {item['priority']})")
            print(f"     è§¸ç™¼: {item['trigger_content']}")
            print(f"     ä¸Šä¸‹æ–‡: {item['context_content']}")
            print()
    
    return result

def nlp_test_multi_intent(modules, text: str = ""):
    """æ¸¬è©¦å¤šæ„åœ–ä¸Šä¸‹æ–‡ç®¡ç†"""
    nlp = modules.get("nlp")
    if nlp is None:
        error_log("[Controller] âŒ ç„¡æ³•è¼‰å…¥ NLP æ¨¡çµ„")
        return

    test_text = text if text else "Hey system, please save my document and then remind me about the meeting tomorrow"
    
    print(f"\nğŸ”„ æ¸¬è©¦å¤šæ„åœ–ä¸Šä¸‹æ–‡ç®¡ç†")
    print(f"ğŸ“ æ¸¬è©¦æ–‡æœ¬: '{test_text}'")
    print("=" * 70)
    
    result = nlp_test(test_text, enable_segmentation=True)
    
    if result and hasattr(nlp, 'intent_analyzer'):
        analyzer = nlp.intent_analyzer
        
        # ç²å–ä¸Šä¸‹æ–‡æ‘˜è¦
        context_summary = analyzer.get_context_summary()
        print(f"\nğŸ“Š ä¸Šä¸‹æ–‡ç®¡ç†æ‘˜è¦:")
        print(f"  æ´»èºä¸Šä¸‹æ–‡: {context_summary.get('active_contexts', 0)}")
        print(f"  å¾…åŸ·è¡Œä¸Šä¸‹æ–‡: {context_summary.get('pending_contexts', 0)}")
        print(f"  å·²å®Œæˆä¸Šä¸‹æ–‡: {context_summary.get('completed_contexts', 0)}")
        
        # ç²å–ä¸‹ä¸€å€‹å¯åŸ·è¡Œçš„ä¸Šä¸‹æ–‡
        next_context = analyzer.get_next_context()
        if next_context:
            state, context = next_context
            print(f"\nâ¡ï¸ ä¸‹ä¸€å€‹å¯åŸ·è¡Œä¸Šä¸‹æ–‡:")
            print(f"  ä¸Šä¸‹æ–‡ID: {context.context_id}")
            print(f"  é¡å‹: {context.context_type.value}")
            print(f"  ä»»å‹™æè¿°: {context.task_description or context.conversation_topic}")
            print(f"  å„ªå…ˆç´š: {context.priority}")
        else:
            print(f"\nâ¡ï¸ ç„¡å¾…åŸ·è¡Œçš„ä¸Šä¸‹æ–‡")

def nlp_test_identity_management(modules, speaker_id: str = "test_user"):
    """æ¸¬è©¦èªè€…èº«ä»½ç®¡ç†"""
    nlp = modules.get("nlp")
    if nlp is None:
        error_log("[Controller] âŒ ç„¡æ³•è¼‰å…¥ NLP æ¨¡çµ„")
        return

    print(f"\nğŸ‘¤ æ¸¬è©¦èªè€…èº«ä»½ç®¡ç† - èªè€…ID: {speaker_id}")
    print("=" * 50)
    
    # å¤šæ¬¡äº¤äº’æ¸¬è©¦èº«ä»½ç´¯ç©å’Œè­˜åˆ¥
    test_interactions = [
        "Hello, I'm testing the system",
        "Can you help me organize my files?", 
        "I want to schedule a meeting for tomorrow",
        "Play my favorite music please"
    ]
    
    for i, text in enumerate(test_interactions, 1):
        print(f"\n--- äº¤äº’ {i} ---")
        
        nlp_input = {
            "text": text,
            "speaker_id": speaker_id,
            "speaker_confidence": 0.8 + (i * 0.05),  # é€æ¼¸æé«˜ä¿¡å¿ƒåº¦
            "speaker_status": "known" if i > 2 else "accumulating",
            "enable_identity_processing": True,
            "enable_segmentation": True
        }
        
        result = nlp.handle(nlp_input)
        
        print(f"æ–‡æœ¬: '{text}'")
        print(f"èº«ä»½å‹•ä½œ: {result.get('identity_action', 'N/A')}")
        
        identity = result.get('identity')
        if identity:
            print(f"èº«ä»½ID: {identity.get('identity_id', 'N/A')}")
            print(f"äº’å‹•æ¬¡æ•¸: {identity.get('interaction_stats', {}).get('total_interactions', 0)}")

def nlp_analyze_context_queue(modules):
    """åˆ†æNLPæ¨¡çµ„çš„ä¸Šä¸‹æ–‡ä½‡åˆ—ç‹€æ…‹"""
    nlp = modules.get("nlp")
    if nlp is None:
        error_log("[Controller] âŒ ç„¡æ³•è¼‰å…¥ NLP æ¨¡çµ„")
        return

    if not hasattr(nlp, 'context_manager'):
        print("âŒ NLPæ¨¡çµ„æ²’æœ‰ä¸Šä¸‹æ–‡ç®¡ç†å™¨")
        return

    context_manager = nlp.context_manager
    
    print(f"\nğŸ“Š å¤šæ„åœ–ä¸Šä¸‹æ–‡ä½‡åˆ—åˆ†æ")
    print("=" * 40)
    
    # ç²å–ä½‡åˆ—ç‹€æ…‹
    summary = context_manager.get_context_summary()
    
    print(f"ç¸½ä¸Šä¸‹æ–‡æ•¸: {len(context_manager.contexts)}")
    print(f"æ´»èºä¸Šä¸‹æ–‡: {len(context_manager.active_contexts)}")
    print(f"å·²å®Œæˆä¸Šä¸‹æ–‡: {len(context_manager.completed_contexts)}")
    print(f"ä½‡åˆ—é•·åº¦: {len(context_manager.state_queue)}")
    
    # é¡¯ç¤ºæ´»èºä¸Šä¸‹æ–‡è©³æƒ…
    if context_manager.active_contexts:
        print(f"\nğŸ”„ æ´»èºä¸Šä¸‹æ–‡:")
        for ctx_id in context_manager.active_contexts:
            if ctx_id in context_manager.contexts:
                ctx = context_manager.contexts[ctx_id]
                print(f"  {ctx_id}: {ctx.context_type.value} - {ctx.task_description or ctx.conversation_topic}")
    
    # é¡¯ç¤ºä½‡åˆ—ä¸­çš„æ¢ç›®
    if context_manager.state_queue:
        print(f"\nğŸ“‹ ä½‡åˆ—æ¢ç›®:")
        for i, entry in enumerate(context_manager.state_queue[:5]):  # åªé¡¯ç¤ºå‰5å€‹
            ctx = entry.context
            print(f"  {i+1}. {ctx.context_id}: {ctx.context_type.value} (å„ªå…ˆç´š: {ctx.priority})")
        
        if len(context_manager.state_queue) > 5:
            print(f"  ... é‚„æœ‰ {len(context_manager.state_queue) - 5} å€‹æ¢ç›®")

def nlp_clear_contexts(modules):
    """æ¸…ç©ºNLPæ¨¡çµ„çš„ä¸Šä¸‹æ–‡"""
    nlp = modules.get("nlp")
    if nlp is None:
        error_log("[Controller] âŒ ç„¡æ³•è¼‰å…¥ NLP æ¨¡çµ„")
        return

    if not hasattr(nlp, 'context_manager'):
        print("âŒ NLPæ¨¡çµ„æ²’æœ‰ä¸Šä¸‹æ–‡ç®¡ç†å™¨")
        return

    context_manager = nlp.context_manager
    
    # æ¸…ç©ºä¸Šä¸‹æ–‡
    context_manager.contexts.clear()
    context_manager.active_contexts.clear()
    context_manager.completed_contexts.clear()
    context_manager.state_queue.clear()
    context_manager.dependency_graph.clear()
    
    print("âœ… å·²æ¸…ç©ºæ‰€æœ‰NLPä¸Šä¸‹æ–‡")