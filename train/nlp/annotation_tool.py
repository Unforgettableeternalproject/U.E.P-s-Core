#!/usr/bin/env python3
"""
å¯¦ç”¨çš„æ•¸æ“šæ”¶é›†å’Œæ¨™è¨»å·¥å…·
æ›¿ä»£è‡ªå‹•ç”Ÿæˆå™¨ï¼Œæ”¯æ´æ‰‹å·¥æ¨™è¨»å’Œè³ªé‡æ§åˆ¶
"""

import json
import re
import pandas as pd
from pathlib import Path
from typing import List, Dict, Any, Tuple, Optional
from dataclasses import dataclass, asdict
from datetime import datetime
import hashlib

@dataclass
class SegmentAnnotation:
    """åˆ†æ®µæ¨™è¨»"""
    text: str
    label: str  # CALL, CHAT, COMMAND, COMPOUND
    start: int
    end: int
    confidence: float = 1.0
    annotator_notes: str = ""

@dataclass 
class TrainingExample:
    """è¨“ç·´ç¯„ä¾‹"""
    id: str
    text: str
    segments: List[SegmentAnnotation]
    metadata: Dict[str, Any]
    
    def to_dict(self) -> Dict[str, Any]:
        """è½‰æ›ç‚ºå­—å…¸"""
        return {
            'id': self.id,
            'text': self.text,
            'segments': [asdict(seg) for seg in self.segments],
            'metadata': self.metadata
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'TrainingExample':
        """å¾å­—å…¸å‰µå»º"""
        segments = [SegmentAnnotation(**seg) for seg in data['segments']]
        return cls(
            id=data['id'],
            text=data['text'],
            segments=segments,
            metadata=data['metadata']
        )

class AnnotationTool:
    """æ¨™è¨»å·¥å…·"""
    
    def __init__(self, data_dir: str = "./train/nlp/data"):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # å­ç›®éŒ„
        self.raw_dir = self.data_dir / "raw"
        self.annotated_dir = self.data_dir / "annotated"
        self.metadata_dir = self.data_dir / "metadata"
        self.statistics_dir = self.data_dir / "statistics"
        
        for dir_path in [self.raw_dir, self.annotated_dir, self.metadata_dir, self.statistics_dir]:
            dir_path.mkdir(exist_ok=True)
        
        self.examples: List[TrainingExample] = []
        self.load_existing_data()
    
    def load_existing_data(self):
        """è¼‰å…¥å·²æœ‰çš„æ¨™è¨»æ•¸æ“š"""
        annotated_files = list(self.annotated_dir.glob("*.jsonl"))
        
        for file_path in annotated_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        if line.strip():
                            data = json.loads(line)
                            example = TrainingExample.from_dict(data)
                            self.examples.append(example)
                            
                print(f"âœ… è¼‰å…¥äº† {len(self.examples)} å€‹å·²æ¨™è¨»ç¯„ä¾‹ from {file_path}")
            except Exception as e:
                print(f"âš ï¸  è¼‰å…¥ {file_path} å¤±æ•—: {e}")
    
    def add_raw_text(self, text: str, source: str = "manual", 
                    scenario: str = "unknown") -> str:
        """æ·»åŠ åŸå§‹æ–‡æœ¬æº–å‚™æ¨™è¨»"""
        # ç”Ÿæˆå”¯ä¸€ID
        text_hash = hashlib.md5(text.encode()).hexdigest()[:8]
        example_id = f"{scenario}_{text_hash}"
        
        # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
        existing_ids = [ex.id for ex in self.examples]
        if example_id in existing_ids:
            print(f"âš ï¸  æ–‡æœ¬å·²å­˜åœ¨: {example_id}")
            return example_id
        
        # å‰µå»ºç¯„ä¾‹
        example = TrainingExample(
            id=example_id,
            text=text,
            segments=[],  # å¾…æ¨™è¨»
            metadata={
                'source': source,
                'scenario': scenario,
                'created_date': datetime.now().isoformat(),
                'annotated': False,
                'quality_checked': False
            }
        )
        
        self.examples.append(example)
        print(f"âœ… æ·»åŠ äº†å¾…æ¨™è¨»æ–‡æœ¬: {example_id}")
        return example_id
    
    def annotate_example(self, example_id: str, segments: List[Dict[str, Any]], 
                        annotator: str = "unknown") -> bool:
        """æ¨™è¨»ç¯„ä¾‹"""
        # æ‰¾åˆ°ç¯„ä¾‹
        example = None
        for ex in self.examples:
            if ex.id == example_id:
                example = ex
                break
        
        if not example:
            print(f"âŒ æ‰¾ä¸åˆ°ç¯„ä¾‹: {example_id}")
            return False
        
        # é©—è­‰åˆ†æ®µ
        if not self._validate_segments(example.text, segments):
            print(f"âŒ åˆ†æ®µé©—è­‰å¤±æ•—: {example_id}")
            return False
        
        # å‰µå»ºåˆ†æ®µæ¨™è¨»
        segment_annotations = []
        for seg in segments:
            annotation = SegmentAnnotation(
                text=seg['text'],
                label=seg['label'],
                start=seg['start'],
                end=seg['end'],
                confidence=seg.get('confidence', 1.0),
                annotator_notes=seg.get('notes', '')
            )
            segment_annotations.append(annotation)
        
        # æ›´æ–°ç¯„ä¾‹
        example.segments = segment_annotations
        example.metadata.update({
            'annotated': True,
            'annotator': annotator,
            'annotation_date': datetime.now().isoformat()
        })
        
        print(f"âœ… å®Œæˆæ¨™è¨»: {example_id} ({len(segments)} å€‹åˆ†æ®µ)")
        return True
    
    def _validate_segments(self, text: str, segments: List[Dict[str, Any]]) -> bool:
        """é©—è­‰åˆ†æ®µçš„åˆæ³•æ€§"""
        # æª¢æŸ¥åŸºæœ¬æ¬„ä½
        for seg in segments:
            required_fields = ['text', 'label', 'start', 'end']
            if not all(field in seg for field in required_fields):
                print(f"âŒ åˆ†æ®µç¼ºå°‘å¿…è¦æ¬„ä½: {seg}")
                return False
            
            # æª¢æŸ¥ä½ç½®
            start, end = seg['start'], seg['end']
            if start >= end or end > len(text):
                print(f"âŒ ç„¡æ•ˆçš„åˆ†æ®µä½ç½®: [{start}, {end}] for text length {len(text)}")
                return False
            
            # æª¢æŸ¥æ–‡æœ¬ä¸€è‡´æ€§
            segment_text = text[start:end]
            if segment_text != seg['text']:
                print(f"âŒ åˆ†æ®µæ–‡æœ¬ä¸åŒ¹é…: '{segment_text}' != '{seg['text']}'")
                return False
            
            # æª¢æŸ¥æ¨™ç±¤æœ‰æ•ˆæ€§
            valid_labels = ['CALL', 'CHAT', 'COMMAND', 'COMPOUND']
            if seg['label'] not in valid_labels:
                print(f"âŒ ç„¡æ•ˆçš„æ¨™ç±¤: {seg['label']}")
                return False
        
        # æª¢æŸ¥é‡ç–Š
        segments_sorted = sorted(segments, key=lambda x: x['start'])
        for i in range(len(segments_sorted) - 1):
            if segments_sorted[i]['end'] > segments_sorted[i+1]['start']:
                print(f"âŒ åˆ†æ®µé‡ç–Š: {segments_sorted[i]} å’Œ {segments_sorted[i+1]}")
                return False
        
        return True
    
    def export_training_data(self, format_type: str = "both", 
                           train_ratio: float = 0.7, dev_ratio: float = 0.15):
        """å°å‡ºè¨“ç·´æ•¸æ“š"""
        # åªå°å‡ºå·²æ¨™è¨»çš„æ•¸æ“š
        annotated_examples = [ex for ex in self.examples if ex.metadata.get('annotated', False)]
        
        if not annotated_examples:
            print("âŒ æ²’æœ‰å·²æ¨™è¨»çš„æ•¸æ“šå¯å°å‡º")
            return
        
        print(f"ğŸ“Š æº–å‚™å°å‡º {len(annotated_examples)} å€‹å·²æ¨™è¨»ç¯„ä¾‹")
        
        # æ•¸æ“šåˆ†å‰²
        import random
        random.shuffle(annotated_examples)
        
        total = len(annotated_examples)
        train_size = int(total * train_ratio)
        dev_size = int(total * dev_ratio)
        
        train_data = annotated_examples[:train_size]
        dev_data = annotated_examples[train_size:train_size + dev_size]
        test_data = annotated_examples[train_size + dev_size:]
        
        print(f"ğŸ“‹ æ•¸æ“šåˆ†å‰²: Train={len(train_data)}, Dev={len(dev_data)}, Test={len(test_data)}")
        
        # å°å‡ºJSONLæ ¼å¼
        if format_type in ["jsonl", "both"]:
            self._export_jsonl(train_data, "train.jsonl")
            self._export_jsonl(dev_data, "dev.jsonl") 
            self._export_jsonl(test_data, "test.jsonl")
        
        # å°å‡ºCoNLL-Uæ ¼å¼
        if format_type in ["conllu", "both"]:
            self._export_conllu(train_data, "train.conllu")
            self._export_conllu(dev_data, "dev.conllu")
            self._export_conllu(test_data, "test.conllu")
        
        # ç”Ÿæˆçµ±è¨ˆå ±å‘Š
        self._generate_statistics(annotated_examples)
    
    def _export_jsonl(self, examples: List[TrainingExample], filename: str):
        """å°å‡ºJSONLæ ¼å¼"""
        filepath = self.annotated_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            for example in examples:
                # è½‰æ›ç‚ºè¨“ç·´æ ¼å¼
                training_data = {
                    'id': example.id,
                    'text': example.text,
                    'tokens': example.text.split(),  # ç°¡åŒ–åˆ†è©
                    'bio_labels': self._segments_to_bio(example),
                    'segments': [asdict(seg) for seg in example.segments],
                    'metadata': example.metadata
                }
                f.write(json.dumps(training_data, ensure_ascii=False) + '\n')
        
        print(f"âœ… JSONLæ ¼å¼å·²å°å‡º: {filepath}")
    
    def _export_conllu(self, examples: List[TrainingExample], filename: str):
        """å°å‡ºCoNLL-Uæ ¼å¼"""
        filepath = self.annotated_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            for example in examples:
                # å¯«å…¥å…ƒæ•¸æ“š
                f.write(f"# sent_id = {example.id}\n")
                f.write(f"# text = {example.text}\n")
                f.write(f"# intent_segments = {json.dumps([asdict(seg) for seg in example.segments])}\n")
                f.write(f"# metadata = {json.dumps(example.metadata)}\n")
                
                # å¯«å…¥tokenå’ŒBIOæ¨™ç±¤
                tokens = example.text.split()  # ç°¡åŒ–åˆ†è©
                bio_labels = self._segments_to_bio(example)
                
                for i, (token, label) in enumerate(zip(tokens, bio_labels), 1):
                    f.write(f"{i}\t{token}\t_\t_\t_\t_\t_\t_\t{label}\t_\n")
                
                f.write("\n")  # å¥å­åˆ†éš”
        
        print(f"âœ… CoNLL-Uæ ¼å¼å·²å°å‡º: {filepath}")
    
    def _segments_to_bio(self, example: TrainingExample) -> List[str]:
        """å°‡åˆ†æ®µè½‰æ›ç‚ºBIOæ¨™ç±¤"""
        tokens = example.text.split()
        bio_labels = ['O'] * len(tokens)
        
        for segment in example.segments:
            # æ‰¾åˆ°tokenç¯„åœ (ç°¡åŒ–ç‰ˆæœ¬)
            char_pos = 0
            token_start = None
            token_end = None
            
            for i, token in enumerate(tokens):
                token_char_start = char_pos
                token_char_end = char_pos + len(token)
                
                # æ‰¾åˆ°ç¬¬ä¸€å€‹ç›¸äº¤çš„token
                if token_start is None and token_char_end > segment.start:
                    token_start = i
                
                # æ‰¾åˆ°æœ€å¾Œä¸€å€‹ç›¸äº¤çš„token
                if token_char_start < segment.end:
                    token_end = i
                
                char_pos = token_char_end + 1  # +1 for space
            
            # æ¨™è¨˜BIOæ¨™ç±¤
            if token_start is not None and token_end is not None:
                for i in range(token_start, token_end + 1):
                    if i == token_start:
                        bio_labels[i] = f'B-{segment.label}'
                    else:
                        bio_labels[i] = f'I-{segment.label}'
        
        return bio_labels
    
    def _generate_statistics(self, examples: List[TrainingExample]):
        """ç”Ÿæˆæ•¸æ“šçµ±è¨ˆ"""
        stats = {
            'total_examples': len(examples),
            'label_distribution': {},
            'length_distribution': {
                'min': float('inf'),
                'max': 0,
                'avg': 0,
                'tokens': []
            },
            'complexity_distribution': {
                'single_intent': 0,
                'multi_intent': 0
            },
            'quality_metrics': {
                'annotated_examples': len(examples),
                'avg_segments_per_example': 0
            }
        }
        
        total_segments = 0
        total_length = 0
        
        for example in examples:
            # é•·åº¦çµ±è¨ˆ
            text_length = len(example.text)
            token_count = len(example.text.split())
            
            total_length += text_length
            stats['length_distribution']['min'] = min(stats['length_distribution']['min'], text_length)
            stats['length_distribution']['max'] = max(stats['length_distribution']['max'], text_length)
            stats['length_distribution']['tokens'].append(token_count)
            
            # æ¨™ç±¤åˆ†ä½ˆ
            for segment in example.segments:
                label = segment.label
                stats['label_distribution'][label] = stats['label_distribution'].get(label, 0) + 1
                total_segments += 1
            
            # è¤‡é›œåº¦åˆ†ä½ˆ
            if len(example.segments) == 1:
                stats['complexity_distribution']['single_intent'] += 1
            else:
                stats['complexity_distribution']['multi_intent'] += 1
        
        # è¨ˆç®—å¹³å‡å€¼
        if examples:
            stats['length_distribution']['avg'] = total_length / len(examples)
            stats['quality_metrics']['avg_segments_per_example'] = total_segments / len(examples)
        
        # ä¿å­˜çµ±è¨ˆ
        stats_file = self.statistics_dir / "data_statistics.json"
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(stats, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“Š æ•¸æ“šçµ±è¨ˆå·²ä¿å­˜: {stats_file}")
        print(f"   ç¸½ç¯„ä¾‹æ•¸: {stats['total_examples']}")
        print(f"   æ¨™ç±¤åˆ†ä½ˆ: {stats['label_distribution']}")
        print(f"   å¹³å‡é•·åº¦: {stats['length_distribution']['avg']:.1f} å­—ç¬¦")
        print(f"   è¤‡é›œåº¦åˆ†ä½ˆ: {stats['complexity_distribution']}")
    
    def interactive_annotation(self):
        """äº’å‹•å¼æ¨™è¨»ä»‹é¢"""
        print("ğŸ·ï¸  é€²å…¥äº’å‹•å¼æ¨™è¨»æ¨¡å¼")
        print("è¼¸å…¥ 'help' æŸ¥çœ‹å‘½ä»¤åˆ—è¡¨ï¼Œè¼¸å…¥ 'quit' é€€å‡º")
        
        while True:
            try:
                command = input("\nğŸ“ > ").strip()
                
                if command == 'quit':
                    break
                elif command == 'help':
                    self._show_help()
                elif command.startswith('add '):
                    text = command[4:].strip()
                    if text:
                        example_id = self.add_raw_text(text)
                        print(f"âœ… æ–‡æœ¬å·²æ·»åŠ ï¼ŒID: {example_id}")
                elif command.startswith('list'):
                    self._list_examples()
                elif command.startswith('annotate '):
                    example_id = command[9:].strip()
                    self._interactive_annotate(example_id)
                elif command == 'export':
                    self.export_training_data()
                elif command == 'stats':
                    annotated = [ex for ex in self.examples if ex.metadata.get('annotated', False)]
                    if annotated:
                        self._generate_statistics(annotated)
                    else:
                        print("âŒ æ²’æœ‰å·²æ¨™è¨»çš„æ•¸æ“š")
                else:
                    print(f"â“ æœªçŸ¥å‘½ä»¤: {command}")
                    
            except KeyboardInterrupt:
                print("\nğŸ‘‹ å†è¦‹ï¼")
                break
            except Exception as e:
                print(f"âŒ éŒ¯èª¤: {e}")
    
    def _show_help(self):
        """é¡¯ç¤ºå¹«åŠ©"""
        help_text = """
ğŸ“š å‘½ä»¤åˆ—è¡¨:
  add <text>        - æ·»åŠ å¾…æ¨™è¨»æ–‡æœ¬
  list             - åˆ—å‡ºæ‰€æœ‰ç¯„ä¾‹
  annotate <id>    - æ¨™è¨»æŒ‡å®šç¯„ä¾‹
  export           - å°å‡ºè¨“ç·´æ•¸æ“š
  stats            - é¡¯ç¤ºçµ±è¨ˆä¿¡æ¯
  help             - é¡¯ç¤ºæ­¤å¹«åŠ©
  quit             - é€€å‡º
        """
        print(help_text)
    
    def _list_examples(self):
        """åˆ—å‡ºç¯„ä¾‹"""
        if not self.examples:
            print("ğŸ“­ æ²’æœ‰ç¯„ä¾‹")
            return
        
        print(f"\nğŸ“‹ ç¯„ä¾‹åˆ—è¡¨ (å…± {len(self.examples)} å€‹):")
        for ex in self.examples[-10:]:  # åªé¡¯ç¤ºæœ€å¾Œ10å€‹
            status = "âœ…" if ex.metadata.get('annotated', False) else "â³"
            print(f"  {status} {ex.id}: {ex.text[:50]}...")
    
    def _interactive_annotate(self, example_id: str):
        """äº’å‹•å¼æ¨™è¨»"""
        example = None
        for ex in self.examples:
            if ex.id == example_id:
                example = ex
                break
        
        if not example:
            print(f"âŒ æ‰¾ä¸åˆ°ç¯„ä¾‹: {example_id}")
            return
        
        print(f"\nğŸ“ æ¨™è¨»ç¯„ä¾‹: {example_id}")
        print(f"æ–‡æœ¬: {example.text}")
        print("\nè«‹è¼¸å…¥åˆ†æ®µä¿¡æ¯ (æ ¼å¼: start,end,label,text)")
        print("ä¾‹å¦‚: 0,5,CALL,Hello")
        print("è¼¸å…¥ 'done' å®Œæˆæ¨™è¨»")
        
        segments = []
        while True:
            try:
                line = input("åˆ†æ®µ > ").strip()
                
                if line == 'done':
                    break
                elif line == 'cancel':
                    print("âŒ å–æ¶ˆæ¨™è¨»")
                    return
                
                parts = line.split(',', 3)
                if len(parts) != 4:
                    print("âŒ æ ¼å¼éŒ¯èª¤ï¼Œè«‹ä½¿ç”¨: start,end,label,text")
                    continue
                
                start, end, label, text = parts
                start, end = int(start), int(end)
                
                segment = {
                    'start': start,
                    'end': end,
                    'label': label.upper(),
                    'text': text,
                    'confidence': 1.0
                }
                
                segments.append(segment)
                print(f"âœ… æ·»åŠ åˆ†æ®µ: {segment}")
                
            except ValueError:
                print("âŒ ä½ç½®å¿…é ˆæ˜¯æ•¸å­—")
            except Exception as e:
                print(f"âŒ éŒ¯èª¤: {e}")
        
        if segments:
            if self.annotate_example(example_id, segments):
                print("âœ… æ¨™è¨»å®Œæˆ")
            else:
                print("âŒ æ¨™è¨»å¤±æ•—")
        else:
            print("âŒ æ²’æœ‰æœ‰æ•ˆçš„åˆ†æ®µ")


def main():
    """ä¸»å‡½æ•¸ - æ¼”ç¤ºç”¨æ³•"""
    tool = AnnotationTool()
    
    # ç¤ºä¾‹ï¼šæ·»åŠ ä¸€äº›æ–‡æœ¬
    examples = [
        "Hello, are you there? I was thinking about the weather today.",
        "Hi UEP! How has your day been? Please set a reminder for my meeting.",
        "Hey there, the weather is beautiful today. Can you check my calendar?",
        "Hello! I just finished watching a great movie. Could you help me find more movies like it?"
    ]
    
    for text in examples:
        tool.add_raw_text(text, source="demo", scenario="daily_chat")
    
    print(f"ğŸ“‹ æ·»åŠ äº† {len(examples)} å€‹å¾…æ¨™è¨»ç¯„ä¾‹")
    print("ğŸ’¡ é‹è¡Œ tool.interactive_annotation() é–‹å§‹æ¨™è¨»")
    
    return tool

if __name__ == "__main__":
    tool = main()
    # å¯ä»¥å–æ¶ˆè¨»é‡‹ä¸‹é¢é€™è¡Œä¾†å•Ÿå‹•äº’å‹•å¼æ¨™è¨»
    # tool.interactive_annotation()
