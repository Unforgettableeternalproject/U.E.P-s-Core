#!/usr/bin/env python3
"""
BIOæ¨™è¨»æ¨¡å‹å…¨é¢æ¸¬è©¦è…³æœ¬
æ¸¬è©¦å„ç¨®å ´æ™¯å’Œé‚Šç•Œæƒ…æ³
"""

import sys
import json
from pathlib import Path
from typing import List, Dict, Any, Tuple
import pandas as pd

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°è·¯å¾‘
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from modules.nlp_module.bio_tagger import BIOTagger
from utils.debug_helper import debug_log, info_log, error_log

class BIOModelTester:
    """BIOæ¨¡å‹æ¸¬è©¦å™¨"""
    
    def __init__(self, model_path: str):
        self.model_path = model_path
        self.bio_tagger = BIOTagger()
        self.test_results = []
        
    def load_model(self) -> bool:
        """è¼‰å…¥æ¨¡å‹"""
        try:
            success = self.bio_tagger.load_model(self.model_path)
            if success:
                info_log(f"[Tester] æˆåŠŸè¼‰å…¥æ¨¡å‹: {self.model_path}")
                return True
            else:
                error_log(f"[Tester] æ¨¡å‹è¼‰å…¥å¤±æ•—")
                return False
        except Exception as e:
            error_log(f"[Tester] è¼‰å…¥æ¨¡å‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False
    
    def test_single_intent_examples(self) -> None:
        """æ¸¬è©¦å–®ä¸€æ„åœ–ç¯„ä¾‹"""
        info_log("[Tester] é–‹å§‹æ¸¬è©¦å–®ä¸€æ„åœ–ç¯„ä¾‹...")
        
        test_cases = [
            # CALLæ„åœ–
            ("Hello UEP", [("Hello UEP", "call")]),
            ("Hey assistant", [("Hey assistant", "call")]),
            ("Are you there?", [("Are you there?", "call")]),
            ("System wake up", [("System wake up", "call")]),
            ("Attention please", [("Attention please", "call")]),
            
            # CHATæ„åœ–
            ("The weather is beautiful today", [("The weather is beautiful today", "chat")]),
            ("I had a great day", [("I had a great day", "chat")]),
            ("That's interesting", [("That's interesting", "chat")]),
            ("I'm feeling happy", [("I'm feeling happy", "chat")]),
            ("The movie was amazing", [("The movie was amazing", "chat")]),
            
            # COMMANDæ„åœ–
            ("Set a reminder for tomorrow", [("Set a reminder for tomorrow", "command")]),
            ("Open my calendar", [("Open my calendar", "command")]),
            ("Save this file", [("Save this file", "command")]),
            ("Turn on the lights", [("Turn on the lights", "command")]),
            ("Play some music", [("Play some music", "command")])
        ]
        
        for text, expected in test_cases:
            self._test_case(text, expected, "å–®ä¸€æ„åœ–")
    
    def test_multi_intent_examples(self) -> None:
        """æ¸¬è©¦å¤šæ„åœ–ç¯„ä¾‹"""
        info_log("[Tester] é–‹å§‹æ¸¬è©¦å¤šæ„åœ–ç¯„ä¾‹...")
        
        test_cases = [
            # é›™æ„åœ–
            ("Hello UEP, set a reminder for 3pm", [("Hello UEP", "call"), ("set a reminder for 3pm", "command")]),
            ("I had a great day. Can you help me organize my photos?", [("I had a great day", "chat"), ("Can you help me organize my photos", "command")]),
            ("Hey there, the weather is nice today", [("Hey there", "call"), ("the weather is nice today", "chat")]),
            
            # ä¸‰æ„åœ–
            ("System wake up. I'm feeling excited today. Please open my calendar", 
             [("System wake up", "call"), ("I'm feeling excited today", "chat"), ("Please open my calendar", "command")]),
            ("Hey UEP, that movie was interesting. Can you recommend similar ones?",
             [("Hey UEP", "call"), ("that movie was interesting", "chat"), ("Can you recommend similar ones", "command")])
        ]
        
        for text, expected in test_cases:
            self._test_case(text, expected, "å¤šæ„åœ–")
    
    def test_edge_cases(self) -> None:
        """æ¸¬è©¦é‚Šç•Œæƒ…æ³"""
        info_log("[Tester] é–‹å§‹æ¸¬è©¦é‚Šç•Œæƒ…æ³...")
        
        test_cases = [
            # ç©ºæ–‡æœ¬
            ("", []),
            
            # æ¥µçŸ­æ–‡æœ¬
            ("Hi", [("Hi", "call")]),
            ("OK", [("OK", "chat")]),
            ("Go", [("Go", "command")]),
            
            # æ¥µé•·æ–‡æœ¬
            ("Hello UEP, I hope you're doing well today because I have a really long story to tell you about my amazing adventure in the mountains where I met some incredible people and learned so much about life. Anyway, can you please help me organize all the photos I took during this trip?",
             [("Hello UEP", "call"), ("I hope you're doing well today because I have a really long story to tell you about my amazing adventure in the mountains where I met some incredible people and learned so much about life", "chat"), ("can you please help me organize all the photos I took during this trip", "command")]),
            
            # ç‰¹æ®Šå­—ç¬¦
            ("Hello! Can you help me? Thanks!", [("Hello", "call"), ("Can you help me", "command"), ("Thanks", "chat")]),
            ("@UEP #help $save", [("@UEP", "call"), ("#help $save", "command")]),
            
            # æ•¸å­—å’Œæ¨™é»
            ("UEP, save file_123.txt", [("UEP", "call"), ("save file_123.txt", "command")]),
            ("Set timer for 30 minutes", [("Set timer for 30 minutes", "command")])
        ]
        
        for text, expected in test_cases:
            self._test_case(text, expected, "é‚Šç•Œæƒ…æ³")
    
    def test_ambiguous_cases(self) -> None:
        """æ¸¬è©¦æ¨¡ç³Šæƒ…æ³"""
        info_log("[Tester] é–‹å§‹æ¸¬è©¦æ¨¡ç³Šæƒ…æ³...")
        
        test_cases = [
            # å¯èƒ½æœ‰æ­§ç¾©çš„å¥å­
            ("Can you hear me?", [("Can you hear me", "call")]),  # å¯èƒ½æ˜¯callæˆ–command
            ("I need help", [("I need help", "chat")]),  # å¯èƒ½æ˜¯chatæˆ–command
            ("That's good", [("That's good", "chat")]),  # å¯èƒ½æ˜¯chatæˆ–commandå›æ‡‰
            ("Please", [("Please", "call")]),  # å–®è©å¯èƒ½æœ‰å¤šç¨®è§£é‡‹
            ("Thanks for helping", [("Thanks for helping", "chat")])  # æ„Ÿè¬å¯èƒ½æ˜¯chat
        ]
        
        for text, expected in test_cases:
            # å°æ–¼æ¨¡ç³Šæƒ…æ³ï¼Œæˆ‘å€‘ä¸»è¦æª¢æŸ¥æ˜¯å¦èƒ½æˆåŠŸè­˜åˆ¥ï¼Œä¸å¼·åˆ¶è¦æ±‚ç‰¹å®šæ¨™ç±¤
            self._test_case(text, expected, "æ¨¡ç³Šæƒ…æ³", strict=False)
    
    def test_performance(self) -> None:
        """æ¸¬è©¦æ€§èƒ½"""
        info_log("[Tester] é–‹å§‹æ¸¬è©¦æ€§èƒ½...")
        
        import time
        
        # æ¸¬è©¦å–®æ¬¡é æ¸¬æ™‚é–“
        test_text = "Hello UEP, I had a great day today. Can you help me with my schedule?"
        
        times = []
        for i in range(10):
            start_time = time.time()
            segments = self.bio_tagger.predict(test_text)
            end_time = time.time()
            times.append(end_time - start_time)
        
        avg_time = sum(times) / len(times)
        max_time = max(times)
        min_time = min(times)
        
        info_log(f"[Tester] æ€§èƒ½æ¸¬è©¦çµæœ:")
        info_log(f"   å¹³å‡é æ¸¬æ™‚é–“: {avg_time:.4f}ç§’")
        info_log(f"   æœ€å¤§é æ¸¬æ™‚é–“: {max_time:.4f}ç§’")
        info_log(f"   æœ€å°é æ¸¬æ™‚é–“: {min_time:.4f}ç§’")
        
        # æ€§èƒ½è¦æ±‚ï¼šå¹³å‡é æ¸¬æ™‚é–“æ‡‰è©²å°æ–¼1ç§’
        if avg_time < 1.0:
            info_log(f"âœ… æ€§èƒ½æ¸¬è©¦é€šé (å¹³å‡ {avg_time:.4f}s < 1.0s)")
        else:
            error_log(f"âŒ æ€§èƒ½æ¸¬è©¦å¤±æ•— (å¹³å‡ {avg_time:.4f}s >= 1.0s)")
    
    def test_batch_prediction(self) -> None:
        """æ¸¬è©¦æ‰¹é‡é æ¸¬"""
        info_log("[Tester] é–‹å§‹æ¸¬è©¦æ‰¹é‡é æ¸¬...")
        
        batch_texts = [
            "Hello UEP",
            "I'm having a good day",
            "Set a reminder",
            "Hey there, the weather is nice. Can you help me?",
            "System wake up. That's interesting. Please save this file."
        ]
        
        try:
            for i, text in enumerate(batch_texts):
                segments = self.bio_tagger.predict(text)
                info_log(f"   æ‰¹é‡æ¸¬è©¦ {i+1}: '{text}' -> {len(segments)} å€‹åˆ†æ®µ")
            
            info_log("âœ… æ‰¹é‡é æ¸¬æ¸¬è©¦é€šé")
        except Exception as e:
            error_log(f"âŒ æ‰¹é‡é æ¸¬æ¸¬è©¦å¤±æ•—: {e}")
    
    def _test_case(self, text: str, expected: List[Tuple[str, str]], category: str, strict: bool = True) -> None:
        """æ¸¬è©¦å–®å€‹æ¡ˆä¾‹"""
        try:
            segments = self.bio_tagger.predict(text)
            
            success = True
            details = []
            
            if strict:
                # åš´æ ¼æ¨¡å¼ï¼šæª¢æŸ¥åˆ†æ®µæ•¸é‡å’Œå…§å®¹
                if len(segments) != len(expected):
                    success = False
                    details.append(f"åˆ†æ®µæ•¸é‡ä¸åŒ¹é…: æœŸæœ›{len(expected)}, å¯¦éš›{len(segments)}")
                
                for i, (pred_seg, exp_seg) in enumerate(zip(segments, expected)):
                    exp_text, exp_intent = exp_seg
                    pred_text = pred_seg['text']
                    pred_intent = pred_seg['intent']
                    
                    if pred_intent != exp_intent:
                        success = False
                        details.append(f"åˆ†æ®µ{i+1}æ„åœ–ä¸åŒ¹é…: æœŸæœ›'{exp_intent}', å¯¦éš›'{pred_intent}'")
            else:
                # å¯¬é¬†æ¨¡å¼ï¼šåªæª¢æŸ¥æ˜¯å¦èƒ½æˆåŠŸé æ¸¬
                if len(segments) == 0 and len(expected) > 0:
                    success = False
                    details.append("ç„¡æ³•è­˜åˆ¥ä»»ä½•åˆ†æ®µ")
            
            # è¨˜éŒ„çµæœ
            result = {
                'category': category,
                'text': text,
                'expected': expected,
                'predicted': segments,
                'success': success,
                'details': details
            }
            self.test_results.append(result)
            
            # é¡¯ç¤ºçµæœ
            status = "âœ…" if success else "âŒ"
            info_log(f"  {status} [{category}] '{text[:50]}{'...' if len(text) > 50 else ''}'")
            if not success and details:
                for detail in details:
                    error_log(f"      {detail}")
            
        except Exception as e:
            error_log(f"âŒ [{category}] æ¸¬è©¦å¤±æ•—: '{text}' - {e}")
            result = {
                'category': category,
                'text': text,
                'expected': expected,
                'predicted': [],
                'success': False,
                'details': [f"ç•°å¸¸: {e}"]
            }
            self.test_results.append(result)
    
    def test_validation_data(self) -> None:
        """æ¸¬è©¦é©—è­‰æ•¸æ“šé›†"""
        info_log("[Tester] é–‹å§‹æ¸¬è©¦é©—è­‰æ•¸æ“šé›†...")
        
        val_data_path = "./data/annotated/dev.jsonl"
        if not Path(val_data_path).exists():
            error_log(f"[Tester] é©—è­‰æ•¸æ“šé›†ä¸å­˜åœ¨: {val_data_path}")
            return
        
        try:
            correct_predictions = 0
            total_samples = 0
            
            with open(val_data_path, 'r', encoding='utf-8') as f:
                for i, line in enumerate(f):
                    if i >= 20:  # åªæ¸¬è©¦å‰20å€‹æ¨£æœ¬
                        break
                        
                    if line.strip():
                        data = json.loads(line)
                        text = ' '.join(data['tokens'])
                        expected_labels = data['bio_labels']
                        
                        # é æ¸¬
                        segments = self.bio_tagger.predict(text)
                        
                        # ç°¡å–®è©•ä¼°ï¼šæª¢æŸ¥æ˜¯å¦æœ‰æ­£ç¢ºçš„åˆ†æ®µæ•¸é‡
                        expected_segments = self._count_segments_from_bio(expected_labels)
                        predicted_segments = len(segments)
                        
                        if abs(predicted_segments - expected_segments) <= 1:  # å…è¨±1å€‹åˆ†æ®µçš„èª¤å·®
                            correct_predictions += 1
                        
                        total_samples += 1
            
            accuracy = correct_predictions / total_samples if total_samples > 0 else 0
            info_log(f"[Tester] é©—è­‰æ•¸æ“šé›†æ¸¬è©¦çµæœ:")
            info_log(f"   æ¸¬è©¦æ¨£æœ¬: {total_samples}")
            info_log(f"   æ­£ç¢ºé æ¸¬: {correct_predictions}")
            info_log(f"   æº–ç¢ºç‡: {accuracy:.2%}")
            
            if accuracy >= 0.8:
                info_log("âœ… é©—è­‰æ•¸æ“šé›†æ¸¬è©¦é€šé (æº–ç¢ºç‡ >= 80%)")
            else:
                error_log("âŒ é©—è­‰æ•¸æ“šé›†æ¸¬è©¦å¤±æ•— (æº–ç¢ºç‡ < 80%)")
                
        except Exception as e:
            error_log(f"[Tester] é©—è­‰æ•¸æ“šé›†æ¸¬è©¦å¤±æ•—: {e}")
    
    def _count_segments_from_bio(self, bio_labels: List[str]) -> int:
        """å¾BIOæ¨™ç±¤è¨ˆç®—åˆ†æ®µæ•¸é‡"""
        count = 0
        for label in bio_labels:
            if label.startswith('B-'):
                count += 1
        return count
    
    def generate_test_report(self) -> None:
        """ç”Ÿæˆæ¸¬è©¦å ±å‘Š"""
        info_log("[Tester] ç”Ÿæˆæ¸¬è©¦å ±å‘Š...")
        
        # çµ±è¨ˆçµæœ
        total_tests = len(self.test_results)
        passed_tests = sum(1 for r in self.test_results if r['success'])
        failed_tests = total_tests - passed_tests
        
        # æŒ‰é¡åˆ¥çµ±è¨ˆ
        category_stats = {}
        for result in self.test_results:
            category = result['category']
            if category not in category_stats:
                category_stats[category] = {'total': 0, 'passed': 0}
            category_stats[category]['total'] += 1
            if result['success']:
                category_stats[category]['passed'] += 1
        
        # ç”Ÿæˆå ±å‘Š
        report = {
            'summary': {
                'total_tests': total_tests,
                'passed_tests': passed_tests,
                'failed_tests': failed_tests,
                'success_rate': passed_tests / total_tests if total_tests > 0 else 0
            },
            'category_stats': category_stats,
            'failed_cases': [r for r in self.test_results if not r['success']]
        }
        
        # ä¿å­˜å ±å‘Š
        report_path = "./data/test_report.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # é¡¯ç¤ºæ‘˜è¦
        info_log(f"\nğŸ“Š æ¸¬è©¦å ±å‘Šæ‘˜è¦:")
        info_log(f"   ç¸½æ¸¬è©¦æ•¸: {total_tests}")
        info_log(f"   é€šéæ¸¬è©¦: {passed_tests}")
        info_log(f"   å¤±æ•—æ¸¬è©¦: {failed_tests}")
        info_log(f"   æˆåŠŸç‡: {report['summary']['success_rate']:.2%}")
        
        info_log(f"\nğŸ“‹ åˆ†é¡çµ±è¨ˆ:")
        for category, stats in category_stats.items():
            success_rate = stats['passed'] / stats['total'] if stats['total'] > 0 else 0
            info_log(f"   {category}: {stats['passed']}/{stats['total']} ({success_rate:.2%})")
        
        if failed_tests > 0:
            info_log(f"\nâŒ å¤±æ•—æ¡ˆä¾‹ ({failed_tests}å€‹):")
            for i, result in enumerate(report['failed_cases'][:5], 1):  # åªé¡¯ç¤ºå‰5å€‹
                info_log(f"   {i}. [{result['category']}] {result['text'][:50]}...")
                for detail in result['details'][:2]:  # åªé¡¯ç¤ºå‰2å€‹è©³æƒ…
                    info_log(f"      - {detail}")
            if failed_tests > 5:
                info_log(f"   ... é‚„æœ‰ {failed_tests - 5} å€‹å¤±æ•—æ¡ˆä¾‹")
        
        info_log(f"\nğŸ“ å®Œæ•´å ±å‘Šå·²ä¿å­˜è‡³: {report_path}")
    
    def run_all_tests(self) -> bool:
        """é‹è¡Œæ‰€æœ‰æ¸¬è©¦"""
        info_log("ğŸš€ é–‹å§‹å…¨é¢æ¸¬è©¦BIOæ¨™è¨»æ¨¡å‹...")
        
        if not self.load_model():
            return False
        
        # é‹è¡Œå„ç¨®æ¸¬è©¦
        self.test_single_intent_examples()
        self.test_multi_intent_examples()
        self.test_edge_cases()
        self.test_ambiguous_cases()
        self.test_performance()
        self.test_batch_prediction()
        self.test_validation_data()
        
        # ç”Ÿæˆå ±å‘Š
        self.generate_test_report()
        
        # åˆ¤æ–·æ•´é«”æ˜¯å¦é€šé
        total_tests = len(self.test_results)
        passed_tests = sum(1 for r in self.test_results if r['success'])
        success_rate = passed_tests / total_tests if total_tests > 0 else 0
        
        if success_rate >= 0.8:
            info_log(f"ğŸ‰ æ‰€æœ‰æ¸¬è©¦å®Œæˆï¼æ¨¡å‹è¡¨ç¾è‰¯å¥½ (æˆåŠŸç‡: {success_rate:.2%})")
            return True
        else:
            error_log(f"âš ï¸  æ¨¡å‹éœ€è¦æ”¹é€² (æˆåŠŸç‡: {success_rate:.2%} < 80%)")
            return False

def main():
    """ä¸»å‡½æ•¸"""
    model_path = "../../models/nlp/bio_tagger"
    
    if not Path(model_path).exists():
        error_log(f"[Main] æ¨¡å‹ä¸å­˜åœ¨: {model_path}")
        error_log("[Main] è«‹å…ˆé‹è¡Œ train_bio_model.py è¨“ç·´æ¨¡å‹")
        return
    
    # å‰µå»ºæ¸¬è©¦å™¨
    tester = BIOModelTester(model_path)
    
    # é‹è¡Œæ¸¬è©¦
    success = tester.run_all_tests()
    
    if success:
        info_log("âœ… æ¨¡å‹æ¸¬è©¦é€šéï¼Œå¯ä»¥æŠ•å…¥ä½¿ç”¨ï¼")
    else:
        error_log("âŒ æ¨¡å‹æ¸¬è©¦æœªå®Œå…¨é€šéï¼Œå»ºè­°é€²ä¸€æ­¥èª¿å„ª")

if __name__ == "__main__":
    main()
