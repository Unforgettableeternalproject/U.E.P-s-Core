"""
TTS Module - é‡æ§‹ç‰ˆæœ¬
ä½¿ç”¨ IndexTTS Lite å¼•æ“ï¼Œæ”¯æŒæƒ…æ„Ÿæ§åˆ¶å’Œä¸²æµæ’­æ”¾
"""

import asyncio
import os
import time
import uuid
import enum
from typing import Optional, Dict, Any, List

from core.bases.module_base import BaseModule
from core.working_context import working_context_manager
from core.status_manager import status_manager
from configs.config_loader import load_module_config
from utils.debug_helper import debug_log, debug_log_e, info_log, error_log

from .schemas import TTSInput, TTSOutput
from .lite_engine import IndexTTSLite
from .emotion_mapper import EmotionMapper
from utils.tts_chunker import TTSChunker

import numpy as np
import soundfile as sf
try:
    import simpleaudio as sa
except ImportError:
    sa = None
    error_log("[TTS] simpleaudio library not found. Audio playback will be disabled.")


class PlaybackState(enum.Enum):
    """éŸ³é »æ’­æ”¾ç‹€æ…‹"""
    IDLE = "idle"              # æœªæ’­æ”¾
    PLAYING = "playing"        # æ­£åœ¨æ’­æ”¾
    COMPLETED = "completed"    # æ’­æ”¾å®Œç•¢
    ERROR = "error"            # æ’­æ”¾éŒ¯èª¤


class TTSModule(BaseModule):
    def __init__(self, config=None):
        """
        åˆå§‹åŒ– TTS æ¨¡çµ„
        
        Args:
            config: æ¨¡çµ„é…ç½® (å¦‚æœç‚º None å‰‡å¾ config_tts.yaml åŠ è¼‰)
        """
        self.config = config or load_module_config("tts_module")
        
        # IndexTTS é…ç½®
        self.model_dir = self.config.get("model_dir", "modules/tts_module/checkpoints")
        self.character_dir = self.config.get("character_dir", "modules/tts_module/checkpoints")
        self.default_character = self.config.get("default_character", "uep")
        self.use_fp16 = self.config.get("use_fp16", True)
        self.device = self.config.get("device", "cuda")
        
        # Chunking é…ç½®
        chunking_config = self.config.get("chunking", {})
        self.chunking_threshold = chunking_config.get("threshold", 200)  # å­—ç¬¦æ•¸é–¾å€¼
        self.chunking_enabled = chunking_config.get("enabled", True)
        self.max_tokens_per_chunk = chunking_config.get("max_tokens", 200)  # BPE tokens
        
        # Emotion é…ç½®
        emotion_config = self.config.get("emotion", {})
        self.emotion_max_strength = emotion_config.get("max_strength", 0.3)
        self.default_emotion = emotion_config.get("default", None)  # None = ä½¿ç”¨è§’è‰²åŸè²
        
        # æ’­æ”¾ç‹€æ…‹è¿½è¸ª
        self._playback_state = PlaybackState.IDLE
        self._current_playback_obj = None
        self._playback_lock = asyncio.Lock()
        
        # åˆå§‹åŒ–çµ„ä»¶
        self.engine: Optional[IndexTTSLite] = None
        self.emotion_mapper = EmotionMapper(max_strength=self.emotion_max_strength)
        
        # åˆå§‹åŒ– TTSChunkerï¼ˆç”¨æ–¼é•·æ–‡æœ¬åˆ†æ®µï¼‰
        self.chunker = TTSChunker(
            max_chars=self.chunking_threshold,
            min_chars=50,
            respect_punctuation=True,
            pause_between_chunks=0.1  # æ®µè½é–“çŸ­æš«åœé “
        )
        
        # Working Context å’Œ Status Manager å¼•ç”¨ (ä½¿ç”¨å…¨å±€å–®ä¾‹)
        self.working_context_manager = working_context_manager
        self.status_manager = status_manager
        
        # å‰µå»ºå¿…è¦ç›®éŒ„
        os.makedirs(os.path.join("temp", "tts"), exist_ok=True)
        os.makedirs(os.path.join("outputs", "tts"), exist_ok=True)
    
    def debug(self):
        """Debug æ¨¡å¼ - é¡¯ç¤ºæ¨¡çµ„é…ç½®"""
        debug_log(1, "[TTS] Debug æ¨¡å¼å•Ÿç”¨")
        debug_log(2, f"[TTS] æ¨¡å‹ç›®éŒ„: {self.model_dir}")
        debug_log(2, f"[TTS] è§’è‰²ç›®éŒ„: {self.character_dir}")
        debug_log(2, f"[TTS] é è¨­è§’è‰²: {self.default_character}")
        debug_log(2, f"[TTS] è¨­å‚™: {self.device}, FP16: {self.use_fp16}")
        debug_log(2, f"[TTS] Chunking é–¾å€¼: {self.chunking_threshold}")
        debug_log(2, f"[TTS] æƒ…æ„Ÿå¼·åº¦ä¸Šé™: {self.emotion_max_strength}")
        debug_log(2, f"[TTS] Working Context Manager: {'å·²é€£æ¥' if self.working_context_manager else 'æœªé€£æ¥'}")
        debug_log(2, f"[TTS] Status Manager: {'å·²é€£æ¥' if self.status_manager else 'æœªé€£æ¥'}")
        debug_log(3, f"[TTS] å®Œæ•´é…ç½®: {self.config}")
    
    def initialize(self):
        """åˆå§‹åŒ– TTS æ¨¡çµ„ï¼ŒåŠ è¼‰ IndexTTS å¼•æ“å’Œè§’è‰²"""
        try:
            info_log("[TTS] åˆå§‹åŒ– IndexTTS Lite å¼•æ“...")
            
            # åˆå§‹åŒ– IndexTTS å¼•æ“
            # âœ… å•Ÿç”¨ CUDA kernel ä»¥åŠ é€Ÿ BigVGAN (éœ€è¦ CUDA Toolkit)
            self.engine = IndexTTSLite(
                cfg_path=os.path.join(self.model_dir, "config.yaml"),
                model_dir=self.model_dir,
                use_fp16=self.use_fp16,
                device=self.device,
                use_cuda_kernel=True  # ğŸš€ åŠ é€Ÿ 15-25%
            )
            
            info_log(f"[TTS] IndexTTS å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
            info_log(f"[TTS] è¨­å‚™: {self.device}, FP16: {self.use_fp16}")
            
            # åŠ è¼‰é è¨­è§’è‰²
            character_path = os.path.join(self.character_dir, f"{self.default_character}.pt")
            if os.path.exists(character_path):
                self.engine.load_character(character_path)
                info_log(f"[TTS] å·²åŠ è¼‰è§’è‰²: {self.default_character}")
            else:
                error_log(f"[TTS] æ‰¾ä¸åˆ°è§’è‰²æª”æ¡ˆ: {character_path}")
                return False
            
            info_log(f"[TTS] Chunking å·²{'å•Ÿç”¨' if self.chunking_enabled else 'ç¦ç”¨'}, é–¾å€¼: {self.chunking_threshold} å­—ç¬¦")
            
            return True
            
        except Exception as e:
            error_log(f"[TTS] åˆå§‹åŒ–å¤±æ•—: {str(e)}")
            import traceback
            debug_log(1, f"[TTS] éŒ¯èª¤è©³æƒ…:\n{traceback.format_exc()}")
            return False
    
    def get_playback_state(self) -> PlaybackState:
        """
        ç²å–ç•¶å‰éŸ³é »æ’­æ”¾ç‹€æ…‹
        
        Returns:
            PlaybackState: ç•¶å‰æ’­æ”¾ç‹€æ…‹
        """
        # æª¢æŸ¥æ’­æ”¾å°è±¡æ˜¯å¦ä»åœ¨æ’­æ”¾
        if self._current_playback_obj and sa:
            if self._current_playback_obj.is_playing():
                self._playback_state = PlaybackState.PLAYING
            else:
                if self._playback_state == PlaybackState.PLAYING:
                    self._playback_state = PlaybackState.COMPLETED
        
        return self._playback_state
    
    def _get_emotion_vector_from_status(self) -> Optional[List[float]]:
        """
        å¾ Status Manager ç²å–ç•¶å‰ç³»çµ±æ•¸å€¼ä¸¦æ˜ å°„ç‚ºæƒ…æ„Ÿå‘é‡
        
        Returns:
            Optional[List[float]]: 8D æƒ…æ„Ÿå‘é‡ï¼Œå¦‚æœæ²’æœ‰ Status Manager å‰‡è¿”å› None
        """
        if not self.status_manager:
            debug_log(3, "[TTS] Status Manager æœªé€£æ¥ï¼Œä½¿ç”¨é è¨­æƒ…æ„Ÿ")
            return self.default_emotion
        
        try:
            # å¾ Status Manager ç²å–æ•¸å€¼
            status = self.status_manager.get_status()
            mood = status.get("mood", 0.0)  # type: ignore
            pride = status.get("pride", 0.5)  # type: ignore
            helpfulness = status.get("helpfulness", 0.5)  # type: ignore
            boredom = status.get("boredom", 0.0)  # type: ignore
            
            debug_log(3, f"[TTS] Status Manager æ•¸å€¼: mood={mood:.2f}, pride={pride:.2f}, " +
                         f"help={helpfulness:.2f}, boredom={boredom:.2f}")
            
            # æ˜ å°„ç‚ºæƒ…æ„Ÿå‘é‡
            emotion_vector = self.emotion_mapper.map_from_status_manager(
                mood, pride, helpfulness, boredom  # type: ignore
            )
            
            debug_log(3, f"[TTS] æ˜ å°„æƒ…æ„Ÿå‘é‡: {[f'{v:.3f}' for v in emotion_vector]}")
            
            return emotion_vector
            
        except Exception as e:
            error_log(f"[TTS] ç²å–æƒ…æ„Ÿå‘é‡å¤±æ•—: {str(e)}")
            return self.default_emotion
    
    def _get_user_preferences(self) -> Dict[str, Any]:
        """
        å¾ Working Context Manager ç²å–ä½¿ç”¨è€…åå¥½
        
        æ³¨æ„ï¼šWorking Context Manager ç®¡ç†å¤šå€‹ä¸Šä¸‹æ–‡ï¼Œé€™è£¡æˆ‘å€‘å¯ä»¥ï¼š
        1. å¾å…¨å±€å…±äº«æ•¸æ“šç²å– TTS åå¥½è¨­ç½®
        2. æˆ–è€…å¾ç‰¹å®šé¡å‹çš„ä¸Šä¸‹æ–‡ç²å–ï¼ˆå¦‚ CONVERSATION ä¸Šä¸‹æ–‡ï¼‰
        
        Returns:
            Dict[str, Any]: ä½¿ç”¨è€…åå¥½è¨­å®š
        """
        if not self.working_context_manager:
            debug_log(3, "[TTS] Working Context Manager æœªé€£æ¥ï¼Œä½¿ç”¨é è¨­åå¥½")
            return {}
        
        try:
            # å¾ Working Context Manager çš„å…¨å±€å…±äº«æ•¸æ“šç²å– TTS åå¥½
            # é€™å€‹å€åŸŸå¯ä»¥å­˜å„²è·¨æ¨¡çµ„çš„ç”¨æˆ¶åå¥½è¨­ç½®
            preferences = {}
            
            # å˜—è©¦ç²å– TTS ç›¸é—œåå¥½
            # æ³¨æ„ï¼šé€™è£¡éœ€è¦ç¢ºèª working_context_manager çš„å¯¦éš› API
            # æš«æ™‚è¿”å›ç©ºå­—å…¸ï¼Œå…·é«”å¯¦ç¾éœ€è¦æ ¹æ“š Working Context çš„è¨­è¨ˆä¾†èª¿æ•´
            
            debug_log(3, f"[TTS] ä½¿ç”¨è€…åå¥½: {preferences}")
            
            return preferences
            
        except Exception as e:
            error_log(f"[TTS] ç²å–ä½¿ç”¨è€…åå¥½å¤±æ•—: {str(e)}")
            return {}
    
    def _get_current_gs_id(self) -> str:
        """
        ç²å–ç•¶å‰ General Session ID
        å¾ working_context çš„å…¨å±€æ•¸æ“šä¸­è®€å– (ç”± SystemLoop è¨­ç½®)
        
        Returns:
            str: ç•¶å‰ GS ID,å¦‚æœç„¡æ³•ç²å–å‰‡è¿”å› 'unknown'
        """
        try:
            if self.working_context_manager:
                gs_id = self.working_context_manager.global_context_data.get('current_gs_id', 'unknown')
                return gs_id
            return 'unknown'
        except Exception as e:
            error_log(f"[TTS] ç²å– GS ID å¤±æ•—: {e}")
            return 'unknown'
    
    def _get_current_cycle_index(self) -> int:
        """
        ç²å–ç•¶å‰å¾ªç’°è¨ˆæ•¸
        å¾ working_context çš„å…¨å±€æ•¸æ“šä¸­è®€å– (ç”± Controller åœ¨ GS å‰µå»ºæ™‚è¨­ç½®)
        
        Returns:
            int: ç•¶å‰ cycle_index,å¦‚æœç„¡æ³•ç²å–å‰‡è¿”å› 0ï¼ˆå‡è¨­ç‚ºç¬¬ä¸€å€‹ cycleï¼‰
        """
        try:
            if self.working_context_manager:
                cycle_index = self.working_context_manager.global_context_data.get('current_cycle_index', 0)
                return cycle_index
            return 0
        except Exception as e:
            error_log(f"[TTS] ç²å– cycle_index å¤±æ•—: {e}")
            return 0
    
    def _on_output_complete(self, result: Dict[str, Any]):
        """
        âœ… äº‹ä»¶é©…å‹•ç‰ˆæœ¬ï¼šTTS è¼¸å‡ºå®Œæˆå›èª¿
        ä½œç‚ºè¼¸å‡ºå±¤ï¼ŒTTS å®Œæˆæ¨™èªŒè‘—ä¸€æ¬¡å®Œæ•´çš„è™•ç†å¾ªç’°çµæŸ
        """
        try:
            info_log("[TTS] è¼¸å‡ºå±¤å®Œæˆï¼Œç™¼å¸ƒäº‹ä»¶")
            
            # æª¢æŸ¥åˆæˆæ˜¯å¦æˆåŠŸ
            if result.get("status") != "success":
                debug_log(1, f"[TTS] åˆæˆå¤±æ•—ï¼Œç‹€æ…‹: {result.get('status')}")
                return
            
            # æ›´æ–° Status Manager (TTS å®Œæˆæœƒå½±éŸ¿ç³»çµ±ç‹€æ…‹)
            if self.status_manager:
                # TTS æˆåŠŸå®Œæˆï¼Œç•¥å¾®é™ä½ boredom (ç³»çµ±æœ‰è¼¸å‡ºæ´»å‹•)
                self.status_manager.update_boredom(-0.05, "TTSè¼¸å‡ºå®Œæˆ")
                debug_log(3, "[TTS] å·²æ›´æ–° Status Manager")
            
            # âœ… ä½¿ç”¨äº‹ä»¶ç¸½ç·šç™¼å¸ƒè¼¸å‡ºå®Œæˆäº‹ä»¶
            try:
                from core.event_bus import event_bus, SystemEvent
                
                # ç²å–ç•¶å‰ GS session_id å’Œ cycle_index (ç”¨æ–¼å»é‡)
                session_id = self._get_current_gs_id()
                cycle_index = self._get_current_cycle_index()
                
                output_completion_data = {
                    # Flow-based å»é‡æ‰€éœ€æ¬„ä½
                    "session_id": session_id,
                    "cycle_index": cycle_index,
                    "layer": "OUTPUT",
                    
                    # åŸæœ‰æ•¸æ“š
                    "tts_result": result,
                    "output_path": result.get("output_path"),
                    "duration": result.get("duration"),
                    "chunk_count": result.get("chunk_count"),
                    "timestamp": time.time(),
                    "source_module": "tts",
                    "completion_type": "output_layer_finished"
                }
                
                event_bus.publish(
                    event_type=SystemEvent.OUTPUT_LAYER_COMPLETE,
                    data=output_completion_data,
                    source="tts"
                )
                
                debug_log(2, f"[TTS] è¼¸å‡ºå±¤å®Œæˆäº‹ä»¶å·²ç™¼å¸ƒ (session={session_id}, cycle={cycle_index})")
                
            except Exception as event_err:
                error_log(f"[TTS] ç™¼å¸ƒè¼¸å‡ºå®Œæˆäº‹ä»¶å¤±æ•—: {event_err}")
            
        except Exception as e:
            error_log(f"[TTS] è¼¸å‡ºå®Œæˆå›èª¿å¤±æ•—: {e}")
    
    def handle(self, data: dict) -> dict:
        """
        è™•ç† TTS è«‹æ±‚ (åŒæ­¥ä»‹é¢)
        
        Args:
            data: TTSInput å­—å…¸
            
        Returns:
            dict: TTSOutput å­—å…¸
        """
        try:
            inp = TTSInput(**data)
        except Exception as e:
            return TTSOutput(
                status="error",
                success=False,
                message=f"Invalid input: {e}",
                output_path=None,
                is_chunked=False,
                chunk_count=0
            ).dict()
        
        text = inp.text
        if not text:
            return TTSOutput(
                status="error",
                success=False,
                message="Text is required",
                output_path=None,
                is_chunked=False,
                chunk_count=0
            ).dict()
        
        # æ±ºå®šæ˜¯å¦ä½¿ç”¨ chunking
        should_chunk = (
            self.chunking_enabled and 
            (len(text) > self.chunking_threshold or inp.force_chunking)
        )
        
        debug_log(2, f"[TTS] è™•ç†æ–‡æœ¬: é•·åº¦={len(text)}, chunking={'æ˜¯' if should_chunk else 'å¦'}")
        
        # åœ¨æ–°çš„ event loop ä¸­é‹è¡Œç•°æ­¥æ–¹æ³•
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        
        if should_chunk:
            result = loop.run_until_complete(
                self._handle_streaming(text, inp.save, inp.save_name, character=inp.character, emotion_vector=inp.emotion_vector)
            )
        else:
            result = loop.run_until_complete(
                self._handle_single(text, inp.save, inp.save_name, inp.character, inp.emotion_vector)
            )
        
        # TTS ä½œç‚ºè¼¸å‡ºå±¤å®Œæˆå¾Œï¼Œé€šçŸ¥ç³»çµ±é€²è¡Œå¾ªç’°çµæŸæª¢æŸ¥
        self._on_output_complete(result)
        
        return result
    
    async def _handle_single(
        self, 
        text: str, 
        save: bool, 
        save_name: Optional[str] = None,
        character: Optional[str] = None,
        emotion_vector: Optional[List[float]] = None
    ) -> dict:
        """
        è™•ç†å–®æ®µæ–‡æœ¬åˆæˆ
        
        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            save: æ˜¯å¦ä¿å­˜åˆ°æ–‡ä»¶
            character: è§’è‰²åç¨± (None ä½¿ç”¨ç•¶å‰è§’è‰²)
            emotion_vector: æƒ…æ„Ÿå‘é‡ (None å‰‡å¾ Status Manager ç²å–)
            
        Returns:
            dict: TTSOutput å­—å…¸
        """
        try:
            # æª¢æŸ¥å¼•æ“æ˜¯å¦å·²åˆå§‹åŒ–
            if not self.engine:
                error_log("[TTS] å¼•æ“æœªåˆå§‹åŒ–")
                return TTSOutput(
                    status="error",
                    success=False,
                    message="Engine not initialized",
                    output_path=None,
                    is_chunked=False,
                    chunk_count=0
                ).model_dump()
            
            # åˆ‡æ›è§’è‰² (å¦‚æœæŒ‡å®š)
            if character and character != self.default_character:
                character_path = os.path.join(self.character_dir, f"{character}.pt")
                if os.path.exists(character_path):
                    self.engine.load_character(character_path)
                    debug_log(2, f"[TTS] åˆ‡æ›åˆ°è§’è‰²: {character}")
                else:
                    error_log(f"[TTS] æ‰¾ä¸åˆ°è§’è‰²: {character}")
            
            # ç²å–æƒ…æ„Ÿå‘é‡
            if emotion_vector is None:
                emotion_vector = self._get_emotion_vector_from_status()
            
            # ç²å–ä½¿ç”¨è€…åå¥½
            preferences = self._get_user_preferences()
            
            # æº–å‚™è¼¸å‡ºè·¯å¾‘
            output_path = None
            if save:
                output_path = os.path.join("outputs", "tts", f"{save_name or f'uep_{uuid.uuid4().hex[:8]}'}.wav")
            else:
                output_path = os.path.join("temp", "tts", f"temp_{uuid.uuid4().hex[:8]}.wav")
            
            info_log(f"[TTS] åˆæˆå–®æ®µæ–‡æœ¬: {len(text)} å­—ç¬¦")
            
            # ä½¿ç”¨å¼•æ“åˆæˆ
            async with self._playback_lock:
                self._playback_state = PlaybackState.PLAYING
                
                result = await asyncio.get_event_loop().run_in_executor(
                    None,
                    self.engine.synthesize,
                    text,
                    output_path,
                    emotion_vector
                )
            
            if not result or not os.path.exists(output_path):
                self._playback_state = PlaybackState.ERROR
                return TTSOutput(
                    status="error",
                    success=False,
                    message="Synthesis failed",
                    output_path=None,
                    is_chunked=False,
                    chunk_count=0
                ).model_dump()
            
            # æ’­æ”¾éŸ³é » (å¦‚æœä¸ä¿å­˜)
            if not save and sa:
                data, sr = sf.read(output_path)
                # è½‰æ›ç‚º int16
                data_int16 = (data * 32767).astype(np.int16)
                self._current_playback_obj = sa.play_buffer(
                    data_int16.tobytes(),
                    num_channels=1,
                    bytes_per_sample=2,
                    sample_rate=sr
                )
                self._current_playback_obj.wait_done()
                
                # æ’­æ”¾å®Œç•¢å¾Œåˆªé™¤è‡¨æ™‚æ–‡ä»¶
                try:
                    if os.path.exists(output_path):
                        os.remove(output_path)
                        debug_log(2, f"[TTS] å·²åˆªé™¤è‡¨æ™‚æ–‡ä»¶: {output_path}")
                except Exception as e:
                    debug_log(1, f"[TTS] åˆªé™¤è‡¨æ™‚æ–‡ä»¶å¤±æ•—: {e}")
            
            self._playback_state = PlaybackState.COMPLETED
            
            final_path = output_path if save else None
            info_log(f"[TTS] åˆæˆå®Œæˆ: {output_path}")
            
            return TTSOutput(
                status="success",
                success=True,
                message="TTS completed",
                output_path=final_path,
                is_chunked=False,
                chunk_count=1
            ).model_dump()
            
        except Exception as e:
            self._playback_state = PlaybackState.ERROR
            error_log(f"[TTS] åˆæˆéŒ¯èª¤: {str(e)}")
            import traceback
            debug_log(1, f"[TTS] éŒ¯èª¤è©³æƒ…:\n{traceback.format_exc()}")
            return TTSOutput(
                status="error",
                success=False,
                message=f"TTS failed: {str(e)}",
                output_path=None,
                is_chunked=False,
                chunk_count=0
            ).model_dump()

    async def _handle_streaming(
        self,
        text: str,
        save: bool,
        save_name: Optional[str] = None,
        character: Optional[str] = None,
        emotion_vector: Optional[List[float]] = None
    ) -> dict:
        """
        è™•ç†ä¸²æµåˆæˆ (Producer/Consumer æ¨¡å¼)
        
        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            save: æ˜¯å¦ä¿å­˜åˆ°æ–‡ä»¶
            character: è§’è‰²åç¨±
            emotion_vector: æƒ…æ„Ÿå‘é‡
            
        Returns:
            dict: TTSOutput å­—å…¸
        """
        generated_files: List[str] = []  # åˆå§‹åŒ–è‡¨æ™‚æ–‡ä»¶åˆ—è¡¨(ç”¨æ–¼éŒ¯èª¤æ¸…ç†)
        
        try:
            # æª¢æŸ¥å¼•æ“æ˜¯å¦å·²åˆå§‹åŒ–
            if not self.engine:
                error_log("[TTS] å¼•æ“æœªåˆå§‹åŒ–")
                return TTSOutput(
                    status="error",
                    success=False,
                    message="Engine not initialized",
                    output_path=None,
                    is_chunked=True,
                    chunk_count=0
                ).model_dump()
            
            # åˆ‡æ›è§’è‰²
            if character and character != self.default_character:
                character_path = os.path.join(self.character_dir, f"{character}.pt")
                if os.path.exists(character_path):
                    self.engine.load_character(character_path)
            
            # ç²å–æƒ…æ„Ÿå‘é‡
            if emotion_vector is None:
                emotion_vector = self._get_emotion_vector_from_status()
            
            # ä½¿ç”¨ TTSChunker é€²è¡Œæ™ºèƒ½åˆ†æ®µ
            info_log(f"[TTS] é–‹å§‹ chunking: {len(text)} å­—ç¬¦")
            
            # ä½¿ç”¨ TTSChunker çš„æ™ºèƒ½åˆ†æ®µç®—æ³•
            chunks = self.chunker.split_text(text)
            info_log(f"[TTS] TTSChunker åˆ†æˆ {len(chunks)} æ®µ")
            
            # ä½¿ç”¨æœ‰é™ç·©è¡éšŠåˆ—,æœ€å¤šç·©è¡ 2 å€‹éŸ³é »æ®µè½
            # é€™æ¨£å¯ä»¥ä¿æŒ Producer é ˜å…ˆ,æ¸›å°‘æ’­æ”¾æ™‚çš„åœé “
            queue = asyncio.Queue(maxsize=2)
            loop = asyncio.get_event_loop()
            tmp_dir = "temp/tts"
            generated_files = []
            
            # ç²å–å¼•æ“å¼•ç”¨ (for type narrowing)
            engine = self.engine  # Type narrowing: æ­¤æ™‚å·²ç¢ºèª engine ä¸æ˜¯ None
            
            # Producer: ç”ŸæˆéŸ³é »æ®µè½
            async def producer():
                info_log(f"[TTS] Producer é–‹å§‹è™•ç† {len(chunks)} å€‹æ®µè½ (ç·©è¡: 2 æ®µ)")
                for idx, chunk in enumerate(chunks, 1):
                    try:
                        debug_log(3, f"[TTS] è™•ç†æ®µè½ {idx}/{len(chunks)}: {chunk[:50]}...")
                        
                        fname = f"chunk_{idx}_{uuid.uuid4().hex[:8]}.wav"
                        out_path = os.path.join(tmp_dir, fname)
                        
                        # åˆæˆæ®µè½
                        await loop.run_in_executor(
                            None,
                            engine.synthesize,
                            chunk,
                            out_path,
                            emotion_vector
                        )
                        
                        if os.path.exists(out_path):
                            generated_files.append(out_path)
                            # å¦‚æœéšŠåˆ—å·²æ»¿,é€™è£¡æœƒç­‰å¾… Consumer å–èµ°ä¸€å€‹éŸ³é »
                            await queue.put(("success", out_path))
                            debug_log(3, f"[TTS] æ®µè½ {idx} å®Œæˆä¸¦æ”¾å…¥éšŠåˆ—")
                        else:
                            error_log(f"[TTS] æ®µè½ {idx} åˆæˆå¤±æ•—")
                            await queue.put(("error", f"Chunk {idx} failed"))
                            
                    except Exception as e:
                        error_log(f"[TTS] Producer éŒ¯èª¤ (æ®µè½ {idx}): {str(e)}")
                        await queue.put(("error", str(e)))
                
                # æ¨™è¨˜çµæŸ
                await queue.put(("done", None))
                info_log(f"[TTS] Producer å®Œæˆï¼Œå…±ç”Ÿæˆ {len(generated_files)} å€‹æ®µè½")
            
            # Consumer: æ’­æ”¾éŸ³é »æ®µè½
            async def consumer():
                count = 0
                while True:
                    status, data = await queue.get()
                    
                    if status == "done":
                        break
                    elif status == "error":
                        error_log(f"[TTS] Consumer æ”¶åˆ°éŒ¯èª¤: {data}")
                        break
                    elif status == "success":
                        count += 1
                        # æ’­æ”¾ (å¦‚æœä¸ä¿å­˜)
                        if not save and sa:
                            try:
                                audio, sr = sf.read(data)
                                audio_int16 = (audio * 32767).astype(np.int16)
                                play_obj = sa.play_buffer(
                                    audio_int16.tobytes(), 1, 2, sr
                                )
                                play_obj.wait_done()
                                
                                # æ’­æ”¾å®Œç•¢å¾Œåˆªé™¤è©²æ®µè‡¨æ™‚æ–‡ä»¶
                                try:
                                    if os.path.exists(data):
                                        os.remove(data)
                                        debug_log(3, f"[TTS] å·²åˆªé™¤è‡¨æ™‚chunk: {data}")
                                except Exception as del_err:
                                    debug_log(1, f"[TTS] åˆªé™¤è‡¨æ™‚chunkå¤±æ•—: {del_err}")
                            except Exception as e:
                                error_log(f"[TTS] æ’­æ”¾å¤±æ•—: {str(e)}")
                
                info_log(f"[TTS] Consumer å®Œæˆï¼Œå·²æ’­æ”¾ {count} å€‹æ®µè½")
            
            # å•Ÿå‹• Producer å’Œ Consumer
            async with self._playback_lock:
                self._playback_state = PlaybackState.PLAYING
                
                producer_task = asyncio.create_task(producer())
                consumer_task = asyncio.create_task(consumer())
                
                await producer_task
                await consumer_task
            
            # åˆä½µéŸ³é » (å¦‚æœéœ€è¦ä¿å­˜)
            output_path = None
            if save and generated_files:
                info_log(f"[TTS] åˆä½µ {len(generated_files)} å€‹éŸ³é »æª”æ¡ˆ")
                buffers = []
                sr = None
                
                for f in generated_files:
                    if os.path.exists(f):
                        data, _sr = sf.read(f)
                        sr = sr or _sr
                        buffers.append(data)
                
                if buffers:
                    merged = np.concatenate(buffers, axis=0)
                    output_path = os.path.join("outputs", "tts", f"{save_name or f'uep_{uuid.uuid4().hex[:8]}'}.wav")
                    sf.write(output_path, merged, sr)
                    info_log(f"[TTS] å·²åˆä½µéŸ³é »åˆ° {output_path}")
                    
                    # åˆä½µå®Œæˆå¾Œåˆªé™¤åŸå§‹è‡¨æ™‚chunkæ–‡ä»¶
                    for f in generated_files:
                        try:
                            if os.path.exists(f):
                                os.remove(f)
                                debug_log(3, f"[TTS] å·²åˆªé™¤åˆä½µå‰çš„chunk: {f}")
                        except Exception as e:
                            debug_log(1, f"[TTS] åˆªé™¤chunkå¤±æ•—: {e}")
            
            self._playback_state = PlaybackState.COMPLETED
            
            return TTSOutput(
                status="success",
                success=True,
                message=f"Streaming completed",
                output_path=output_path,
                is_chunked=True,
                chunk_count=len(chunks)
            ).model_dump()
            
        except Exception as e:
            self._playback_state = PlaybackState.ERROR
            error_log(f"[TTS] Streaming éŒ¯èª¤: {str(e)}")
            import traceback
            debug_log(1, f"[TTS] éŒ¯èª¤è©³æƒ…:\n{traceback.format_exc()}")
            
            # ç™¼ç”ŸéŒ¯èª¤æ™‚æ¸…ç†å·²ç”Ÿæˆçš„è‡¨æ™‚æ–‡ä»¶
            if generated_files:
                debug_log(2, f"[TTS] æ¸…ç† {len(generated_files)} å€‹è‡¨æ™‚æ–‡ä»¶...")
                for f in generated_files:
                    try:
                        if os.path.exists(f):
                            os.remove(f)
                            debug_log(3, f"[TTS] å·²åˆªé™¤: {f}")
                    except Exception as cleanup_err:
                        debug_log(1, f"[TTS] æ¸…ç†å¤±æ•—: {cleanup_err}")
            
            return TTSOutput(
                status="error",
                success=False,
                message=f"Streaming failed: {str(e)}",
                output_path=None,
                is_chunked=True,
                chunk_count=0
            ).model_dump()
