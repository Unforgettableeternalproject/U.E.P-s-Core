# modules/llm_module/gemini_client.py

import os
from typing import Any, Optional
from dotenv import load_dotenv
from google import genai
from google.genai import types
from utils.debug_helper import debug_log, info_log, error_log

load_dotenv()

class GeminiWrapper:
    def __init__(self, config: dict):
        self.model_name = config.get("model", "gemini-2.5-flash-lite")
        self.temperature = config.get("temperature", 0.8)
        self.top_p = config.get("top_p", 0.95)
        self.max_tokens = config.get("max_output_tokens", 8192)

        # å®‰å…¨è¨­å®šå¯ç”¨ config æ§åˆ¶ï¼Œé€™è£¡å…ˆå¯«æ­»ç‚º OFF
        self.safety_settings = [
            types.SafetySetting(category=str(item["category"]), threshold=str(item["threshold"])) # type: ignore
            for item in config.get("safety_settings", [
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_LOW_AND_ABOVE"},
                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_LOW_AND_ABOVE"},
                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_LOW_AND_ABOVE"},
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_LOW_AND_ABOVE"},
            ])
        ]

        self.client = genai.Client(
            vertexai=True,
            project=os.getenv("GCP_PROJECT_ID"),
            location=os.getenv("GCP_LOCATION"),
        )

        # Context Caching æ”¯æ´
        self.cache_enabled = config.get("cache_enabled", True)
        
        # æ ¹æ“šè™•ç†æ¨¡å¼å‹•æ…‹ç”Ÿæˆå›æ‡‰ schema
        self.response_schemas = self._create_response_schemas()
    
    def _create_response_schemas(self) -> dict:
        """å‰µå»ºä¸åŒæ¨¡å¼çš„å›æ‡‰ Schema"""
        return {
            "chat": self._create_chat_schema(),
            "work": self._create_work_schema(),
            "direct": self._create_direct_schema(),
            "internal": self._create_internal_schema()
        }
    
    def _create_chat_schema(self) -> dict:
        """å‰µå»º CHAT æ¨¡å¼çš„å›æ‡‰ Schema - èˆ‡ MEM å”ä½œ"""
        return {
            "type": "object",
            "properties": {
                "text": {
                    "type": "string",
                    "description": "è‡ªç„¶çš„å°è©±å›æ‡‰æ–‡å­—"
                },
                "confidence": {
                    "type": "number",
                    "description": "å›æ‡‰ä¿¡å¿ƒåº¦ (0.0-1.0)",
                    "minimum": 0.0,
                    "maximum": 1.0
                },
                "status_updates": {
                    "type": "object",
                    "nullable": True,
                    "properties": {
                        "mood_delta": {
                            "type": "number",
                            "description": "æƒ…ç·’è®ŠåŒ–é‡ (-1.0 åˆ° +1.0)",
                            "minimum": -1.0,
                            "maximum": 1.0
                        },
                        "pride_delta": {
                            "type": "number", 
                            "description": "è‡ªå°Šè®ŠåŒ–é‡ (-1.0 åˆ° +1.0)",
                            "minimum": -1.0,
                            "maximum": 1.0
                        },
                        "helpfulness_delta": {
                            "type": "number",
                            "description": "åŠ©äººæ„é¡˜è®ŠåŒ–é‡ (-1.0 åˆ° +1.0)",
                            "minimum": -1.0,
                            "maximum": 1.0
                        },
                        "boredom_delta": {
                            "type": "number",
                            "description": "ç„¡èŠç¨‹åº¦è®ŠåŒ–é‡ (-1.0 åˆ° +1.0)",
                            "minimum": -1.0,
                            "maximum": 1.0
                        }
                    },
                    "description": "æ ¹æ“šå°è©±å…§å®¹å»ºè­°çš„ç³»çµ±ç‹€æ…‹æ›´æ–°"
                },
                "memory_observation": {
                    "type": "string",
                    "description": "å°è©±è§€å¯Ÿæ‘˜è¦ï¼Œç”¨æ–¼è¨˜æ†¶è™•ç†"
                },
                "learning_signals": {
                    "type": "object",
                    "nullable": True,
                    "properties": {
                        "formality_signal": {
                            "type": "number",
                            "description": "æ­£å¼ç¨‹åº¦ä¿¡è™Ÿ (-1.0=éæ­£å¼, 0=ä¸­æ€§, 1.0=æ­£å¼)",
                            "minimum": -1.0,
                            "maximum": 1.0
                        },
                        "detail_signal": {
                            "type": "number",
                            "description": "è©³ç´°ç¨‹åº¦ä¿¡è™Ÿ (-1.0=ç°¡æ½”, 0=é©ä¸­, 1.0=è©³ç´°)",
                            "minimum": -1.0,
                            "maximum": 1.0
                        },
                        "technical_signal": {
                            "type": "number",
                            "description": "æŠ€è¡“ç¨‹åº¦ä¿¡è™Ÿ (-1.0=é€šä¿—, 0=é©ä¸­, 1.0=å°ˆæ¥­)",
                            "minimum": -1.0,
                            "maximum": 1.0
                        },
                        "interaction_signal": {
                            "type": "number",
                            "description": "äº’å‹•åå¥½ä¿¡è™Ÿ (-1.0=ç¨ç«‹, 0=é©ä¸­, 1.0=äº’å‹•)",
                            "minimum": -1.0,
                            "maximum": 1.0
                        }
                    },
                    "description": "ç”¨æˆ¶åå¥½å­¸ç¿’ä¿¡è™Ÿï¼Œç´¯ç©å¤šæ¬¡å¾Œå½¢æˆç”¨æˆ¶ç•«åƒ"
                },
                "session_control": {
                    "type": "object",
                    "nullable": True,
                    "properties": {
                        "should_end_session": {
                            "type": "boolean",
                            "description": "æ˜¯å¦æ‡‰è©²çµæŸç•¶å‰å°è©±æœƒè©±"
                        },
                        "end_reason": {
                            "type": "string",
                            "enum": ["natural_conclusion", "user_goodbye", "task_completed", "no_further_input"],
                            "description": "å»ºè­°çµæŸæœƒè©±çš„åŸå› "
                        },
                        "confidence": {
                            "type": "number",
                            "description": "çµæŸæœƒè©±å»ºè­°çš„ä¿¡å¿ƒåº¦",
                            "minimum": 0.0,
                            "maximum": 1.0
                        }
                    },
                    "description": "æœƒè©±æ§åˆ¶å»ºè­°ï¼Œç”± LLM åˆ¤æ–·å°è©±æ˜¯å¦æ‡‰è©²çµæŸ"
                }
            },
            "required": ["text", "confidence"]
        }
    
    def _create_work_schema(self) -> dict:
        """å‰µå»º WORK æ¨¡å¼çš„å›æ‡‰ Schema - èˆ‡ SYS å”ä½œ"""
        return {
            "type": "object",
            "properties": {
                "text": {
                    "type": "string",
                    "description": "ä»»å‹™å°å‘çš„å›æ‡‰æ–‡å­—"
                },
                "confidence": {
                    "type": "number",
                    "description": "ä»»å‹™åŸ·è¡Œä¿¡å¿ƒåº¦ (0.0-1.0)",
                    "minimum": 0.0,
                    "maximum": 1.0
                },
                "sys_action": {
                    "type": "object",
                    "nullable": False,
                    "properties": {
                        "action": {
                            "type": "string",
                            "enum": ["start_workflow", "execute_function", "provide_options"],
                            "description": "ç³»çµ±å‹•ä½œé¡å‹"
                        },
                        "target": {
                            "type": "string",
                            "description": "å‹•ä½œç›®æ¨™ (å·¥ä½œæµåç¨±æˆ–åŠŸèƒ½åç¨±)"
                        },
                        "parameters": {
                            "type": "object",
                            "description": "å‹•ä½œåƒæ•¸"
                        },
                        "confidence": {
                            "type": "number",
                            "description": "å‹•ä½œå»ºè­°çš„ä¿¡å¿ƒåº¦",
                            "minimum": 0.0,
                            "maximum": 1.0
                        },
                        "requires_confirmation": {
                            "type": "boolean",
                            "description": "æ˜¯å¦éœ€è¦ç”¨æˆ¶ç¢ºèª"
                        },
                        "reason": {
                            "type": "string",
                            "description": "é¸æ“‡æ­¤å‹•ä½œçš„è©³ç´°ç†ç”±"
                        }
                    },
                    "required": ["action", "target", "reason"],
                    "description": "å»ºè­°çš„ç³»çµ±å‹•ä½œ"
                },
                "status_updates": {
                    "type": "object",
                    "nullable": True,
                    "properties": {
                        "helpfulness_delta": {
                            "type": "number",
                            "description": "å®Œæˆä»»å‹™å¾Œçš„åŠ©äººæ„é¡˜è®ŠåŒ–",
                            "minimum": -1.0,
                            "maximum": 1.0
                        },
                        "pride_delta": {
                            "type": "number",
                            "description": "ä»»å‹™æˆåŠŸ/å¤±æ•—å°è‡ªå°Šçš„å½±éŸ¿",
                            "minimum": -1.0,
                            "maximum": 1.0  
                        },
                        "mood_delta": {
                            "type": "number",
                            "description": "å·¥ä½œå®Œæˆç‹€æ³å°æƒ…ç·’çš„å½±éŸ¿",
                            "minimum": -1.0,
                            "maximum": 1.0
                        },
                        "boredom_delta": {
                            "type": "number",
                            "description": "ä»»å‹™è¤‡é›œåº¦å°ç„¡èŠç¨‹åº¦çš„å½±éŸ¿",
                            "minimum": -1.0,
                            "maximum": 1.0
                        },
                        "reason": {
                            "type": "string",
                            "description": "ç‹€æ…‹è®ŠåŒ–åŸå› "
                        }
                    },
                    "description": "åŸºæ–¼ä»»å‹™åŸ·è¡Œç‹€æ³çš„ç‹€æ…‹æ›´æ–°"
                },
                "session_control": {
                    "type": "object",
                    "nullable": True,
                    "properties": {
                        "should_end_session": {
                            "type": "boolean",
                            "description": "æ˜¯å¦æ‡‰è©²çµæŸç•¶å‰å·¥ä½œæœƒè©±"
                        },
                        "end_reason": {
                            "type": "string",
                            "enum": ["task_completed", "workflow_finished", "user_satisfied", "cannot_proceed"],
                            "description": "å»ºè­°çµæŸæœƒè©±çš„åŸå› "
                        },
                        "confidence": {
                            "type": "number",
                            "description": "çµæŸæœƒè©±å»ºè­°çš„ä¿¡å¿ƒåº¦",
                            "minimum": 0.0,
                            "maximum": 1.0
                        }
                    },
                    "description": "æœƒè©±æ§åˆ¶å»ºè­°ï¼Œç”± LLM åˆ¤æ–·å·¥ä½œæ˜¯å¦æ‡‰è©²çµæŸ"
                }
            },
            "required": ["text", "confidence"]
        }
    
    def _create_direct_schema(self) -> dict:
        """å‰µå»º DIRECT æ¨¡å¼çš„å›æ‡‰ Schema"""
        return {
            "type": "object", 
            "properties": {
                "text": {
                    "type": "string",
                    "description": "ç›´æ¥å›æ‡‰æ–‡å­—"
                }
            },
            "required": ["text"]
        }
        
    def _create_internal_schema(self) -> dict:
        """å‰µå»º INTERNAL æ¨¡å¼çš„å›æ‡‰ Schema"""
        return {
            "type": "object",
            "properties": {
                "text": {
                    "type": "string", 
                    "description": "å…§éƒ¨ç³»çµ±å›æ‡‰"
                },
                "confidence": {
                    "type": "number",
                    "description": "å…§éƒ¨è™•ç†ä¿¡å¿ƒåº¦",
                    "minimum": 0.0,
                    "maximum": 1.0
                }
            },
            "required": ["text"]
        }
    
    def _create_mischief_schema(self) -> dict:
        """å‰µå»º MISCHIEF æ¨¡å¼çš„å›æ‡‰ Schema"""
        return {
            "type": "object",
            "properties": {
                "actions": {
                    "type": "array",
                    "description": "MISCHIEF è¡Œç‚ºåºåˆ—",
                    "items": {
                        "type": "object",
                        "properties": {
                            "action_id": {
                                "type": "string",
                                "description": "è¡Œç‚º IDï¼ˆå¿…é ˆä¾†è‡ªå¯ç”¨è¡Œç‚ºåˆ—è¡¨ï¼‰"
                            },
                            "params": {
                                "type": "object",
                                "description": "è¡Œç‚ºåƒæ•¸"
                            }
                        },
                        "required": ["action_id", "params"]
                    }
                }
            },
            "required": ["actions"]
        }



    # [ä¿®æ”¹] å…è¨± str æˆ– list[str]
    def query(self, prompt: str, mode: str = "chat", cached_content=None, tools=None, system_instruction: Optional[str] = None, tool_choice: str = "ANY") -> dict:
        """
        æŸ¥è©¢ Gemini API
        
        Args:
            prompt: ç”¨æˆ¶è¼¸å…¥
            mode: æ¨¡å¼ï¼ˆchat/work/internal/mischiefï¼‰
            cached_content: å¿«å–å…§å®¹ ID
            tools: MCP å·¥å…·åˆ—è¡¨
            system_instruction: è‡ªå®šç¾©ç³»çµ±æç¤ºè©ï¼ˆç”¨æ–¼ internal/mischief æ¨¡å¼ï¼‰
            tool_choice: Function calling æ¨¡å¼ ("ANY" å¼·åˆ¶èª¿ç”¨ | "AUTO" è‡ªå‹•æ±ºå®š | "NONE" ä¸èª¿ç”¨)
        """
        contents = [types.Content(role="user", parts=[types.Part(text=prompt)])]
        # æ”¯æŒ mischief æ¨¡å¼
        if mode == "mischief":
            schema = self._create_mischief_schema()
        else:
            schema = self.response_schemas.get(mode, self.response_schemas["chat"])

        config_params = {
            "temperature": self.temperature,
            "top_p": self.top_p,
            "max_output_tokens": self.max_tokens,
            "safety_settings": self.safety_settings
        }
        
        # ğŸ”§ æ”¯æ´è‡ªå®šç¾©ç³»çµ±æç¤ºè©ï¼ˆç”¨æ–¼ internal æ¨¡å¼æˆ–å·¥ä½œæµï¼‰
        if system_instruction:
            config_params["system_instruction"] = types.Part(text=system_instruction)
        
        # âœ… å¦‚æœæä¾›äº† toolsï¼Œä½¿ç”¨ function calling æ¨¡å¼ï¼›å¦å‰‡ä½¿ç”¨ JSON schema æ¨¡å¼
        if tools:
            config_params["tools"] = tools
            # âœ… æ ¹æ“š tool_choice åƒæ•¸æ±ºå®š function calling æ¨¡å¼
            config_params["tool_config"] = {"function_calling_config": {"mode": tool_choice}}
            # ğŸ” DEBUG: è¨˜éŒ„ tools æ•¸é‡å’Œæ¨¡å¼
            from utils.debug_helper import debug_log
            tool_count = sum(len(t.get('function_declarations', [])) for t in tools)
            mode_desc = {
                "ANY": "å¼·åˆ¶èª¿ç”¨",
                "AUTO": "è‡ªå‹•æ±ºå®š",
                "NONE": "ä¸èª¿ç”¨"
            }.get(tool_choice, tool_choice)
            debug_log(3, f"[Gemini] ä½¿ç”¨ function calling æ¨¡å¼ï¼ˆ{mode_desc}ï¼‰ï¼Œå·¥å…·æ•¸é‡: {tool_count}")
        else:
            config_params["response_mime_type"] = "application/json"
            config_params["response_schema"] = schema
        
        config = types.GenerateContentConfig(**config_params)

        # [ä¿®æ”¹] æ”¯æ´å–®ä¸€ id æˆ–å¤šå€‹ id
        if self.cache_enabled and cached_content:
            if isinstance(cached_content, (list, tuple)):
                config.cached_content = list(cached_content) # type: ignore
            else:
                config.cached_content = cached_content

        result = self.client.models.generate_content(
            model=self.model_name,
            contents=contents, # type: ignore
            config=config
        )

        # ğŸ”§ é˜²ç¦¦æ€§æª¢æŸ¥ï¼šç¢ºä¿ result å’Œ candidates ä¸æ˜¯ None
        if result is None:
            error_log("[Gemini] API è¿”å› None")
            return {"text": "Welp...I did not come up with any response, sorry."}
        
        if not hasattr(result, 'candidates') or result.candidates is None or len(result.candidates) == 0:
            error_log(f"[Gemini] API è¿”å›ç„¡æ•ˆçš„ candidates: {result}")
            return {"text": "Welp...I did not come up with any valid response, sorry."}
        
        candidate = result.candidates[0]
        if candidate is None or not hasattr(candidate, 'content') or candidate.content is None:
            error_log(f"[Gemini] candidate æˆ– content ç‚º None")
            return {"text": "Welp...I did not come up with any content, sorry."}
        
        # ğŸ”§ **å„ªå…ˆæª¢æŸ¥ finish_reason** - MALFORMED_FUNCTION_CALL æ™‚ content.parts é€šå¸¸ç‚ºç©º
        # å¿…é ˆåœ¨æª¢æŸ¥ parts ä¹‹å‰åŸ·è¡Œï¼Œå¦å‰‡æœƒè¢«æå‰è¿”å›æ””æˆª
        if hasattr(candidate, 'finish_reason') and str(candidate.finish_reason) == 'FinishReason.MALFORMED_FUNCTION_CALL':
            error_log(f"[Gemini] æª¢æ¸¬åˆ° MALFORMED_FUNCTION_CALLï¼ŒGemini ç„¡æ³•æ­£ç¢ºèª¿ç”¨å·¥å…·")
            # è¿”å›éŒ¯èª¤æ¨™è¨˜ï¼Œè®“ä¸Šå±¤å¯ä»¥é™ç´šè™•ç†
            return {
                "text": "",
                "error": "malformed_function_call",
                "finish_reason": "MALFORMED_FUNCTION_CALL"
            }
        
        # ğŸ”§ ä¿®å¾©ï¼šå„ªå…ˆä½¿ç”¨ result.text ä¾¿åˆ©æ–¹æ³•ï¼ˆæ–° SDK æ¨è–¦ï¼‰ï¼Œå†å˜—è©¦ parts[0]
        part = None
        if not hasattr(candidate.content, 'parts') or candidate.content.parts is None or len(candidate.content.parts) == 0:
            # content.parts ç‚ºç©ºï¼Œå˜—è©¦ä½¿ç”¨ result.text ä¾¿åˆ©æ–¹æ³•
            if hasattr(result, 'text') and result.text:
                debug_log(3, f"[Gemini] content.parts ç‚ºç©ºï¼Œä½† result.text å¯ç”¨ï¼Œä½¿ç”¨ä¾¿åˆ©æ–¹æ³•")
                return {"text": result.text}
            else:
                error_log(f"[Gemini] content.parts ç‚ºç©ºä¸” result.text ä¸å¯ç”¨")
                # è¨˜éŒ„æ›´å¤šèª¿è©¦ä¿¡æ¯
                if hasattr(result, 'prompt_feedback'):
                    debug_log(3, f"[Gemini] prompt_feedback: {result.prompt_feedback}")
                if hasattr(candidate, 'finish_reason'):
                    debug_log(3, f"[Gemini] finish_reason: {candidate.finish_reason}")
                if hasattr(candidate, 'safety_ratings'):
                    debug_log(3, f"[Gemini] safety_ratings: {candidate.safety_ratings}")
                return {"text": "Sorry, I could not generate any response parts."}
        
        part = candidate.content.parts[0] # type: ignore

        import json
        payload: dict[str, Any] = {}
        
        # âœ… è™•ç† function call å›æ‡‰
        if hasattr(part, 'function_call') and part.function_call:
            # ä¿®å¾©é¡å‹éŒ¯èª¤ï¼šç›´æ¥è½‰æ›ç‚º dictï¼Œé¿å… dict() æ§‹é€ å‡½æ•¸çš„é¡å‹å•é¡Œ
            args_dict = {}
            if hasattr(part.function_call, 'args') and part.function_call.args:
                args_dict = {k: v for k, v in part.function_call.args.items()}
            
            payload = {
                "function_call": {
                    "name": part.function_call.name,
                    "args": args_dict
                },
                "text": ""  # function call æ™‚æ²’æœ‰æ–‡æœ¬å›æ‡‰
            }
        elif hasattr(part, 'text') and part.text:
            # ç•¶ä½¿ç”¨ tools æ™‚ï¼ŒGemini å¯èƒ½è¿”å›ç´”æ–‡æœ¬è€Œé JSON
            if tools:
                # ğŸ”§ ä¿®å¾©ï¼šGemini åœ¨ function calling æ¨¡å¼ä¸‹å¯èƒ½è¿”å›é›™é‡ç·¨ç¢¼çš„ JSON
                try:
                    # å˜—è©¦è§£æå¤–å±¤ JSON
                    parsed = json.loads(part.text)
                    if isinstance(parsed, dict) and 'text' in parsed:
                        # è§£ç¢¼å…§å±¤çš„ Unicode è½‰ç¾©åºåˆ—
                        decoded_text = parsed['text'].encode().decode('unicode_escape')
                        payload = {"text": decoded_text}
                        # ä¿ç•™å…¶ä»–å­—æ®µ
                        for key, value in parsed.items():
                            if key != 'text':
                                payload[key] = value
                    else:
                        payload = {"text": part.text}
                except (json.JSONDecodeError, UnicodeDecodeError, AttributeError):
                    # Fallback: ç•¶ä½œç´”æ–‡æœ¬è™•ç†
                    payload = {"text": part.text}
            else:
                try:
                    payload = json.loads(part.text)
                except json.JSONDecodeError:
                    # Fallback: è‹¥ JSON è§£æå¤±æ•—ï¼Œç•¶ä½œç´”æ–‡æœ¬è™•ç†
                    payload = {"text": part.text}
        elif hasattr(part, 'struct') and part.struct:  # type: ignore
            payload = part.struct  # type: ignore
        else:
            payload = {"text": "Gemini did not produce a valid response."}

        # [å»ºè­°] æŠŠå¿«å–å‘½ä¸­è³‡è¨Šå¸¶å›å»ï¼Œæ–¹ä¾¿ Debug GUI é¡¯ç¤º
        meta = getattr(result, "usage_metadata", None)
        payload["_meta"] = {
            "cached_input_tokens": getattr(meta, "cached_content_used_input_tokens", 0) if meta else 0,
            "total_input_tokens": getattr(meta, "total_token_count", 0) if meta else 0,
        }
        return payload
